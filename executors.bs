<pre class='metadata'>
Title: Completing the Design of Executors
Shortname: D2300
Revision: 0
Status: D
Group: WG21
Audience: SG1, LEWG
Editor: Michał Dominiak, griwes@griwes.info
Editor: Lewis Baker, lewissbaker@gmail.com
Editor: Lee Howes, xrikcus@gmail.com
Editor: Michael Garland, mgarland@nvidia.com
Editor: Eric Niebler, eric.niebler@gmail.com
Editor: Bryce Adelstein Lelbach, brycelelblach@gmail.com
URL: https://wg21.link/D2300
Metadata Order: Editor, This Version, Source, Issue Tracking, Project, Audience
Markup Shorthands: markdown yes
Toggle Diffs: no
No Abstract: yes
</pre>

<style>
pre {
  margin-top: 0px;
  margin-bottom: 0px;
}
.ins, ins, ins *, span.ins, span.ins * {
  background-color: rgb(200, 250, 200);
  color: rgb(0, 136, 0);
  text-decoration: none;
}
.del, del, del *, span.del, span.del * {
  background-color: rgb(250, 200, 200);
  color: rgb(255, 0, 0);
  text-decoration: line-through;
  text-decoration-color: rgb(255, 0, 0);
}
math, span.math {
  font-family: serif;
  font-style: italic;
}
ul {
  list-style-type: "— ";
}
blockquote {
  counter-reset: paragraph;
}
div.numbered, div.newnumbered {
  margin-left: 2em;
  margin-top: 1em;
  margin-bottom: 1em;
}
div.numbered:before, div.newnumbered:before {
  position: absolute;
  margin-left: -2em;
  display-style: block;
}
div.numbered:before {
  content: counter(paragraph);
  counter-increment: paragraph;
}
div.newnumbered:before {
  content: "�";
}
div.numbered ul, div.newnumbered ul {
  counter-reset: list_item;
}
div.numbered li, div.newnumbered li {
  margin-left: 3em;
}
div.numbered li:before, div.newnumbered li:before {
  position: absolute;
  margin-left: -4.8em;
  display-style: block;
}
div.numbered li:before {
  content: "(" counter(paragraph) "." counter(list_item) ")";
  counter-increment: list_item;
}
div.newnumbered li:before {
  content: "(�." counter(list_item) ")";
  counter-increment: list_item;
}
</style>

# Abstract # {#abstract}

This paper proposes a self-contained design for an C++ executors, a series of abstractions for managing asynchronous and parallel execution on generic execution contexts. It is based on the ideas in [[P0443R14]] and its companion papers.

## Code example ## {#design-code}

Using the facilities in this paper, an end user can write code such as this:

<pre highlight="c++">
using namespace std::execution;

// get a scheduler from somewhere, e.g. a thread pool
executor auto sch = get_thread_pool().scheduler();

// describe a chain of dependent work
sender auto begin = schedule(sch);
sender auto hi_again = then(begin, []{
    std::cout << "Hi again! Have an int.";
    return 13;
});
sender auto work = then(hi_again, [](int arg) { return arg + 42; });

// submit the work for execution on the pool
// block the current thread until its completion
// the return value is a tuple of values being the result of the sender chain
auto [i] = std::this_thread::sync_wait(work);
</pre>

See [[#design-factories]], [[#design-adapters]], and [[#design-algorithms]] for short explanations of the algorithms used in this code example.

## What this proposal is ## {#abstract-is}

This paper describes a design for a complete, self-contained library providing precise control for code execution on varying execution contexts in C++. This paper should be considered as a full design on its own, based heavily on prior papers that have been seen and
discussed by the committee.

We are aiming at satisfying all the promises that have been given when the sender/receiver model has been proposed and adopted by SG1, most importantly that:

1. sender algorithms will allow for customization of their behavior based on the scheduler they are invoked for; and
2. the sender/receiver model is a replacement for two-way executors, which provided precise controls over places of execution of user code.

We believe that this aim has been achieved by the design proposed here.

## What this proposal is **not** ## {#abstract-is-not}

This paper is not a patch on top of [[P0443R14]]; we are not asking to update the existing paper, we are asking to retire it in favor of this paper, which is already self-contained; any example code within this paper can be written in Standard C++, without the need
to standardize any further facilities.

This paper is not an alternative design to [[P0443R14]]; rather, we have taken the design in the current executors paper, and applied targeted fixes to allow it to fulfill the promises of the sender/receiver model, as well as provide all the facilities we consider
essential when writing user code using standard execution concepts; we have also applied the guidance of removing one-way executors from the paper entirely, and instead provided an algorithm based around senders that serves the same purpose.

## What are the major design changes compared to P0443? ## {#abstract-compare}

1. This proposal does not propose any specific type erasure facilities; it does, however, discuss type erasure to an extent in [[#design-dispatch]].
2. Properties are not included in this paper; we see them as a possible future extension, if the committee gets more comfortable with them.
3. This paper does not include a specific thread pool implementation, per prior committee direction to propose it separately.
4. We have implemented the SG1 direction to remove executors and base all of the proposed functionalities on senders and schedulers.
5. Senders now advertise what scheduler, if any, their operations will complete on.
6. Users now have a choice between using a strictly lazy vs a possibly eager version of most algorithms.
7. The places of execution of user code in P0443 weren't precisely defined, whereas they are in this paper. See [[#design-propagation]].
8. P0443 did not propose a suite of algorithms necessary for writing sender code; this paper does. See [[#design-factories]], [[#design-adapters]], and [[#design-algorithms]].
9. P0443 did not specify the semantics of variously qualified `connect` overloads; this paper does. See [[#design-fork]].

## Prior art ## {#prior-art}

This proposal builds upon years of prior art and field experience with asynchronous and parallel programming frameworks in C++.

Futures, as traditionally realized, require the dynamic allocation and management of a shared state, synchronization, and typically type-erasure of work and continuation. Many of these costs are inherent in the nature of “future” as a handle to an operation that is already scheduled for execution. These expenses rule out the future abstraction for many uses and makes it a poor choice for a basis of a Generic mechanism.

Coroutines suffer many of the same problems but can avoid synchronizing when chaining dependent work because they typically start suspended. In many cases, coroutine frames require unavoidable dynamic allocation. Consequently, coroutines in embedded or heterogeneous environments require great attention to detail. Neither are coroutines good candidates for cancellation because the early and safe termination of coordinating coroutines requires unsatisfying solutions. On the one hand, exceptions are inefficient and disallowed in many environments. Alternatively, clumsy ad hoc mechanisms, whereby co_yield returns a status code, hinder correctness. P1662 provides a complete discussion.

Callbacks are the simplest, most powerful, and most efficient mechanism for creating chains of work, but suffer problems of their own. Callbacks must propagate either errors or values. This simple requirement yields many different interface possibilities, but the lack of a standard obstructs generic design. Additionally, few of these possibilities accomodate cancellation signals when the user requests upstream work to stop and clean up.

## Field experience ## {#field-experience}

This proposal draws heavily from our experience with the [libunifex](https://github.com/facebookexperimental/libunifex) and [Agency](https://github.com/agency-library/agency) libraries.

It is also inspired by the needs of countless other C++ frameworks for asynchrony, parallelism, and concurrency, including:
* [HPX](https://github.com/STEllAR-GROUP/hpx)
* [Folly](https://github.com/facebook/folly/blob/master/folly/docs/Futures.md)
* [stlab](https://stlab.cc/libraries/concurrency/)

Before this proposal is approved, we will present a new implementation of this proposal written from the specification and intended as a contribution to libc++. This implementation will demonstrate the viability of the design across the use cases and execution contexts that the committee has identified as essential.

# Revision history # {#revisions}

## R0 ## {#r0}

Initial revision, still in progress.

# Proposed design - introduction # {#design-intro}

The following four sections describe the entirety of the proposed design. [[#design-intro]] describes the conventions used through the rest of the design sections, as well as an example illustrating how we envision code will be written using this proposal.

[[#design-user]] describes all the functionality from the perspective we intend for users: it describes the various concepts they will interact with, and what their programming model is. [[#design-implementer]] describes the machinery that allows for
that programming model to function, and the information contained there is necessary for people implementing senders and sender algorithms (including the standard library ones) - but is not necessary to use senders productively.

Finally, [[#design-api]] discusses API decisions and questions that we believe reflect on the code that will need to be written to implement and use senders, but not on the programming model of senders in general.

Note: none of the algorithm names proposed here are names that we are particularly attached to; consider the names of the algorithms to be reasonable placeholders that can freely be changed, should the committee want to do so.

## Conventions ## {#design-conventions}

The following conventions are used throughout the design section:

  1. Universal references and explicit calls to `std::move`/`std::forward` are omitted in code samples and signatures for simplicity; assume universal references and perfect forwarding unless stated otherwise.
  2. The namespace proposed in this paper is the same as in [[P0443R14]]: `std::execution`; however, for brevity, the `std::` part of this name is omitted. When you see `execution::foo`, treat that as `std::execution::foo`.

# Proposed design - user side # {#design-user}

## Execution contexts describe the place of execution ## {#design-contexts}

An <dfn>execution context</dfn> is a resource that represents the *place* where execution will happen. This could be a concrete resource - like a specific thread pool object, or a GPU - or a more abstract one, like the current thread of execution. Execution contexts
don't need to have a representation in code; they are simply a term describing certain properties of execution of a function.

## Schedulers represent execution contexts ## {#design-schedulers}

A <dfn>scheduler</dfn> is a lightweight handle to an *execution context*, which allows describing work that will be executed on an execution agent belonging to that context. Since execution contexts don't necessarily manifest in C++ code, it's not possible to program
directly against their API. A scheduler is a solution to that problem: the scheduler concept is defined by a single operation, `schedule`, which creates a description of work on its associated execution context, materialized in the form of a sender.

<pre highlight="c++">
execution::scheduler auto sch = get_thread_pool().scheduler();
execution::sender auto snd = execution::schedule(sch);
// snd is a sender (see below) describing the creation of a new execution resource
// on the execution context associated with sch
</pre>

## Senders describe work ## {#design-senders}

A <dfn>sender</dfn> is an object that describes work. Senders are similar to futures in existing asynchrony designs, but unlike futures, the work that is being done to arrive at the values they will *send* is also directly described by the sender object itself. A
sender is said to <dfn>send</dfn> some values if a receiver connected (see [[#design-connect]]) to that sender will eventually *receive* said values.

The primary defining operation of senders is [[#design-connect]]; this function, however, is not a user-facing API; it is used to facilitate communication between senders and various sender algorithms (or other senders), but end user code is not expected to invoke
it directly. The way user code is expected to interact with senders is by using said sender algorithms; the opening example of the design section already contains a sample of sender algorithms, and the ones we are proposing as a part of this paper are described in
[[#design-factories]], [[#design-adapters]], and [[#design-algorithms]]. Here is how a user can ensure that work is started (and will eventually complete if no errors happen), but without waiting for it to finish:

<pre highlight="c++">
execution::scheduler auto sch = get_thread_pool().scheduler();
execution::sender auto snd = execution::schedule(sch);
execution::sender auto cont = execution::then(snd, []{
    std::fstream file{ "result.txt" };
    file << compute_result;
});

execution::start_detached(cont);
// at this point, the work described by \`cont\` has been submitted to the thread pool
</pre>

## Senders can propagate completion schedulers ## {#design-propagation}

One of the less clear aspects of [[P0443R14]] has been the set of requirements for the <i>place of execution</i> of any given piece of code. This underspecification is problematic, especially in case of systems where not all execution agents are created equal,
and not all functions can be run on all execution agents. Having precise control over the execution context used for any given function call being submitted is very important on such systems, and the users of standard execution facilities will expect to be able
to express such (binding) requirements.

Such precise control was present in the two-way execution API, but it has so far been missing from the senders design. There has been a proposal ([[P1897R3]]) to provide a number of algorithms that would enforce certain rules on the places of execution
of the work described by a sender, but we have found those algorithms to be insufficient for achieving the best performance on all platforms that are of interest to us. The implementation strategies that we are aware of result in one of the following situations:

  1. trying to submit work to CPU execution contexts (e.g. a thread pool) from an accelerator (e.g. a GPU), which assumes that the accelerator threads of execution are as capable as the CPU threads of execution (which they aren't); or
  2. forcibly interleaving two adjacent execution graph nodes that are both executing on an accelerator with glue code that runs on the CPU; this operation is prohibitively expensive on runtimes such as CUDA.

Neither of these implementation strategies is acceptable for accelerator runtimes. Therefore, in addition to the `on` algorithm from [[P1897R3]], we are proposing to add a standardized way for senders to advertise what scheduler (and by extension - what execution
context) they will complete on. Any given sender <b>may</b> have <dfn>completion schedulers</dfn> for some or all of the signals (value, error, or done) it completes with (for more detail on the completion signals, see [[#design-receivers]]). When further work is
attached to that sender by invoking sender algorithms, that work will also complete on the appropriate completion scheduler.

There exists a function to retrieve the [=completion scheduler=] from a sender, called `get_completion_scheduler`. Calling this function on a sender that does not have an completion scheduler is ill-formed. If a scheduler advertises its completion scheduler in this
way, that sender <b>must</b> ensure that it [=send|sends=] its values on an execution agent belonging to an execution context represented by a scheduler returned from this function.

<pre highlight="c++">
execution::scheduler auto sch = new_thread_scheduler{};
// sch is a scheduler that starts work on a new thread

execution::sender auto initial = execution::schedule(sch);
execution::sender auto next = execution::then(initial, []{
    std::cout << "First continuation" << std::endl;
});
execution::sender auto last = execution::then(next, []{
    std::cout << "Second continuation" << std::endl;
});

execution::scheduler auto completion_sch = execution::get_completion_scheduler(last);
// completion_sch is equivalent to sch

std::this_thread::sync_wait(last);
// both continuations will run on the same thread created by the scheduler
</pre>

## Execution context transitions are explicit ## {#design-transitions}

[[P0443R14]] does not contain any mechanisms for performing an execution context transition. The only algorithm that can create a sender that will move execution to a specific* execution context is `execution::schedule`, which does not take an imput sender, which
means that there's no way to construct sender chains that traverse different execution contexts. This is necessary to fulfill the promise of senders being able to replace two-way executors, which had this capability.

We propose that, for senders advertising their [=completion scheduler=], all execution context transitions <b>must</b> be explicit; running user code anywhere but where they defined it to run <b>must</b> be considered a bug.

We propose a new user-facing algorithm, `execution::reschedule`, for performing transitions from one execution context to another:

<pre highlight="c++">
execution::scheduler auto sch1 = ...;
execution::scheduler auto sch2 = ...;

execution::sender auto snd1 = execution::schedule(sch1);
execution::sender auto then1 = execution::then(snd1, []{
    std::cout << "I am running on sch1!\n";
});

execution::sender auto snd2 = execution::reschedule(then1, sch2);

execution::sender auto then2 = execution::then(snd2, []{
    std::cout << "I am running on sch2!\n";
});

std::this_thread::sync_wait(then2);
</pre>

## Senders are forkable ## {#design-fork}

Any non-trivial program will eventually want to fork a chain of senders into independent streams of work; an incoming event to a middleware system may be required to trigger events on more than one downstream system, for instance. This requires that senders provide
well defined mechanisms for making sure that attaching multiple continuations to a sender is possible and correct.

There are two parts of what we are proposing in this area. One is a semantic requirement on both senders and sender algorithms: if you invoke a sender algorithm with an lvalue sender, that sender must remain valid after such an algorithm invocation. If your algorithm
accepts an lvalue sender, it must not invalidate the lvalue it has received. It must be possible to invoke sender algorithms with rvalue senders, but lvalues must not be invalidated other than by turning them into rvalues ("moving" them).

The consequences of the above requirement are as follows:

 * single-shot senders should only work with rvalue-qualified overloads of sender algorithms;
 * multi-shot senders should work with at least some lvalue-qualified algorithms; and
 * multi-shot senders can still have operations that require moving them into an algorithm call.

To facilitate attaching multiple continuations to the same sender multiple times regardless of whether it is single-shot or multi-shot, we are also proposing a new sender algorithm: `split`.

<pre highlight=c++>
auto some_algorithm(execution::sender auto input) {
    // here, we can test whether the input sender is multi-shot
    // (for the purposes of the algorithms being used in this function)

    // but we can also turn the input into a multi-shot sender:

    execution::sender auto multi_shot = split(input);
    // multi_shot is guaranteed to be multi-shot
}
</pre>

## Senders are joinable ## {#design-join}

Similarly to how it's hard to write a complex program that will eventually want to fork sender chains into independent streams, it's also hard to write a program that does not want to eventually create join nodes, where multiple independent streams of execution are
merged into a single one in an asynchronous fashion. We are proposing an algorithm that deals with the common use case for such merging: `when_all`, and an additional variant, `reschedule_when_all`, which takes an additional scheduler.

The sender returned from `when_all` completes when the last of the input senders completes. It [=send|sends=] a pack of values, where the elements of said pack are the values sent by the input senders, in order. The `when_all` algorithm returns a sender
that also does not have an associated scheduler.

`reschedule_when_all` accepts an additional scheduler argument. It returns a sender whose [=completion scheduler=] is the scheduler provided as an argument, but otherwise behaves the same as `when_all`. You can think of it as a composition of
`transform(when_all(inputs...), scheduler)`, but one that allows for better efficiency through customization.

## Proposed set of user-facing sender factories ## {#design-factories}

A <dfn>sender factory</dfn> is a function which creates new senders, without requiring an input sender.

### `execution::schedule` ### {#design-factory-schedule}

<pre highlight="c++">
execution::sender auto schedule(
    execution::scheduler auto scheduler
);
</pre>

Returns a sender describing the start of a task graph on the provided scheduler. See [[#design-schedulers]].

<pre highlight="c++">
execution::scheduler auto sch1 = get_system_thread_pool().scheduler();

execution::sender auto snd1 = execution::schedule(sch1);
// snd1 describes the creation of a new task on the system thread pool
</pre>

### `execution::just` ### {#design-factory-just}

<pre highlight="c++">
execution::sender auto just(
    auto ...values
);
</pre>

Returns a sender with no [=completion scheduler=], which [=send|sends=] copies of the provided values.

TODO: example

### `execution::reschedule_just` ### {#design-factory-reschedule_just}

<pre highlight="c++">
execution::sender auto reschedule_just(
    execution::scheduler auto scheduler,
    auto ...values
);
</pre>

Returns a sender whose [=completion scheduler=] is the provided scheduler, which [=send|sends=] copies of the provided values.

<pre highlight="c++">
execution::sender auto vals = execution::reschedule_just(
    get_system_thread_pool().scheduler(),
    1, 2, 3
);
execution::sender auto snd = execution::then(pred, [](auto... args) {
    std::print(args..);
});
// when snd is executed, it will print "123"
</pre>

This algorithm is included, as it greatly simplifies lifting values into senders.

## Proposed set of user-facing sender adapters ## {#design-adapters}

A <dfn>sender adapter</dfn> is a function which accepts one or more senders, and possibly other algorithms, and returns a sender, whose completion is related to the sender arguments it has received.

Many sender adapters come in two versions: a strictly lazy one, which is never allowed to submit any work for execution prior to the returned sender being <dfn lt="start">started</dfn> later on, and a potentially eager one, which is allowed to submit work prior to
the returned sender being started. Sender algorithms such as [[#design-adapter-ensure_started]], [[#design-algorithm-start_detached]], and [[#design-algorithm-sync_wait]] start senders; the implementations of non-lazy versions of the sender adapters are **allowed**,
but not guaranteed, to start senders.

The strictly lazy versions of the adapters below (that is, all the versions whose names start with `lazy_`) are guaranteed to not start any input senders passed into them.

For more implementer-centric description of starting senders, see [[#design-laziness]].

### `execution::reschedule` ### {#design-adapter-reschedule}

<pre highlight="c++">
execution::sender auto reschedule(
    execution::sender auto input,
    execution::scheduler auto scheduler
);

execution::sender auto lazy_reschedule(
    execution::sender auto input,
    execution::scheduler auto scheduler
);
</pre>

Returns a sender describing the transition from the execution agent of the input sender to the execution agent of the target scheduler. See [[#design-transitions]].

<pre highlight="c++">
execution::scheduler auto cpu_sched = get_system_thread_pool().scheduler();
execution::scheduler auto gpu_sched = cuda::scheduler();

execution::sender auto cpu_task = execution::schedule(cpu_sched);
// cpu_task describes the creation of a new task on the system thread pool

execution::sender auto gpu_task = execution::reschedule(cpu_task, gpu_sched);
// gpu_task describes the transition of the task graph described by cpu_task to the gpu
</pre>

### `execution::then`, `execution::upon_error`, `execution::upon_done` ### {#design-adapter-then}

<pre highlight="c++">
execution::sender auto then(
    execution::sender auto input,
    std::invocable<<i>values-sent-by(input)</i>...> function
);

execution::sender auto lazy_then(
    execution::sender auto input,
    std::invocable<<i>values-sent-by(input)</i>...> function
);

execution::sender auto upon_error(
    execution::sender auto input,
    std::invocable<<i>errors-sent-by(input)</i>...> function
);

execution::sender auto lazy_upon_error(
    execution::sender auto input,
    std::invocable<<i>errors-sent-by(input)</i>...> function
);

execution::sender auto upon_error(
    execution::sender auto input,
    std::invocable<> function
);

execution::sender auto lazy_upon_error(
    execution::sender auto input,
    std::invocable<> function
);
</pre>

`then` returns a sender describing the task graph described by the input sender, with an added node of invoking the provided function with the values [=send|sent=] by the input sender as arguments.

`lazy_then` is **guaranteed** to not begin executing `function` until the returned sender is started.

`upon_error` and `upon_done` are similar to `then`, but where `then` works with values sent by the input sender, `upon_error` works with errors, and `upon_done` is invoked when the "done" signal is sent.

<pre highlight="c++">
execution::sender auto input = get_input();
execution::sender auto snd = execution::then(input, [](auto... args) {
    std::print(args..);
});
// snd describes the work described by pred
// followed by printing all of the values sent by pred
</pre>

This algorithm is included, as it is necessary for writing any sender code that actually performs a useful function.

### `execution::let_value`, `execution::let_error`, `execution::let_done` ### {#design-adapter-let}

<pre highlight="c++">
execution::sender auto let_value(
    execution::sender auto input,
    std::invocable<<i>values-sent-by(input)</i>...> function
);

execution::sender auto lazy_let_value(
    execution::sender auto input,
    std::invocable<<i>values-sent-by(input)</i>...> function
);

execution::sender auto let_error(
    execution::sender auto input,
    std::invocable<<i>errors-sent-by(input)</i>...> function
);

execution::sender auto lazy_let_error(
    execution::sender auto input,
    std::invocable<<i>errors-sent-by(input)</i>...> function
);

execution::sender auto let_error(
    execution::sender auto input,
    std::invocable<> function
);

execution::sender auto lazy_let_error(
    execution::sender auto input,
    std::invocable<> function
);
</pre>

`let_value` is very similar to `then`: when it is started, it invokes the provided function with the values [=send|sent=] by the input sender as arguments. However, where the sender returned from `then` sends exactly what that function ends up returning -
`let_value` requires that the function return a sender, and the sender returned by `let_value` sends the values sent by the sender returned from the callback. (In the futures world, we would call this "future unwrapping".)

`lazy_let_value` is **guaranteed** to not begin executing `function` until the returned sender is started.

`let_error` and `let_done` are similar to `let_value`, but where `let_value` works with values sent by the input sender, `let_error` works with errors, and `let_done` is invoked when the "done" signal is sent.

### `execution::on` ### {#design-adapter-on}

<pre highlight="c++">
execution::sender auto on(
    execution::scheduler auto sched,
    execution::sender auto snd
);

execution::sender auto lazy_on(
    execution::scheduler auto sched,
    execution::sender auto snd
);
</pre>

Returns a sender which, when started, will start the provided sender on an execution agent belonging to the execution context associated with the provided scheduler. This returned sender does not have a [=completion scheduler=].

TODO: example

### `execution::into_variant` ### {#design-adapter-into_variant}

<pre highlight=c++>
execution:;sender into_variant(
    execution::sender auto snd
);
</pre>

Returns a sender which sends a variant of tuples of all the possible sets of types sent by the input sender. Senders can send multiple sets of values depending on runtime conditions; this is a helper function that turns them into a single variant value.

TODO: example

### `execution::unschedule` ### {#design-adapter-unschedule}

<pre highlight="c++">
execution::sender unschedule(
    execution::sender auto snd
);
</pre>

Returns a sender which [=send|sends=] values equivalent to values sent by the provided sender, but does not have an [=completion scheduler=].

TODO: example

### `execution::bulk` ### {#design-adapter-bulk}

<pre highlight="c++">
execution::sender auto bulk(
    execution::sender auto input,
    std::integral auto size,
    invocable&lt;decltype(size), <i>values-sent-by(input)</i>...> function
);

execution::sender auto lazy_bulk(
    execution::sender auto input,
    std::integral auto size,
    invocable&lt;decltype(size), <i>values-sent-by(input)</i>...> function
);
</pre>

Returns a sender describing the task of invoking the provided function with the values [=send|sent=] by the input sender for every index in the provided shape.

In this paper, only integral types satisfy the concept of a shape, but future papers will explore bulk shapes of different kinds in more detail.

`lazy_bulk` is **guaranteed** to not begin executing `function` until the returned sender is started.

XXX TODO: provide an example

### `execution::split` ### {#design-adapter-split}

<pre highlight="c++">
execution::sender auto split(execution::sender auto sender);

execution::sender auto lazy_split(execution::sender auto sender);
</pre>

If the provided sender is a multi-shot sender, returns that sender. Otherwise, returns a multi-shot sender which sends values equivalent to the values sent by the provided sender. See [[#design-fork]].

### `execution::when_all` ### {#design-adapter-when_all}

<pre highlight="c++">
execution::sender auto when_all(
    execution::sender auto ...inputs
);

execution::sender auto when_all_with_variant(
    execution::sender auto ...inputs
);
</pre>

`when_all` returns a sender which completes once all of the input senders have completed. The values send by this sender are the values sent by each of the input, in order of the arguments passed to `when_all`.

`when_all_with_variant` does the same, but it adapts all the input senders using `into_variant`.

The returned sender does not have a [=completion scheduler=].

`when_all` is a strictly lazy algorithm; it is guaranteed to not start any of the input senders until the returned sender is started.

See [[#design-join]].

<pre highlight="c++">
execution::scheduler auto sched = get_thread_pool().scheduler();

execution::sender auto sends_1 = ...;
execution::sender auto sends_abc = ...;

execution::sender auto both = execution::when_all(sched,
    sends_1,
    sends_abc
);

execution::sender auto final = execution::then(both, [](auto... args){
    std::cout << std::format("the two args: {}, {}", args...);
});
// when final executes, it will print "the two args: 1, abc"
</pre>

### `execution::reschedule_when_all` ### {#design-adapter-reschedule_when_all}

<pre highlight="c++">
execution::sender auto reschedule_when_all(
    execution::scheduler auto sched,
    execution::sender auto ...inputs
);

execution::sender auto reschedule_when_all_with_variant(
    execution::scheduler auto sched,
    execution::sender auto ...inputs
);

execution::sender auto lazy_reschedule_when_all(
    execution::scheduler auto sched,
    execution::sender auto ...inputs
);

execution::sender auto lazy_reschedule_when_all_with_variant(
    execution::scheduler auto sched,
    execution::sender auto ...inputs
);
</pre>

Similar to [[#design-adapter-when_all]], but returns a sender whose [=completion scheduler=] is the provided scheduler.

See [[#design-join]].

### `execution::ensure_started` ### {#design-adapter-ensure_started}

<pre highlight="c++">
execution::sender auto ensure_started(
    execution::sender auto sender
);
</pre>

Once `ensure_started` returns, it is known that the provided sender has been [=connect|connected=] and `start` has been called on the resulting operation state (see [[#design-states]]); in other words, the work described by the provided sender has been submitted
for execution on the appropriate execution contexts. Returns a sender which completes when the provided sender completes and sends values equivalent to those of the provided sender.

XXX TODO: provide an example

## Proposed set of user-facing sender algorithms ## {#design-algorithms}

A <dfn>sender algorithm</dfn> is a function that accepts one or more senders.

### `execution::start_detached` ### {#design-algorithm-start_detached}

<pre highlight="c++">
void auto start_detached(
    execution::sender auto sender
);
</pre>

Like `ensure_started`, but does not return a value; if the provided sender sends an error instead of a value, `std::terminate` is called.

### `std::this_thread::sync_wait` ### {#design-algorithm-sync_wait}

<pre highlight="c++">
auto sync_wait(
    execution::sender auto sender
) requires (<i>always-sends-same-values</i>(sender))
    -> std::optional&lt;std::tuple&lt;<i>values-sent-by</i>(sender)>>;
</pre>

`std::this_thread::sync_wait` is an algorithm that submits the work described by the provided sender for execution, similarly to `ensure_started`, execept that it blocks <b>the current `std::thread` or thread of `main`</b> until the work is completed, and returns
an optional tuple of values that were sent by the provided sender on its completion of work. Where [[#design-factory-schedule]] and [[#design-factory-reschedule_just]] are meant to <i>enter</i> the domain of senders, `sync_wait` is meant to <i>exit</i> the domain of
senders, retrieving the result of the task graph.

If the provided sender sends an error instead of values, `sync_wait` throws that error as an exception, or rethrows the original exception if the error is of type `std::exception_ptr`.

If the provided sender sends the "done" signal instead of values, `sync_wait` returns an empty optional.

For an explanation of the `requires` clause, see [[#design-typed-issue]]. That clause also explains another algorithm, built on top of `sync_wait`: `sync_wait_with_variant`.

XXX TODO: provide an example

Note: Notice that this function is specified inside `std::this_thread`, and not inside `execution`. This is because `sync_wait` has to block the <i>current</i> execution agent, but determining what the current execution agent is is not reliable. Since the standard
does not specify any functions on the current execution agent other than those in `std::this_thread`, this is the flavor of this function that is being proposed. If C++ ever obtains fibers, for instance, we expect that a variant of this function called
`std::this_fiber::sync_wait` would be provided. We also expect that runtimes with execution agents that use different synchronization mechanisms than `std::thread`'s will provide their own flavors of `sync_wait` as well (assuming their execution agents have the means
to block in a non-deadlock manner).

## `execution::execute` ## {#design-execute}

In addition to the three categories of functions presented above, we also propose to include a convenience function for fire-and-forget eager one-way submission of an invocable to a scheduler, to fullfil the role of one-way executors from P0443.

<pre highlight="c++">
void execution::execute(
    execution::schedule auto sched,
    std::invocable<void> auto fn
);
</pre>

Submits the provided function for execution on the provided scheduler, as-if by:

<pre highlight="c++">
auto snd = execution::schedule(sched);
auto work = execution::then(snd, fn);
execution::start_detached(work);
</pre>

TODO: example

# Proposed design - implementer side # {#design-implementer}

## Receivers serve as glue between senders ## {#design-receivers}

A <dfn>receiver</dfn> is a callback that supports more than one channel. In fact, it supports three of them:

* `set_value`, which is the moral equivalent of an `operator()` or a function call, which signals successful completion of the operation its execution depends on;
* `set_error`, which signals that an error has happened during scheduling of the current work, executing the current work, or at some earlier point in the sender chain; and
* `set_done`, which signals that the *operation its execution depends on* requests that any work that has not started yet should not start, because it is not needed (this is cancellation, but propagating from the root of the execution tree down to its leaf nodes, as
    opposed to propagating from the leaf nodes up to the root - so **not** `some_sender.cancel()`).

Exactly one of these channels must be successfully (i.e. without an exception being thrown) invoked on a receiver before it is destroyed; if a call to `set_value` failed with an exception, either `set_error` or `set_done` must be invoked on the same receiver. These
requirements are know as the <dfn>receiver contract</dfn>.

While the receiver interface may look novel, it is in fact very similar to the interface of `std::promise`, which provides the first two signals as `set_value` and `set_error`, and it's possible to emulate the third channel with lifetime management of the promise.

Receivers are not a part of the end-user-facing API of this proposal; they are necessary to allow unrelated senders communicate with each other, but the only users who will interact with receivers directly are authors of senders.

Receivers are what is passed as the second argument to [[#design-connect]].

## Operation states represents work ## {#design-states}

An <dfn>operation state</dfn> is an object that represents work. Unlike senders, it is not a chaining mechanism; instead, it is a concrete object that packages the work described by a full sender chain, ready to be executed. An operation state is neither movable nor
copyable, and its interface consists of a single operation: `start`, which serves as the submission point of the work represented by a given operation state.

Operation states are not a part of the user-facing API of this proposal; they are necessary for implementing algorithms like `ensure_started` and `std::this_thread::sync_wait`, and the knowledge of them is necessary to implement senders, so the only users who will
interact with operation states directly are authors of senders and authors of sender algorithms.

The return value of [[#design-connect]] must satisfy the operation state concept.

## `execution::connect` ## {#design-connect}

`execution::connect` is a customization point which <dfn lt="connect">connects</dfn> senders with receivers, resulting in an operation state that will ensure that the [=receiver contract=] of the receiver passed to `connect` will be fulfilled.

<pre highlight="c++">
execution::sender auto snd = <i>some input sender</i>;
execution::receiver auto rcv = <i>some receiver</i>;
execution::operation_state auto state = execution::connect(snd, rcv);

execution::start(state);
// at this point, it is guaranteed that the work represented by state has been submitted
// to an execution context, and that execution context will eventually fulfill the
// receiver contract of rcv

// operation states are not movable, and therefore this operation state object must be
// kept alive until the operation finishes
</pre>

## Sender algorithms are customizable ## {#design-customization}

Senders being able to advertise what their [=completion scheduler=] is fulfills one of the promises of senders: that of being able to customize an implementation of an algorithm based on what scheduler any operations it depends on will complete on.

The simple way to provide customizations for functions like `then`, that is for [=sender adapter|sender adapters=] and [=sender algorithm|algorithms=], is to follow the customization scheme that has been adopted for C++20 Ranges library; to do that, we would define
the expression `execution::then(sender, invocable)` to be equivalent to:

  1. `sender.then(invocable)`, if that expression is well formed; otherwise
  2. `then(sender, invocable)`, performed in a context where this call always performs ADL, if that expression is well formed; otherwise
  3. a default implementation of `then`, which returns a sender adapter, and then define the exact semantics of said adapter.

However, this definition is problematic. Imagine another sender algorithm, `bulk`, which is a structured abstraction for a loop over an index space. Its default implementation is just a for loop. However, for accelerator runtimes like CUDA, we would like operations
like `bulk` to have specialized behavior, which invokes a kernel of more than one thread (with its size defined by the call to `bulk`); therefore, we would like to customize `bulk` for CUDA senders to achieve this. However, there's no reason for CUDA kernels to
necessarily customize the `then` algorithm, as the generic implementation is perfectly sufficient. This creates a problem, though; consider the following snippet:

<pre highlight="c++">
execution::scheduler auto cuda_sch = cuda_scheduler{};

execution::sender auto initial = execution::schedule(cuda_sch);
// the type of initial is a type defined by the cuda_scheduler
// let's call it cuda::schedule_sender&lt;>

execution::sender auto next = execution::then(cuda_sch, []{ return 1; });
// the type of next is a standard-library implementation-defined sender adapter
// that wraps the cuda sender
// let's call it execution::then_sender_adapter&lt;cuda::schedule_sender&lt;>>

execution::sender auto kernel_sender = execution::bulk(next, shape, [](int i){ ... });
</pre>

How can we specialize the `bulk` algorithm for our wrapped `schedule_sender`? Well, here's one possible approach, taking advantage of ADL (and the fact that the definition of "associated namespace" also recursively enumerates the associated namespaces of all template
parameters of a type):

<pre highlight="c++">
namespace cuda::for_adl_purposes {
template&lt;typename... SentValues>
class schedule_sender {
    execution::operation_state auto connect(execution::receiver auto rcv);
    execution::scheduler auto get_completion_scheduler() const;
};

execution::sender auto bulk(
    execution::sender auto && input,
    execution::shape auto && shape,
    invocable<<i>sender-values(input)</i>> auto && fn)
{
    // return a cuda sender representing a bulk kernel launch
}
}
</pre>

However, if the input sender is not just a `then_sender_adapter` like in the example above, but another sender that overrides `bulk` by itself, as a member function, because its author believes they know an optimization for bulk - the specialization above will no
longer be selected, because a member function of the first argument is a better match than the ADL-found overload.

This means that well-meant specialization of algorithms on senders that are entirely scheduler-agnostic can have negative consequences; the scheduler-specific specialization - which is essential for good performance on platforms providing specialized ways to launch
certain algorithms - would not be selected in such cases. But it's really the scheduler that should control the behavior of algorithms when a non-default implementation exists, not the sender. Senders merely describe work; schedulers, however, are the handle to the
runtime that will eventually execute said work, and should thus have the final say in *how* the work is going to be executed.

Therefore, we are proposing the following customization scheme (also modified to take [[#design-dispatch]] into account): the expression `execution::<algorithm>(sender, args...)`, for any given algorithm (accepting a sender as its first argument), should be
equivalent to:

  1. <code>tag_invoke(&lt;algorithm>, get_completion_scheduler&lt;<i>Signal</i>>(sender), sender, args...)</code>, if that expression is well-formed; otherwise
  2. `tag_invoke(<algorithm>, sender, args...)`, if that expression is well-formed; otherwise
  4. a default implementation, if there exists a default implementation of the given algorithm.

where <code><i>Signal</i></code> is one of `set_value`, `set_error`, or `set_done`; for most algorithms, the completion scheduler for `set_value` would be used, but for some (like `upon_error` or `let_done`), one of the others would be used.

For algorithms which accept concepts other than `sender` as their first argument, we propose that the customization scheme remains as it has been in [[P0443R14]] so far, except it should also use `tag_invoke`.

TODO: more example

## Laziness of operations is defined by algorithms ## {#design-laziness}

We distinguish two different guarantees about *when* work is submitted to an execution context:

 * <dfn>strictly lazy submission</dfn>, which means that there is a guarantee that no work is submitted to an execution context before a receiver is connected to a sender, and `execution::start` is called on the resulting operation state;
 * <dfn>potentially eager submission</dfn>, which means that work may be submitted to an execution context as soon as all the information necessary to perform it is provided.

If an operation requires potentially eager submission, strictly lazy submission is acceptable as an implementation, because it does fulfill the potentially eager guarantee. This is why the default implementations for the non-strictly-lazy sender adapters are specified
to dispatch to the strictly lazy ones; for an author of a specific sender, it is sufficient to specialize the strictly lazy version, to also achieve a specialization of the potentially eager one.

As has been described in [[#design-adapters]], whether an operation is guaranteed to perform strictly lazy submission or not is defined by the adapter used to perform it; the adapters whose names begin with `lazy_` provide the strictly lazy guarantee.

## Lazy senders provide optimization opportunities ## {#design-fusion}

Because lazy senders fundamentally *describe* work, instead of describing or representing the submission of said work to an execution context, and thanks to the flexibility of the customization of most sender algorithms, they provide an opportunity for fusing
multiple operations in a sender chain together, into a single function that can later be submitted for execution by an execution context. There are two ways this can happen.

The first (and most common) way for such optimizations to happen is thanks to the structure of the implementation: because all the work is done within callbacks invoked on the completion of an earlier operation, recursively up to the root of computation,
the compiler is able to see a chain of work described using senders as a tree of tail calls, allowing for inlining and removal of most of the sender machinery. In fact, when work is not submitted to execution contexts outside of the current thread of execution,
compilers are capable of removing the senders abstraction entirely, while still allowing for composition of functions across different parts of a program.

The second way for this to occur is when an algorithm is specialized for a specific set of arguments. For instance, we expect that, for senders which are known to have been started already, [[#design-adapter-ensure_started]] will be an identity transformation,
because the algorithm will be specialized for such senders. Similarly, an implementation could recognize two subsequent lazy [[#design-adapter-bulk]] operations of compatible shapes, and merge them together into a single submission of a GPU kernel.

## Execution context transitions are two-step ## {#design-transition-details}

Because `execution::reschedule` takes a sender as its first argument, it is not actually directly customizable by the target scheduler. This is by design: the target scheduler may not know how to transition <i>from</i> a scheduler such as a CUDA scheduler;
transitioning away from a GPU in an efficient manner requires making runtime calls that are specific to the GPU in question, and the same is usually true for other kinds of accelerators too (or for scheduler running on remote systems). To avoid this problem,
specialized schedulers like the ones mentioned here can still hook into the transition mechanism, and inject a sender which will perform a transition to the regular CPU execution context, so that any sender can be attached to it.

This, however, is a problem: because customization of algorithms must be controlled by the scheduler they will run on (see [[#design-customization]]), the type of the sender returned from `reschedule` must be controllable by the target scheduler. Besides, the target
scheduler may itself represent a specialized execution context, which requires additional work to be performed to transition <i>to</i> it. GPUs and remote node schedulers are once again good examples of such schedulers: executing code on their execution contexts
requires making runtime API calls for work submission, and quite possibly for the data movement of the values being sent by the input sender passed into `reschedule`.

To allow for such customization from both ends, we propose the inclusion of a secondary transitioning algorithm, called `schedule_from`. This algorithm is a form of `schedule`, but takes an additional, second argument: the input sender. This algorithm is not
meant to be invoked manually by the end users; they are always supposed to invoke `reschedule`, to ensure that both schedulers have a say in how the transitions are made. Any scheduler that specializes `reschedule(snd, sch)` shall ensure that the
return value of their customization is equivalent to `schedule_from(sch, snd2)`, where `snd2` is a successor of `snd` that sends values equivalent to those sent by `snd`.

The default implementation of `reschedule(snd, sched)` is `schedule_from(sched, snd)`.

# Proposed design - API specifics # {#design-api}

## Senders are pipeable ## {#design-pipelines}

Almost all sender algorithms that take a single input sender that we are proposing here take the input sender as the first argument. This is not an accident; in line with prior proposals, we are proposing that senders and sender algorithms use the familiar pipeline
syntax for chaining, just like C++20 ranges do. Therefore, a user could write the following to represent a sequence of tasks to execute first on the CPU, then on a CUDA GPU, then on a CPU again, retrieving the result at the end:

<pre highlight=c++>
auto work = execution::schedule(get_thread_pool())
    | execution::then([]{ return 123; })
    | execution::reschedule(cuda::new_stream_scheduler())
    | execution::then([](int i){ return 123 * 5; })
    | execution::reschedule(get_thread_pool())
    | execution::then([](int i){ return i - 5; });
auto [result] = std::this_thread::sync_wait(work);
// result == 610
</pre>

Certain functions should not be pipeable, because using the pipeline syntax can result in confusion of the semantics of the algorithms involved. Specifically, the following algorithms should not be pipeable:

 * `sync_wait`: rather than being a terminal node in a pipeline, it <b>consumes</b> a pipeline, and reads better as a function call;
 * `on` and `lazy_on`: the `on` algorithm changes how the sender passed to it is executed, not what happens to its result, but allowing it in a pipeline makes it read as if it performed a function more similar to `reschedule`.

## Most senders are typed ## {#design-typed}

All senders should advertise the types they will [=send=] when they complete. This is necessary for a number of features, and writing code in a way that's agnostic of whether an imput sender is typed or not in common sender adapters such as `execution::then` is
hard.

The mechanism for this advertisement is the same as in [[P0443R14]]; the way to query the types is through `sender_traits::value_types<tuple_like, variant_like>`.

### Design issue: `value_types` ### {#design-typed-issue}

`sender_traits::value_types` is a template that takes two arguments: one is a tuple-like template, the other is a variant-like template. The tuple-like argument is required to represent senders sending more than one value (such as `when_all`). The variant-like
argument is required to represent senders that choose which specific values to send at runtime.

There's a choice made in the specification of [[#design-algorithm-sync_wait]]: it returns a tuple of values sent by the sender passed to it, wrapped in `std::optional` to handle the `set_done` signal. However, this assumes that those values can be represented as a
tuple, like here:

<pre highlight=c++>
execution::sender auto sends_1 = ...;
execution::sender auto sends_2 = ...;
execution::sender auto sends_3 = ...;

auto [a, b, c] = std::this_thread::sync_wait(
    execution::reschedule_when_all(
        execution::get_completion_scheduler<execution::set_value>s(sends_1),
        sends_1,
        sends_2,
        sends_3
    ).value());
// a == 1
// b == 2
// c == 3
</pre>

This works well for senders that always send the same set of arguments. If we ignore the possibility of having a sender that sends different sets of arguments into a receiver, we can specify the "canonical" (i.e. required to be followed by all senders) form of
`value_types` of a sender which sends `Types...` to be as follows:

<pre highlight=c++>
template&lt;template&lt;typename ...> typename TupleLike>
using value_types = TupleLike<Types...>;
</pre>

If senders could only ever send one specific set of values, this would probably need to be the required form of `value_types` for all senders; defining it otherwise would cause very weird results and should be considered a bug.

This matter is somewhat complicated by the fact that (1) `set_value` for receivers can be overloaded and accept different sets of arguments, and (2) senders are allowed to send multiple different sets of values, depending on runtime conditions, the data they
consumed, and so on. To accomodate this, [[P0443R14]] also includes a second template parameter to `value_types`, one that represents a variant-like type. If we permit such senders, we would almost certainly need to require that the canonical form of `value_types`
for *all* senders (to ensure consistency in how they are handled, and to avoid accidentally interpreting a user-provided variant as a sender-provided one) sending the different sets of arguments `Types1...`, `Types2...`, ..., `TypesN...` to be as follows:

<pre highlight=c++>
template&lt;
    template&lt;typename ...> typename TupleLike,
    template&lt;typename ...> typename VariantLike
>
using value_types = VariantLike&lt;
    TupleLike&lt;Types1...>,
    TupleLike&lt;Types2...>,
    ...,
    TupleLike&lt;Types3...>
>;
</pre>

This, however, introduces a couple of complications:

1. A `just(1)` sender would also need to follow this structure, so the correct type for storing the value sent by it would be `std::variant<std::tuple<int>>` or some such. This introduces a lot of compile time overhead for the simplest senders, and this overhead
    effectively exists in all places in the code where `value_types` is queried, regardless of the tuple-like and variant-like templates passed to it. Such overhead does exist if only the tuple-like parameter exists, but is made much worse by adding this second
    wrapping layer.
2. As a consequence of (1): because `sync_wait` needs to store the above type, it can no longer return just a `std::tuple<int>` for `just(1)`; it has to return `std::variant<std::tuple<int>>`. C++ currently does not have an easy way to destructure this; it may get
    less awkward with pattern matching, but even then it seems extremely heavyweight to involve variants in this API, and for the purpose of generic code, the kind of the return type of `sync_wait` must be the same across all sender types.

One possible solution to (2) above is to place a requirement on `sync_wait` that it can only accept senders which send only a single set of values, therefore removing the need for `std::variant` to appear in its API; because of this, we propose to expose both
`sync_wait`, which is a simple, user-friendly version of the algorithm, but requires that `value_types` have only one possible variant, and `sync_wait_with_variant`, which accepts any sender, but returns an optional whose value type is the variant of all the
possible tuples sent by the input sender:

<pre highlight=c++>
auto sync_wait_with_variant(
    execution::sender auto sender
) -> std::optional&lt;std::variant&lt;
        std::tuple&lt;<i>values<sub>0</sub>-sent-by</i>(sender)>,
        std::tuple&lt;<i>values<sub>1</sub>-sent-by</i>(sender)>,
        ...,
        std::tuple&lt;<i>values<sub>n</sub>-sent-by</i>(sender)>
    >>;

auto sync_wait(
    execution::sender auto sender
) requires (<i>always-sends-same-values</i>(sender))
    -> std::optional&lt;std::tuple&lt;<i>values-sent-by</i>(sender)>>;
</pre>

## Ranges-style CPOs vs `tag_invoke` ## {#design-dispatch}

XXX TODO: describe pros and cons of both; make the argument for using `tag_invoke`

short list:
1. allows for propagation of all specializations to a wrapped object, without having to know them all;
2. in the future provides what is necessary for a polymorphic wrapper that is supposed to perform well;
3. because we anticipate multiple versions of `sync_wait`, for different runtimes (`std::this_thread` vs `std::this_fiber`, for instance), the specializations for it must happen not by a global name (because otherwise it'd need to be something like
    `std_this_thread_sync_wait`), but rather by a namespaced name, and `tag_invoke` provides a way to do this

# Specification # {#spec}

Much of this wording follows the wording of [[P0443R14]].

[[#spec-utilities]] is meant to be a diff relative to the wording of the <b>[utilities]</b> clause of [[N4885]]. This diff imports changes from [[P1895R0]].

[[#spec-thread]] is meant to be a diff relative to the wording of the <b>[thread]</b> clause of [[N4885]]. This diff imports changes from [[P2175R0]].

[[#spec-execution]] is meant to be added as a new library clause to the working draft of C++.

# General utilities library <b>[utilities]</b> # {#spec-utilities}

## Function objects <b>[function.objects]</b> ## {#spec-function.objects}

### Header `<functional>` synopsis <b>[functional.syn]</b> ### {#spec-functional.syn}

At the end of this subclause, insert the following declarations into the synopsis within `namespace std`:

<ins>
<blockquote>
<pre highlight=c++>
// [func.tag_invoke], tag_invoke
inline namespace unspecified {
  inline constexpr unspecified tag_invoke = unspecified;
}

template&lt;auto& Tag>
  using tag_t = decay_t&lt;decltype(Tag)>;

template&lt;class Tag, class... Args>
  concept tag_invocable =
    invocable&lt;decltype(tag_invoke), Tag, Args...>;

template&lt;class Tag, class... Args>
  concept nothrow_tag_invocable =
    tag_invocable&lt;Tag, Args...> &&
    is_nothrow_invocable_v&lt;decltype(tag_invoke), Tag, Args...>;

template&lt;class Tag, class... Args>
  using tag_invoke_result = invoke_result&lt;decltype(tag_invoke), Tag, Args...>;

template&lt;class Tag, class... Args>
  using tag_invoke_result_t = invoke_result_t&lt;decltype(tag_invoke), Tag, Args...>;
</pre>
</blockquote>
</ins>

### Tag_invoke <b>[func.tag_invoke]</b> ### {#spec-func.tag_invoke}

Insert this section as a new subclause, between Searchers <b>[func.search]</b> and Class template `hash` <b>[unord.hash]</b>.

<ins>
<blockquote>

1. The name `std::tag_invoke` denotes a customization point object. For some subexpressions `tag` and `args...`, `tag_invoke(tag, args...)` is expression-equivalent to an unqualified call to <code>tag_invoke(<i>decay-copy</i>(tag), args...)</code> with overload
    resolution performed in a context that includes the declaration:

    <pre>
    void tag_invoke();
    </pre>

    and that does not include the the `std::tag_invoke` name.

</blockquote>
</ins>

# Thread support library <b>[thread]</b> # {#spec-thread}

## Stop tokens <b>[thread.stoptoken]</b> ## {#spec-thread.stoptoken}

### Header `<stop_token>` synopsis <b>[thread.stoptoken.syn]</b> ### {#spec-thread.stoptoken.syn}

At the beginning of this subclause, insert the following declarations into the synopsis within `namespace std`:

<ins>
<blockquote>
<pre>
template&lt;template&lt;typename> class>
  struct &lt;i>check-type-alias-exists&lt;/i>; // exposition-only

template&lt;typename T>
  concept stoppable_token = &lt;i>see-below&lt;/i>;

template&lt;typename T, typename CB, typename Initializer = CB>
  concept stoppable_token_for = &lt;i>see-below&lt;/i>;

template&lt;typename T>
  concept unstoppable_token = &lt;i>see-below&lt;/i>;
</pre>
</blockquote>
</ins>

At the end of this subclause, insert the following declarations into the synopsis of within `namespace std`:

<ins>
<blockquote>
<pre>
// [stoptoken.never], class never_stop_token
class never_stop_token;

// [stoptoken.inplace], class in_place_stop_token
class in_place_stop_token;

// [stopsource.inplace], class in_place_stop_source
class in_place_stop_source;

// [stopcallback.inplace], class template in_place_stop_callback
template&lt;typename Callback>
class in_place_stop_callback;
</pre>
</blockquote>
</ins>

### Stop token concepts <b>[thread.stoptoken.concepts]</b> ### {#spec-thread.stoptoken.concepts}

Insert this section as a new subclause between Header `<stop_token>` synopsis <b>[thread.stoptoken.syn]</b> and Class `stop_token` <b>[stoptoken]</b>.

<ins>
<blockquote>
1. The `stoppable_token` concept checks for the basic interface of a “stop token” which is copyable and allows polling to see if stop has been requested and also whether a stop request is possible. It also requires an associated nested template-type-alias,
    `T::callback_type<CB>`, that identifies the stop-callback type to use to register a callback to be executed if a stop-request is ever made on a stoppable_token of type, `T`. The `stoppable_token_for` concept checks for a stop token type compatible with a given
    callback type. The `unstoppable_token` concept checks for a stop token type that does not allow stopiing.

<pre>
template&lt;typename T>
  concept stoppable_token =
    copy_constructible&lt;T> &&
    move_constructible&lt;T> &&
    is_nothrow_copy_constructible_v&lt;T> &&
    is_nothrow_move_constructible_v&lt;T> &&
    equality_comparable&lt;T> &&
    requires (const T& token) {
      { token.stop_requested() } noexcept -> boolean-testable;
      { token.stop_possible() } noexcept -> boolean-testable;
      typename __check_type_alias_exists&lt;T::template callback_type>;
    };

template&lt;typename T, typename CB, typename Initializer = CB>
  concept stoppable_token_for =
    stoppable_token&lt;T> &&
    invocable&lt;CB> &&
    requires {
      typename T::template callback_type&lt;CB>;
    } &&
    constructible_from&lt;CB, Initializer> &&
    constructible_from&lt;typename T::template callback_type&lt;CB>, T, Initializer> &&
    constructible_from&lt;typename T::template callback_type&lt;CB>, T&, Initializer> &&
    constructible_from&lt;typename T::template callback_type&lt;CB>, const T, Initializer> &&
    constructible_from&lt;typename T::template callback_type&lt;CB>, const T&, Initializer>;

template&lt;typename T>
  concept unstoppable_token =
    stoppable_token&lt;T> &&
    requires {
      { T::stop_possible() } -> boolean-testable;
    } &&
    (!T::stop_possible());
</pre>

2. Let `t` and `u` be distinct object of type `T`. The type `T` models `stoppable_token` only if:

    1. All copies of a `stoppable_token` reference the same logical shared stop state and shall report values consistent with each other.

    2. If `t.stop_possible()` evaluates to `false` then, if `u`, references the same logical shared stop state, `u.stop_possible()` shall also subsequently evaluate to `false` and `u.stop_requested()` shall also subsequently evaluate to `false`.

    3. If `t.stop_requested()` evaluates to `true` then, if `u`, references the same logical shared stop state, `u.stop_requested()` shall also subsequently evaluate to `true` and `u.stop_possible()` shall also subsequently evaluate to `true`.

    4. Given a callback-type, CB, and a callback-initializer argument, `init`, of type `Initializer` then constructing an instance, `cb`, of type `T::callback_type<CB>`, passing `t` as the first argument and `init` as the second argument to the constructor, shall,
        if `t.stop_possible()` is `true`, construct an instance, `callback`, of type `CB`, direct-initialized with `init`, and register callback with `t`’s shared stop state such that callback will be invoked with an empty argument list if a stop request is made on
        the shared stop state.

        1. If `t.stop_requested()` is `true` at the time callback is registered then callback may be invoked immediately inline inside the call to `cb`’s constructor.

        2. If callback is invoked then, if `u` references the same shared stop state as `t`, an evaluation of `u.stop_requested()` will be `true` if the beginning of the invocation of callback strongly-happens-before the evaluation of `u.stop_requested()`.

        3. If `t.stop_possible()` evaluates to `false` then the construction of `cb` is not required to construct and initialize `callback`.

    5. Construction of a `T::callback_type<CB>` instance shall only throw exceptions thrown by the initialization of the `CB` instance from the value of type `Initializer`.

    6. Destruction of the `T::callback_type<CB>` object, `cb`, deregisters callback from the shared stop state such that `callback` will not be invoked after the destructor returns.

        1. If `callback` is currently being invoked on another thread then the destructor of `cb` will block until the invocation of `callback` returns such that the return from the invocation of `callback` strongly-happens-before the destruction of `callback`.

        2. Destruction of a callback `cb` shall not block on the completion of the invocation of some other callback registered with the same shared stop state.

</blockquote>
</ins>

# Execution control library <b>[execution]</b> # {#spec-execution}

1. This Clause describes components supporting execution of function objects [function.objects].

2. The following subclauses describe the requirements, concepts, and components for execution control primitives as summarized in Table 1.

<table>
<caption>Table 1: Execution control library summary <b>[tab:execution.summary]</b></caption>
<th><td>Subclause</td><td>Header</td></th>
<tr style="border-bottom-style: hidden;"><td><a href="#spec-execution.scheduler">[execution.scheduler]</a></td><td>Schedulers</td><td>`<execution>`</td></tr>
<tr style="border-bottom-style: hidden;"><td><a href="#spec-execution.receiver">[execution.receiver]</a></td><td>Receivers</td><td></td></tr>
<tr style="border-bottom-style: hidden;"><td><a href="#spec-execution.op_state">[execution.op_state]</a></td><td>Operation states</td><td></td></tr>
<tr style="border-bottom-style: hidden;"><td><a href="#spec-execution.sender">[execution.sender]</a></td><td>Senders</td><td></td></tr>
<tr><td><a href="#spec-execution.execute">[execution.execute]</a></td><td>One-way execution</td><td></td></tr>
</table>

## Header `<execution>` synopsis <b>[execution.syn]</b> ## {#spec-execution.syn}

<pre highlight=c++>
namespace std::execution {
  // [execution.helpers], helper concepts
  template&lt;class T>
    concept <i>moveable-value</i> = <i>see-below</i>; // exposition only

  // [execution.scheduler], schedulers
  template&lt;class S>
    concept scheduler = <i>see-below</i>;

  // [execution.scheduler.queries], scheduler queries
  inline namespace <i>unspecified</i> {
    struct get_forward_progress_guarantee_t;
    inline constexpr get_forward_progress_guarantee_t get_forward_progress_guarantee{}; // TODO
  }

  // [execution.receiver], receivers
  template&lt;class T, class E = exception_ptr>
    concept receiver = <i>see-below</i>;

  template&lt;class T, class... An>
    concept receiver_of = <i>see-below</i>;

  inline namespace <i>unspecified</i> {
    struct set_value_t;
    inline constexpr set_value_t set_value{};
    struct set_error_t;
    inline constexpr set_error_t set_error{};
    struct set_done_t;
    inline constexpr set_done_t set_done{};
  }

  // [execution.receiver.queries], receiver queries
  inline namespace <i>unspecified</i> {
    struct get_scheduler_t;
    inline constexpr get_scheduler_t get_scheduler{};
    struct get_allocator_t;
    inline constexpr get_allocator_t get_allocator{};
    struct get_stop_token_t;
    inline constesxpr get_stop_token_t get_stop_token{};
  }

  // [execution.op_state], operation states
  template&lt;class O>
    concept operation_state = <i>see-below</i>;

  inline namespace <i>unspecified</i> {
    struct start_t;
    inline constexpr start_t start{};
  }

  // [execution.sender], senders
  template&lt;class S>
    concept sender = <i>see-below</i>;

  template&lt;class S, class R>
    concept sender_to = <i>see-below</i>;

  template&lt;class S>
    concept <i>has-sender-types</i> = <i>see-below</i>; // exposition only

  template&lt;class S>
    concept typed_sender = <i>see-below</i>;

  // [execution.sender.traits], sender traits
  template&lt;class S>
    struct sender_traits; // TODO

  inline namespace <i>unspecified</i> {
    // [execution.sender.connect], the connect algorithm
    struct connect_t;
    inline constexpr connect_t connect{};

    // [execution.sender.queries], sender queries
    template&lt;class CPO>
    struct get_completion_scheduler_t;
    template&lt;class CPO>
    inline constexpr get_completion_scheduler_t get_completion_scheduler{};

    // [execution.sender.factories], sender factories
    struct schedule_t;
    inline constexpr schedule_t schedule{};
    template&lt;class... Ts>
      struct <i>just-sender</i>; // exposition only
    template&lt;<i>moveable-value</i>... Ts>
      <i>just-sender</i>&lt;remove_cvref_t&lt;Ts>...> just(Ts &&...);
    struct reschedule_just_t;
    inline constexpr reschedule_just_t reschedule_just{};

    // [execution.sender.adapters], sender adapters
    struct on_t;
    inline constexpr on_t on{};
    struct lazy_on_t;
    inline constexpr lazy_on_t lazy_on{};
    struct reschedule_t;
    inline constexpr reschedule_t reschedule{};
    struct lazy_reschedule_t;
    inline constexpr lazy_reschedule_t lazy_reschedule{};
    struct schedule_from_t;
    inline constexpr schedule_from_t schedule_from{};
    struct lazy_schedule_from_t;
    inline constexpr lazy_schedule_from_t lazy_schedule_from{};

    struct then_t;
    inline constexpr then_t then{};
    struct lazy_then_t;
    inline constexpr lazy_then_t lazy_then{};
    struct upon_error_t;
    inline constexpr upon_error_t upon_error{};
    struct lazy_upon_error_t;
    inline constexpr lazy_upon_error_t lazy_upon_error{};
    struct upon_done_t;
    inline constexpr upon_done_t upon_done{};
    struct lazy_upon_done_t;
    inline constexpr lazy_upon_done_t lazy_upon_done{};

    struct let_value_t;
    inline constexpr let_value_t let_value{};
    struct lazy_let_value_t;
    inline constexpr lazy_let_value_t lazy_let_value{};
    struct let_error_t;
    inline constexpr let_error_t let_error{};
    struct lazy_let_error_t;
    inline constexpr lazy_let_error_t lazy_let_error{};
    struct let_done_t;
    inline constexpr let_done_t let_done{};
    struct lazy_let_done_t;
    inline constexpr lazy_let_done_t lazy_let_done{};

    struct bulk_t;
    inline constexpr bulk_t bulk{};
    struct lazy_bulk_t;
    inline constexpr lazy_bulk_t lazy_bulk{};

    struct split_t;
    inline constexpr split_t split{};
    struct lazy_split_t;
    inline constexpr lazy_split_t lazy_split{};
    struct when_all_t;
    inline constexpr when_all_t when_all{};
    struct when_all_with_variant_t;
    inline constexpr when_all_with_variant_t when_all_with_variant{};
    struct reschedule_when_all_t;
    inline constexpr reschedule_when_all_t reschedule_when_all{};
    struct lazy_reschedule_when_all_t;
    inline constexpr lazy_reschedule_when_all_t lazy_reschedule_when_all{};
    struct reschedule_when_all_with_variant_t;
    inline constexpr reschedule_when_all_with_variant_t
      reschedule_when_all_with_variant{};
    struct lazy_reschedule_when_all_with_variant_t;
    inline constexpr lazy_reschedule_when_all_with_variant_t
      lazy_reschedule_when_all_with_variant{};

    template&lt;typed_sender S>
      using <i>into-variant-type</i> = <i>see-below</i>; // exposition-only
    template&lt;typed_sender S>
      <i>see-below</i> into_variant(S &&);
    template&lt;sender S>
      <i>see-below</i> unschedule(S &&);
    struct ensure_started_t;
    inline constexpr ensure_started_t ensure_started{};

    // [execution.sender.algorithms], sender algorithms
    struct start_detached_t;
    inline constexpr start_detached_t start_detached{};
  }
}

namespace std::this_thread {
  inline namespace <i>unspecified</i> {
    template&lt;typed_sender S>
      using <i>sync-wait-type</i> = <i>see-below</i>; // exposition-only
    template&lt;typed_sender S>
      using <i>sync-wait-with-variant-type</i> = <i>see-below</i>; // exposition-only

    struct sync_wait_t;
    inline constexpr sync_wait_t sync_wait{};
    struct sync_wait_with_variant_t;
    inline constexpr sync_wait_with_variant_t sync_wait_with_variant{};
  }
}

namespace std::execution {
  inline namespace <i>unspecified</i> {
    // [execution.execute], one-way execution
    struct execute_t;
    inline constexpr execute_t execute{};
  }
}
</pre>

## Helper concepts <b>[execution.helpers]</b> ## {#spec-execution.helpers}

    <pre highlight=c++>
    template&lt;class T>
    concept moveable-value = // exposition only
      move_constructible&lt;remove_cvref_t&lt;T>> &&
      constructible_from&lt;remove_cvref_t&lt;T>, T>;
    </pre>

## Schedulers <b>[execution.scheduler] </b> ## {#spec-execution.scheduler}

1. The `scheduler` concept defines the requirements of a type that allows for scheduling of work on its <i>associated execution context</i>.

    <pre highlight=c++>
    template&lt;class S>
      concept scheduler =
        copy_constructible&lt;remove_cvref_t&lt;S>> &&
        equality_comparable&lt;remove_cvref_t&lt;S>> &&
        requires(S&& s) {
          execution::schedule((S&&)s);
        };
    </pre>

2. None of a scheduler's copy constructor, destructor, equality comparison, or `swap` operations shall exit via an exception.

3. None of these operations, nor a scheduler type's `schedule` function, or a call to a scheduler type's query functions ([[#spec-execution.scheduler.queries]]) shall introduce data races as a result of concurrent invocations of thos functions from different
    threads.

4. For any two (possibly const) values `s1` and `s2` of some scheduler type `S`, `s1 == s2` shall return `true` only if both `s1` and `s2` are handles to the same associated execution context.

5. A scheduler type's destructor shall not block pending completion of any receivers connected to the sender objects returned from `schedule`. [<i>Note:</i> The ability to wait for completion of submitted function objects may be provided by the associated execution
    context of the scheduler. <i>—end note</i>]

### Scheduler queries <b>[execution.scheduler.queries]</b> ### {#spec-execution.scheduler.queries}

## Receivers <b>[execution.receiver]</b> ## {#spec-execution.receiver}

1. A <i>receiver</i> represents the continuation of an asynchronous operation. An asynchronous operation may complete with a (possibly empty) set of values, an error, or it may be cancelled. A receiver has three principal operations corresponding to the three ways
    an asynchronous operation may complete: `set_value`, `set_error`, and `set_done`. These are collectively known as a receiver’s <i>completion-signal operations</i>.

2. The `receiver` concept defines the requirements for a receiver type with an unknown set of value types. The `receiver_of` concept defines the requirements for a receiver type with a known set of value types, whose error type is `std::exception_ptr`.

    <pre highlight=c++>
    template&lt;class T, class E = exception_ptr>
    concept receiver =
      move_constructible&lt;remove_cvref_t&lt;T>> &&
      constructible_from&lt;remove_cvref_t&lt;T>, T> &&
      requires(remove_cvref_t&lt;T>&& t, E&& e) {
        { execution::set_done(std::move(t)) } noexcept;
        { execution::set_error(std::move(t), (E&&) e) } noexcept;
      };

    template&lt;class T, class... An>
    concept receiver_of =
      receiver&lt;T> &&
      requires(remove_cvref_t&lt;T>&& t, An&&... an) {
        execution::set_value(std::move(t), (An&&) an...);
      };
    </pre>

3. The receiver’s completion-signal operations have semantic requirements that are collectively known as the <i>receiver contract</i>, described below:

    1. None of a receiver’s completion-signal operations shall be invoked before `execution::start` has been called on the operation state object that was returned by `execution::connect` to connect that receiver to a sender.

    2. Once `execution::start` has been called on the operation state object, exactly one of the receiver’s completion-signal operations shall complete non-exceptionally before the receiver is destroyed.

    3. If `execution::set_value` exits with an exception, it is still valid to call `execution::set_error` or `execution::set_done` on the receiver, but it is no longer valid to call `execution::set_value` on the receiver.

4. Once one of a receiver’s completion-signal operations has completed non-exceptionally, the receiver contract has been satisfied.

### Set value algorithm <b>[execution.receiver.set_value]</b> ### {#spec-execution.receiver.set_value}

1. `execution::set_value` is used to send a <i>value completion signal</i> to a receiver.

2. The name `execution::set_value` denotes a customization point object. The expression `execution::set_value(R, Vs...)` for some subexpressions `R` and `Vs...` is expression-equivalent to:

    1. `tag_invoke(execution::set_value, R, Vs...)`, if that expression is valid. If the function selected by `tag_invoke` does not send the value(s) `Vs...` to the receiver `R`’s value channel, the program is ill-formed with no diagnostic required.

    2. Otherwise, `execution::set_value(R, Vs...)` is ill-formed.

### Set error algorithm <b>[execution.receiver.set_error]</b> ### {#spec-execution.receiver.set_error}

1. `execution::set_error` is used to send a <i>error signal</i> to a receiver.

2. The name `execution::set_error` denotes a customization point object. The expression `execution::set_error(R, E)` for some subexpressions `R` and `E` is expression-equivalent to:

    1. `tag_invoke(execution::set_error, R, E)`, if that expression is valid. If the function selected by `tag_invoke` does not send the error `E` to the receiver `R`’s error channel, the program is ill-formed with no diagnostic required.

    2. Otherwise, `execution::set_error(R, E)` is ill-formed.

### Set done algorithm <b>[execution.receiver.set_done]</b> ### {#spec-execution.receiver.set_done}

1. `execution::set_done` is used to send a <i>done signal</i> to a receiver.

2. The name `execution::set_done` denotes a customization point object. The expression `execution::set_done(R)` for some subexpression `R` is expression-equivalent to:

    1. `tag_invoke(execution::set_done, R)`, if that expression is valid. If the function selected by `tag_invoke` does not signal the receiver `R`’s done channel, the program is ill-formed with no diagnostic required.

    2. Otherwise, `execution::set_done(R)` is ill-formed.

### Receiver queries <b>[execution.receiver.queries]</b> ### {#spec-execution.receiver.queries}

#### Scheduler receiver query <b>[execution.receiver.queries.scheduler]</b> #### {#spec-execution.receiver.queries.scheduler}

1. `execution::get_scheduler` is used to ask a receiver object for a <i>suggested scheduler</i> to be used by a sender it is connected to when it needs to launch additional work. [<i>Note:</i> the presence of this query on a receiver does not bind a sender to use
    its result. --<i>end note</i>]

2. The name `execution::get_scheduler` denotes a customization point object. For some subexpression `r`, let `R` be `decltype((r))`. If `R` does not satisfy `execution::receiver`, `execution::get_scheduler` is ill-formed. Otherwise, `execution:;get_scheduler(r)` is
    expression equivalent to:

    1. `tag_invoke(execution:;get_scheduler, as_const(r))`, if this expression is well formed and satisfies `execution::scheduler`, and is `noexcept`.

    2. Otherwise, `execution::get_scheduler(r)` is ill-formed.

#### Allocator receiver query <b>[execution.receiver.queries.allocator]</b> #### {#spec-execution.receiver.queries.allocator}

1. `execution::get_allocator` is used to ask a receiver object for a <i>suggested allocator</i> to be used by a sender it is connected to when it needs to allocate memory. [<i>Note:</i> the presence of this query on a receiver does not bind a sender to use
    its result. --<i>end note</i>]

2. The name `execution::get_allocator` denotes a customization point object. For some subexpression `r`, let `R` be `decltype((r))`. If `R` does not satisfy `execution::receiver`, `execution::get_allocator` is ill-formed. Otherwise, `execution:;get_allocator(r)` is
    expression equivalent to:

    1. `tag_invoke(execution:;get_allocator, as_const(r))`, if this expression is well formed and models <i>Allocator</i>, and is `noexcept`.

    2. Otherwise, `execution::get_allocator(r)` is ill-formed.

#### Stop_token receiver query <b>[execution.receiver.queries.stop_token]</b> #### {#spec-execution.receiver.queries.stop_token}

1. `execution::get_stop_token` is used to ask a receiver object for an <i>associated stop token</i> to be used by a sender it is connected to when it needs to launch additional work. [<i>Note:</i> the presence of this query on a receiver does not bind a sender to
    use its result. --<i>end note</i>]

2. The name `execution::get_stop_token` denotes a customization point object. For some subexpression `r`, let `R` be `decltype((r))`. If `R` does not satisfy `execution::receiver`, `execution::get_stop_token` is ill-formed. Otherwise, `execution:;get_stop_token(r)`
    is expression equivalent to:

    1. `tag_invoke(execution:;get_stop_token, as_const(r))`, if this expression is well formed and satisfies `stoppable_token`, and is `noexcept`.

    2. Otherwise, `never_stop_token{}`.

## Operation states <b>[execution.op_state]</b> ## {#spec-execution.op_state}

1. The `operation_state` concept defines the requirements for an operation state type, which allows for starting the execution of work.

    <pre highlight=c++>
    template&lt;class O>
      concept operation_state =
        destructible&lt;O> &&
        is_object_v&lt;O> &&
        requires (O& o) {
          { execution::start(o) } noexcept;
        };
    </pre>

### Start algorithm <b>[execution.op_state.start]</b> ### {#spec-execution.op_state.start}

1. `execution::start` is used to start work represented by an operation state object.

2. The name `execution::start` denotes a customization point object. The expression `execution::start(O)` for some lvalue subexpression `O` is expression-equivalent to:

    1. `tag_invoke(execution::start, O)`, if that expression is valid. If the function selected by `tag_invoke` does not start the work represented by the operation state `O`, the program is ill-formed with no diagnostic required.

    2. Otherwise, `execution::start(O)` is ill-formed.

3. The caller of `execution::start(O)` must guarantee that the lifetime of the operation state object `O` extends at least until one of the receiver completion-signal functions of a receiver `R` passed into the `execution::connect` call that produced `O` is ready
    to successfully return. [<i>Note:</i> this allows for the receiver to manage the lifetime of the operation state object, if destroying it is the last operation it performs in its completion-signal functions. --<i>end note</i>]

## Senders <b>[execution.sender]</b> ## {#spec-execution.sender}

1. A sender describes a potentially asynchronous operation. A sender's responsibility is to fulfill the receiver contract of a connected receiver by delivering one of the receiver completion-signals.

2. The `sender` concept defines the requirements for a sender type. The `sender_to` concept defines the requirements for a sender type capable of being connected with a specific receiver type.

    <pre highlight=c++>
    template&lt;class S>
      concept sender =
        move_constructible&lt;remove_cvref_t&lt;S>> &&
        !requires {
          typename sender_traits&lt;remove_cvref_t&lt;S>>::__unspecialized; // exposition only
        };

    template&lt;class S, class R>
      concept sender_to =
        sender&lt;S> &&
        receiver&lt;R> &&
        requires (S&& s, R&& r) {
          execution::connect((S&&) s, (R&&) r);
        };
    </pre>

3. A sender is <i>typed</i> if it declares what types it sends through a connected receiver's channels.

4. The `typed_sender` concept defines the requirements for a typed sender type.

    <pre highlight=c++>
    template&lt;class S>
      concept <i>has-sender-types</i> = // exposition only
        requires {
          typename has-value-types&lt;S::template value_types>;
          typename has-error-types&lt;S::template error_types>;
          typename bool_constant&lt;S::sends_done>;
        };

    template&lt;class S>
      concept typed_sender =
        sender&lt;S> &&
        <i>has-sender-types</i>&lt;sender_traits&lt;remove_cvref_t&lt;S>>>;
    </pre>

### Sender traits <b>[execution.sender.traits]</b> ### {#spec-execution.sender.traits}

### Connect algorithm <b>[execution.sender.connect]</b> ### {#spec-execution.sender.connect}

1. `execution::connect` is used to <i>connect</i> a sender with a receiver, producing an operation state object that represents the work that needs to be performed to satisfy the receiver contract of the receiver with values that are the result of the operations
    described by the sender.

2. The name `execution::connect` denotes a customization point object. For some subexpressions `s` and `r`, let `S` be `decltype((s))` and `R` be `decltype((r))`. If `R` does not satisfy `execution::receiver` or `S` does not satisfy `execution::sender`,
    `execution::connect(s, r)` is ill-formed. Otherwise, the expression `execution::connect(s, r)` is expression-equivalent to:

    1. `tag_invoke(execution::connect, s, r)`, if that expression is valid and its type satisfies `execution::operation_state`. If the function selected by `tag_invoke` does not return an operation state for which `execution::start` starts work described by `s`, the program
        is ill-formed with no diagnostic required.

    2. Otherwise, `execution::connect(s, r)` is ill-formed.

3. Standard sender types shall always expose an rvalue-qualified overload of a customization of `execution::connect`. Standard sender types shall only expose an lvalue-qualified overload of a customization of `execution::connect` if they are copyable.

### Sender queries <b>[execution.sender.queries]</b> ### {#spec-execution.sender.queries}

#### Scheduler sender query <b>[execution.sender.queries.scheduler]</b> #### {#spec-execution.sender.queries.scheduler}

1. `execution::get_completion_scheduler` is used to ask a sender object for the <i>completion scheduler</i> for one of its signals.

2. The name `execution::get_completion_scheduler` denotes a customization point object template. For some subexpression `s`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::get_completion_scheduler` is ill-formed. If the template
    argument `CPO` in `execution::get_completion_scheduler<CPO>` is not one of `execution::set_value_t`, `execution::set_error_t`, or `execution:;set_done_t`, `execution::get_completion_scheduler<CPO>` is ill-formed. Otherwise,
    `execution::get_completion_scheduler<CPO>(s)` is expression-equivalent to:

    1. `tag_invoke(execution:;get_completion_scheduler<CPO>, as_const(s))`, if this expression is well formed and satisfies `execution::scheduler`, and is `noexcept`.

    2. Otherwise, `execution::get_completion_scheduler<CPO>(s)` is ill-formed.

3. If, for some sender `s` and customization point object `CPO`, `execution::get_completion_scheduler<decltype(CPO)>(s)` is well-formed and results in a scheduler `sch`, and the sender `s` invokes `CPO(r, args...)`, for some receiver `r` which has been connected to
    `s`, with additional arguments `args...`, on an execution agent which does not belong to the associated execution context of `sch`, the behavior is undefined.

### Sender factories <b>[execution.sender.factories]</b> ### {#spec-execution.sender.factories}

#### General <b>[execution.sender.factories.general]</b> #### {#spec-execution.sender.factories.general}

1. Subclause [execution.sender.factories] defines <i>sender factories</i>, which are utilities that return senders without accepting senders as arguments.

#### Schedule sender factory <b>[execution.sender.schedule]</b> #### {#spec-execution.sender.schedule}

1. `execution::schedule` is used to obtain a sender associated with a scheduler, which can be used to describe work to be started on that scheduler's associated execution context.

2. The name `execution::schedule` denotes a customization point object. For some subexpression `s`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::scheduler`, `execution::schedule` is ill-formed. Otherwise, the expression `execution::schedule(s)`
    is expression-equivalent to:

    1. `tag_invoke(execution::schedule, s)`, if that expression is valid and its type satisfies `execution::sender`. If the function selected by `tag_invoke` does not return a sender whose completion scheduler is equivalent to `s`, the program is ill-formed with no
        diagnostic required.

    2. Otherwise, `execution::schedule(s)` is ill-formed.

#### Just sender factory <b>[execution.sender.just]</b> #### {#spec-execution.sender.just}

1. `execution::just` is used to create a sender that propagates a set of values to a connected receiver.

    <pre highlight=c++>
    template&lt;class... Ts>
    struct <i>just-sender</i> // exposition only
    {
      std::tuple&lt;Ts...> vs_;

      template&lt;template&lt;class...> class Tuple, template&lt;class...> class Tuple>
      using value_types = Variant&lt;Tuple&lt;Ts...>>;

      template&lt;template&lt;class...> class Variant>
      using error_types = Variant&lt;>;

      static const constexpr auto sends_done = false;

      template&lt;class R>
      struct operation_state {
        std::tuple&lt;Ts...> vs_;
        R r_;

        void tag_invoke(execution::start_t)
          noexcept(noexcept(
            execution::set_value(declval&lt;R>(), declval&lt;Ts>()...)
          )) {
          try {
            apply([&](Ts &... values_) {
              execution::set_value(move(r_), move(values_)...);
            }, vs_);
          }
          catch (...) {
            execution::set_error(move(r_), current_exception());
          }
        }
      };

      template&lt;receiver R>
        requires receiver_of&lt;R, Ts...> && (copyable&ltTs>... &&)
      auto tag_invoke(execution::connect_t, R && r) const & {
        return operation_state&lt;R>{ vs_, std::forward&lt;R>(r) };
      }

      template&lt;receiver R>
        requires receiver_of&lt;R, Ts...>
      auto tag_invoke(execution::connect_t, R && r) && {
        return operation_state&lt;R>{ std::move(vs_), std::forward&lt;R>(r) };
      }
    };

    template&lt;<i>moveable-value</i>... Ts>
      <i>just-sender</i>&lt;remove_cvref_t&lt;Ts>...> just(Ts &&... ts) noexcept(<i>see-below</i>);
    </pre>

1. <i>Effects</i>: Initializes `vs_` with `make_tuple(forward<Ts>(ts)...)`.

2. <i>Remarks</i>: The expression in the `noexcept-specifier` is equivalent to

    <pre highlight=c++>
    (is_nothrow_constructible_v&lt;remove_cvref_t&lt;Ts>, Ts> && ...)
    </pre>

#### Reschedule_just sender factory <b>[execution.sender.reschedule_just]</b> #### {#spec-execution.sender.reschedule_just}

1. `execution::reschedule_just` is used to create a sender that propagates a set of values to a connected receiver on an execution agent belonging to the associated execution context of a specified scheduler.

2. The name `execution::reschedule_just` denotes a customization point object. For some subexpressions `s` and `vs...`, let `S` be `decltype((s))` and `Vs...` be `decltype((vs))`. If `S` does not satisfy `execution::scheduler`, or any type `V` in `Vs` does not
    satisfy `<i>moveable-value</i>`, `execution::reschedule_just(s, vs...)` is ill-formed. Otherwise, `execution::reschedule_just(s, vs...)` is expression-equivalent to:

    1. `tag_invoke(execution::reschedule_just, s, vs...)`, if that expression is valid and its type satisfies `execution::typed_sender`. If the function selected by `tag_invoke` does not return a sender whose completion scheduler is equivalent to `s` and sends
        values equivalent to `vs...` to a receiver connected to it, the program is ill-formed with no diagnostic required.

    2. Otherwise, `execution::reschedule(execution::just(vs...), s)`.

### Sender adaptors <b>[execution.sender.adaptors]</b> ### {#spec-execution.sender.adaptors}

#### General <b>[execution.sender.adaptors.general]</b> #### {#spec-execution.sender.adaptors.general}

1. Subclause [execution.sender.adaptors] defines <i>sender adaptors</i>, which are utilities that transform one or more senders into a sender with custom behaviors. When they accept a single sender argument, they can be chained to create sender chains.

2. The bitwise OR operator is overloaded for the purpose of creating sender chains. The adaptors also support function call syntax with equivalent semantics.

3. Most sender adaptors have two versions, an <i>potentially eager version</i>, and a <i>strictly lazy</i> version. For such sender adaptors, <code><i>adaptor</i></code> is the potentially eager version, and <code>lazy&lowbar;<i>adaptor</i></code> is the strictly
    lazy version.

4. A strictly lazy version of a sender adaptor is required to not begin executing any functions which would observe or modify any of the arguments of the adaptor before the returned sender is connected with a receiver using `execution::connect`, and
    `execution::start` is called on the resulting operation state. This requirement applies to any function that is selected by the implementation of the sender adaptor.

5. Unless otherwise specified, all sender adaptors which accept a single `sender` argument return sender objects that propagate sender queries to that single sender argument. This requirement applies to any function that is selected by the implementation of the
    sender adaptor.

6. Unless otherwise specified, whenever a strictly lazy sender adaptor constructs a receiver it passes to another sender's connect, that receiver shall propagate receiver queries to a receiver accepted as an argument of `execution::connect`. This requirements
    applies to any sender returned from a function that is selected by the implementation of a strictly lazy sender adaptor.

#### Sender adaptor closure objects <b>[execution.sender.adaptor.objects]</b> #### {#spec-execution.sender.adaptor.objects}

1. A <i>pipeable sender adaptor closure object</i> is a function object that accepts one or more `sender` arguments and returns a `sender`. For a sender adaptor closure object `C` and an expression `S` such that `decltype((S))` models `sender`, the following
    expressions are equivalent and yield a `sender`:

    <pre highlight=c++>
    C(S)
    S | C
    </pre>

    Given an additional pipeable sender adaptor closure object `D`, the expression `C | D` is well-formed and produces another range adaptor closure object such that the following two expressions are equivalent:

    <pre highlight=c++>
    S | C | D
    S | (C | D)
    </pre>

2. A <i>pipeable sender adaptor object</i> is a customization point object that accepts a `sender` as its first argument and returns a `sender`.

3. If a pipeable sender adaptor object accepts only one argument, then it is a pipeable sender adaptor closure object.

4. If a pipeable sender adaptor object accepts more than one argument, then the following expressions are equivalent:

    <pre highlight=c++>
    <i>adaptor</i>(sender, args...)
    <i>adaptor</i>(args...)(sender)
    sender | <i>adaptor</i>(args...)
    </pre>

    In that case, <code><i>adaptor</i>(args...)</code> is a pipeable sender adaptor closure object.

#### On adaptor <b>[execution.sender.adaptors.on]</b> #### {#spec-execution.sender.adaptors.on}

1. `execution::on` and `execution::lazy_on` are used to adapt a sender in a sender that will start the input sender on an execution agent belonging to a specific execution context.

2. The name `execution::on` denotes a customization point object. For some subexpressions `sch` and `s`, let `Sch` be `decltype((sch))` and `S` be `decltype((s))`. If `Sch` does not satisfy `execution::scheduler`, or `S` does not satisfy `execution::sender`,
    `execution::on` is ill-formed. Otherwise, the expression `execution::on(sch, s)` is expression-equivalent to:

    1. `tag_invoke(execution::on, sch, s)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `lazy_on(sch, s)`.

    If the function selected above does not return a sender which starts `s` on an execution agent of the associated execution context of `sch`, the program is ill-formed with no diagnostic required.

3. The name `execution::lazy_on` denotes a customization point object. For some subexpressions `sch` and `s`, let `Sch` be `decltype((sch))` and `S` be `decltype((s))`. If `Sch` does not satisfy `execution::scheduler`, or `S` does not satisfy `execution::sender`,
    `execution::lazy_on` is ill-formed. Otherwise, the expression `execution::lazy_on(sch, s)` is expression-equivalent to:

    1. `tag_invoke(execution::lazy_on, sch, s)`, if that expression is valid and its type satisfies `execution::sender`. If the function selected above does not return a sender which starts `s` on an execution agent of the associated execution context of `sch` when
        started, the program is ill-formed with no diagnostic required.

    2. Otherwise, constructs a sender `s2`. When `s2` is connected with some receiver `out_r`, it results in an operation state `op_state`. When `execution::start` is called on `op_state`, it:

        1. Constructs a receiver `r`:

            2. When `execution::set_value(r)` is called, it calls `execution::connect(s, out_r)`, which results in `op_state2`. It calls `execution::start(op_state2)`. If any of these operations throws an exception, it calls `execution::set_error` on `out_r`,
                passing `current_exception()` as the second argument.

            3. When `execution::set_error(r, e)` is called, it calls `execution::set_error(out_r, e)`.

            4. When `execution::set_done(r)` is called, it calls `execution::set_done(out_r)`.

        2. Calls `execution::schedule(sch)`, which results in `s3`. It then calls `execution::connect(s3, r)`, resulting in `op_state3`, and then it calls `execution::start(op_state3)`. If any of these operation throws an exception, it catches it and calls
            `execution::set_error(out_r, current_exception())`.

4. Any receiver `r` created by an implementation of `on` and `lazy_on` shall implement the `get_scheduler` receiver query. The scheduler returned from the query for all such receivers should be equivalent to the `sch` argument passed into the `on` or `lazy_on` call.

#### Reschedule adaptor <b>[execution.sender.adaptors.reschedule]</b> #### {#spec-execution.sender.adaptors.reschedule}

1. `execution::reschedule` and `execution::lazy_reschedule` are used to adapt a sender into a sender with a different associated completion scheduler. [<i>Note</i>: it results in a transition between different execution contexts when executed. --<i>end note</i>]

2. The name `execution::reschedule` denotes a customization point object. For some subexpressions `sch` and `s`, let `Sch` be `decltype((sch))` and `S` be `decltype((s))`. If `Sch` does not satisfy `execution::scheduler`. or `S` does not satisfy `execution::sender`,
    `execution::reschedule` is ill-formed. Otherwise, the expression `execution::reschedule(s, sch)` is expression-equivalent to:

    1. `tag_invoke(execution::reschedule, get_completion_scheduler<set_value>(s), s, sch)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::reschedule, s, sch)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, `schedule_from(sch, s)`.

    If the function selected above does not return a sender which is a result of a call to `execution::schedule_from(sch, s2)`, where `s2` is a sender which sends equivalent to those sent by `s`, the program is ill-formed with no diagnostic required.

3. The name `execution::lazy_reschedule` denotes a customization point object. For some subexpressions `sch` and `s`, let `Sch` be `decltype((sch))` and `S` be `decltype((s))`. If `Sch` does not satisfy `execution::scheduler`. or `S` does not satisfy
    `execution::sender`, `execution::lazy_reschedule` is ill-formed. Otherwise, the expression `execution::lazy_reschedule(s, sch)` is expression-equivalent to:

    1. `tag_invoke(execution::lazy_reschedule, get_completion_scheduler<set_value>(s), s, sch)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::lazy_reschedule, s, sch)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, `lazy_schedule_from(sch, s)`.

    If the function selected above does not return a sender which is a result of a call to `execution::lazy_schedule_from(sch, s2)`, where `s2` is a sender which sends equivalent to those sent by `s`, the program is ill-formed with no diagnostic required.

4. Senders returned from `execution::reschedule` and `execution::lazy_reschedule` shall not propagate the sender queries `get_completion_scheduler<CPO>` to an input sender. They shall return a sender equivalent to the `sch` argument from those queries.

#### Schedule_from adaptor <b>[execution.sender.adaptors.schedule_from]</b> #### {#spec-execution.sender.adaptors.schedule_from}

1. `execution::schedule_from` and `execution::lazy_schedule_from` are used to schedule work dependent on the completion of a sender onto a scheduler's associated execution context. [<i>Note</i>: `schedule_from` and `lazy_schedule_from` are not meant to be used in
    user code; they are used in the implementation of `reschedule` and `lazy_reschedule`. -<i>end note</i>]

2. The name `execution::schedule_from` denotes a customization point object. For some subexpressions `sch` and `s`, let `Sch` be `decltype((sch))` and `S` be `decltype((s))`. If `Sch` does not satisfy `execution::scheduler`, or `S` does not satisfy
    `execution::typed_sender`, `execution::schedule_from` is ill-formed. Otherwise, the expression `execution::schedule_from(sch, s)` is expression-equivalent to:

    1. `tag_invoke(execution::schedule_from, sch, s)`, if that expression is valid and its type satisfies `execution::sender`. If the function selected by `tag_invoke` does not return a sender which completes on an execution agent belonging to the associated
        execution context of `sch` and sends signals equivalent to those sent by `s`, the program is ill-formed with no diagnostic required.

    2. Otherwise, `lazy_schedule_from(sch, s)`.

3. The name `execution::lazy_schedule_from` denotes a customization point object. For some subexpressions `sch` and `s`, let `Sch` be `decltype((sch))` and `S` be `decltype((s))`. If `Sch` does not satisfy `execution::scheduler`, or `S` does not satisfy
    `execution::typed_sender`, `execution::lazy_schedule_from` is ill-formed. Otherwise, the expression `execution::lazy_schedule_from(sch, s)` is expression-equivalent to:

    1. `tag_invoke(execution::lazy_schedule_from, sch, s)`, if that expression is valid and its type satisfies `execution::sender`. If the function selected by `tag_invoke` does not return a sender which completes on an execution agent belonging to the associated
        execution context of `sch` and sends signals equivalent to those sent by `s`, the program is ill-formed with no diagnostic required.

    2. Otherwise, constructs a sender `s2`. When `s2` is connected with some reciever `out_r`, it:

        1. Constructs a receiver `r`.

        2. Calls `execution::connect(s, r)`, which results in an operation state `op_state2`. If any of these operations throws an exception, calls `execution::set_error` on `out_r`, passing `current_exception()` as the second argument.

        3. When a receiver completion-signal <code><i>Signal</i>(r, args...)</code> is called, it constructs a receiver `r2`:

            1. When `execution::set_value(r2)` is called, it calls <code><i>Signal</i>(out_r, args...)</code>.

            2. When `execution::set_error(r2, e)` is called, it calls `execution::set_error(out_r, e)`.

            3. When `execution::done(r2)` is called, it calls `execution::set_done(out_r)`.

            It then calls `execution::schedule(sch)`, resulting in a sender `s3`. It then calls `execution::connect(s3, r2)`, resulting in an operation state `op_state3`. It then calls `execution::start(op_state3)`. If any of these operations throws an exception,
            it catches it and calls `execution::set_error(out_r, current_exception())`.

        3. Returns an operation state `op_state` that contains `op_state2`. When `execution::start(op_state)` is called, calls `execution::start(op_state2)`.

4. Senders returned from `execution::reschedule` and `execution::lazy_reschedule` shall not propagate the sender queries `get_completion_scheduler<CPO>` to an input sender. They shall return a scheduler equivalent to the `sch` argument from those queries.

#### Then adaptor <b>[execution.sender.adaptors.then]</b> #### {#spec-execution.sender.adaptor.then}

1. `execution::then` and `execution::lazy_then` are used to attach invocables as continuation for successful completion of the input sender.

2. The name `execution::then` denotes a customization point object. For some subexpressions `s` and `f`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::then` is ill-formed. Otherwise, the expression `execution::then(s, f)` is
    expression-equivalent to:

    1. `tag_invoke(execution::then, get_completion_scheduler<set_value>(s), s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::then, s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, `lazy_then(s, f)`.

    If the function selected above does not return a sender which invokes `f` with the result of the `set_value` signal of `s`, passing the return value as the value to any connected receivers, and propagates the other completion-signals sent by `s`, the program is
        ill-formed with no diagnostic required.

2. The name `execution::lazy_then` denotes a customization point object. For some subexpressions `s` and `f`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::lazy_then` is ill-formed. Otherwise, the expression
    `execution::lazy_then(s, f)` is expression-equivalent to:

    1. `tag_invoke(execution::lazy_then, get_completion_scheduler<set_value>(s), s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::lazy_then, s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, constructs a sender `s2`. When `s2` is connected with some receiver `out_r`, it:

        1. Constructs a receiver `r`:

            1. When `execution::set_value(r, args...)` is called, calls `invoke(f, args...)` and passes the result `v` to `execution::set_value(out_r, v)`. If any of these operations throws an exception, it catches it and calls
                `execution::set_error(out_r, current_exception())`.

            2. When `execution::set_error(r, e)` is called, calls `execution::set_error(out_r, e)`.

            3. When `execution::set_done(r)` is called, calls `execution::set_done(out_r)`.

        2. Calls `execution::connect(s, r)`, which results in an operation state `op_state2`.

        3. Returns an operation state `op_state` that contains `op_state2`. When `execution::start(op_state)` is called, calls `execution::start(op_state2)`.

    If the function selected above does not return a sender which invokes `f` with the result of the `set_value` signal of `s`, passing the return value as the value to any connected receivers, and propagates the other completion-signals sent by `s`, the program is
        ill-formed with no diagnostic required.

#### Upon_error adaptor <b>[execution.sender.adaptors.upon_error]</b> #### {#spec-execution.sender.adaptor.upon_error}

1. `execution::upon_error` and `execution::lazy_upon_error` are used to attach invocables as continuation for successful completion of the input sender.

2. The name `execution::upon_error` denotes a customization point object. For some subexpressions `s` and `f`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::upon_error` is ill-formed. Otherwise, the expression
    `execution::upon_error(s, f)` is expression-equivalent to:

    1. `tag_invoke(execution::upon_error, get_completion_scheduler<set_error>(s), s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::upon_error, s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, `lazy_upon_error(s, f)`.

    If the function selected above does not return a sender which invokes `f` with the result of the `set_error` signal of `s`, passing the return value as the value to any connected receivers, and propagates the other completion-signals sent by `s`, the program is
        ill-formed with no diagnostic required.

2. The name `execution::lazy_upon_error` denotes a customization point object. For some subexpressions `s` and `f`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::lazy_upon_error` is ill-formed. Otherwise, the expression
    `execution::lazy_upon_error(s, f)` is expression-equivalent to:

    1. `tag_invoke(execution::lazy_upon_error, get_completion_scheduler<set_error>(s), s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::lazy_upon_error, s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, constructs a sender `s2`. When `s2` is connected with some receiver `out_r`, it:

        1. Constructs a receiver `r`:

            1. When `execution::set_value(r, args...)` is called, calls `execution::set_value(out_r, args...)`.

            2. When `execution::set_error(r, e)` is called, calls `invoke(f, e)` and passes the result `v` to `execution::set_value(out_r, v)`. If any of these operations throws an exception, it catches it and calls
                `execution::set_error(out_r, current_exception())`.

            3. When `execution::set_done(r)` is called, calls `execution::set_done(out_r)`.

        2. Calls `execution::connect(s, r)`, which results in an operation state `op_state2`.

        3. Returns an operation state `op_state` that contains `op_state2`. When `execution::start(op_state)` is called, calls `execution::start(op_state2)`.

    If the function selected above does not return a sender which invokes `f` with the result of the `set_error` signal of `s`, passing the return value as the value to any connected receivers, and propagates the other completion-signals sent by `s`, the program is
        ill-formed with no diagnostic required.

#### Upon_done adaptor <b>[execution.sender.adaptors.upon_done]</b> #### {#spec-execution.sender.adaptor.upon_done}

1. `execution::upon_done` and `execution::lazy_upon_done` are used to attach invocables as continuation for successful completion of the input sender.

2. The name `execution::upon_done` denotes a customization point object. For some subexpressions `s` and `f`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::upon_done` is ill-formed. Otherwise, the expression
    `execution::upon_done(s, f)` is expression-equivalent to:

    1. `tag_invoke(execution::upon_done, get_completion_scheduler<set_done>(s), s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::upon_done, s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, `lazy_upon_done(s, f)`.

    If the function selected above does not return a sender which invokes `f` when the `set_done` signal of `s` is called, passing the return value as the value to any connected receivers, and propagates the other completion-signals sent by `s`, the program is
        ill-formed with no diagnostic required.

2. The name `execution::lazy_upon_done` denotes a customization point object. For some subexpressions `s` and `f`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::lazy_upon_done` is ill-formed. Otherwise, the expression
    `execution::lazy_upon_done(s, f)` is expression-equivalent to:

    1. `tag_invoke(execution::lazy_upon_done, get_completion_scheduler<set_done>(s), s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::lazy_upon_done, s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, constructs a sender `s2`. When `s2` is connected with some receiver `out_r`, it:

        1. Constructs a receiver `r`:

            1. When `execution::set_value(r, args...)` is called, calls `execution::set_value(out_r, args...)`.

            2. When `execution::set_error(r, e)` is called, calls `execution::set_error(out_r, e)`.

            3. When `execution::set_done(r)` is called, calls `invoke(f)` and passes the result `v` to `execution::set_value(out_r, v)`. If any of these operations throws an exception, it catches it and calls `execution::set_error(out_r, current_exception())`.

        2. Calls `execution::connect(s, r)`, which results in an operation state `op_state2`.

        3. Returns an operation state `op_state` that contains `op_state2`. When `execution::start(op_state)` is called, calls `execution::start(op_state2)`.

    If the function selected above does not return a sender which invokes `f` when the `set_done` signal of `s` is called, passing the return value as the value to any connected receivers, and propagates the other completion-signals sent by `s`, the program is
        ill-formed with no diagnostic required.

#### Let_value adaptor <b>[execution.sender.adaptors.let_value]</b> #### {#spec-execution.sender.adaptors.let_value}

1. `execution::let_value` and `execution::lazy_let_value` are used to insert continuations creating more work dependent on the results of their input senders into a sender chain.

2. The name `execution::let_value` denotes a customization point object. For some subexpressions `s` and `f`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::let_value` is ill-formed. Otherwise, the expression
    `execution::let_value(s, f)` is expression-equivalent to:

    1. `tag_invoke(execution::let_value, get_completion_scheduler<set_value>(s), s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::let_value, s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, `lazy_let_value(s, f)`.

    If the function selected above does not return a sender which invokes `f` when `set_value` is called, and making its completion dependent on the completion of a sender returned by `f`, and propagates the other completion-signals sent by `s`, the program is
        ill-formed with no diagnostic required.

2. The name `execution::lazy_let_value` denotes a customization point object. For some subexpressions `s` and `f`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::lazy_let_value` is ill-formed. Otherwise, the expression
    `execution::lazy_let_value(s, f)` is expression-equivalent to:

    1. `tag_invoke(execution::lazy_let_value, get_completion_scheduler<set_value>(s), s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::lazy_let_value, s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, constructs a sender `s2`. When `s2` is connected with some receiver `out_r`, it:

        1. Constructs a receiver `r`.

            1. When `execution::set_value(r, args...)` is called, copies `args...` into `op_state2` as `args2...`, then calls `invoke(f, args2...)`, resulting in a sender `s3`. It then calls `execution::connect(s3, out_r)`, resulting in an operation state
                `op_state3`. `op_state3` is saved as a part of `op_state2`. It then calls `execution:;start(op_state3)`. If any of these operations throws an exception, it catches it and calls `execution:;set_error(out_r, current_exception())`.

            2. When `execution::set_error(r, e)` is called, calls `execution:;set_error(out_r, e)`.

            3. When `execution:;set_done(r, e)` is called, calls `execution::set_done(out_r)`.

        2. Calls `execution::connect(s, r)`. which results in an operation state `op_state2`.

        3. Returns an operation state `op_state` that contains `op_state2`. When `execution::start(op_state)` is called, calls `execution::start(op_state2)`.

    If the function selected above does not return a sender which invokes `f` when `set_value` is called, and making its completion dependent on the completion of a sender returned by `f`, and propagates the other completion-signals sent by `s`, the program is
        ill-formed with no diagnostic required.

#### Let_error adaptor <b>[execution.sender.adaptors.let_error]</b> #### {#spec-execution.sender.adaptors.let_error}

1. `execution::let_error` and `execution::lazy_let_error` are used to insert continuations creating more work dependent on the results of their input senders into a sender chain.

2. The name `execution::let_error` denotes a customization point object. For some subexpressions `s` and `f`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::let_error` is ill-formed. Otherwise, the expression
    `execution::let_error(s, f)` is expression-equivalent to:

    1. `tag_invoke(execution::let_error, get_completion_scheduler<set_error>(s), s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::let_error, s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, `lazy_let_error(s, f)`.

    If the function selected above does not return a sender which invokes `f` when `set_error` is called, and making its completion dependent on the completion of a sender returned by `f`, and propagates the other completion-signals sent by `s`, the program is
        ill-formed with no diagnostic required.

2. The name `execution::lazy_let_error` denotes a customization point object. For some subexpressions `s` and `f`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::lazy_let_error` is ill-formed. Otherwise, the expression
    `execution::lazy_let_error(s, f)` is expression-equivalent to:

    1. `tag_invoke(execution::lazy_let_error, get_completion_scheduler<set_error>(s), s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::lazy_let_error, s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, constructs a sender `s2`. When `s2` is connected with some receiver `out_r`, it:

        1. Constructs a receiver `r`.

            1. When `execution::set_value(r, args...)` is called, calls `execution:;set_value(out_r, args...)`.

            2. When `execution::set_error(r, e)` is called, copies `e` into `op_statee2` as `e`, then calls `invoke(f, e)`, resulting in a sender `s3`. It then calls `execution::connect(s3, out_r)`, resulting in an operation state `op_state3`. `op_state3` is saved
                as a part of `op_state2`. It then calls `execution:;start(op_state3)`. If any of these operations throws an exception, it catches it and calls `execution:;set_error(out_r, current_exception())`.

            3. When `execution:;set_done(r, e)` is called, calls `execution::set_done(out_r)`.

        2. Calls `execution::connect(s, r)`. which results in an operation state `op_state2`.

        3. Returns an operation state `op_state` that contains `op_state2`. When `execution::start(op_state)` is called, calls `execution::start(op_state2)`.

    If the function selected above does not return a sender which invokes `f` when `set_error` is called, and making its completion dependent on the completion of a sender returned by `f`, and propagates the other completion-signals sent by `s`, the program is
        ill-formed with no diagnostic required.

#### Let_done adaptor <b>[execution.sender.adaptors.let_done]</b> #### {#spec-execution.sender.adaptors.let_done}

1. `execution::let_done` and `execution::lazy_let_done` are used to insert continuations creating more work dependent on the results of their input senders into a sender chain.

2. The name `execution::let_done` denotes a customization point object. For some subexpressions `s` and `f`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::let_done` is ill-formed. Otherwise, the expression
    `execution::let_done(s, f)` is expression-equivalent to:

    1. `tag_invoke(execution::let_done, get_completion_scheduler<set_done>(s), s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::let_done, s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, `lazy_let_done(s, f)`.

    If the function selected above does not return a sender which invokes `f` when `set_done` is called, and making its completion dependent on the completion of a sender returned by `f`, and propagates the other completion-signals sent by `s`, the program is
        ill-formed with no diagnostic required.

2. The name `execution::lazy_let_done` denotes a customization point object. For some subexpressions `s` and `f`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::lazy_let_done` is ill-formed. Otherwise, the expression
    `execution::lazy_let_done(s, f)` is expression-equivalent to:

    1. `tag_invoke(execution::lazy_let_done, get_completion_scheduler<set_done>(s), s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::lazy_let_done, s, f)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, constructs a sender `s2`. When `s2` is connected with some receiver `out_r`, it:

        1. Constructs a receiver `r`.

            1. When `execution:;set_value(r, args...)` is called, calls `execution::set_value(out_r, args...)`.

            2. When `execution::set_error(r, e)` is called, calls `execution:;set_error(out_r, e)`.

            3. When `execution::set_done(r)` is called, calls `invoke(f)`, resulting in a sender `s3`. It then calls `execution::connect(s3, out_r)`, resulting in an operation state `op_state3`. `op_state3` is saved as a part of `op_state2`.
                It then calls `execution:;start(op_state3)`. If any of these operations throws an exception, it catches it and calls `execution:;set_error(out_r, current_exception())`.

        2. Calls `execution::connect(s, r)`. which results in an operation state `op_state2`.

        3. Returns an operation state `op_state` that contains `op_state2`. When `execution::start(op_state)` is called, calls `execution::start(op_state2)`.

    If the function selected above does not return a sender which invokes `f` when `set_done` is called, and making its completion dependent on the completion of a sender returned by `f`, and propagates the other completion-signals sent by `s`, the program is
        ill-formed with no diagnostic required.

#### Bulk adaptor <b>[execution.sender.adaptors.bulk]</b> #### {#spec-execution.sender.adaptors.bulk}

1. `execution::bulk` and `execution::lazy_bulk` are used to run a task repeatedly for every index in an index space.

2. The name `execution::bulk` denotes a customization point object. For some subexpressions `s`, `shape`, and `f`, let `S` be `decltype((s))`, `Shape` be `decltype((shape))`, and `F` be `decltype((f))`. If `S` does not satisfy `execution::sender` or `Shape` does not
    satisfy `integral`, `execution::bulk` is ill-formed. Otherwise, the expression `execution::bulk(s, shape, f)` is expression-equivalent to:

    1. `tag_invoke(execution::bulk, get_completion_scheduler<set_value>(s), s, shape, f)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::bulk, s, shape, f)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, `lazy_bulk(s, shape, f)`.

2. The name `execution::lazy_bulk` denotes a customization point object. For some subexpressions `s`, `shape`, and `f`, let `S` be `decltype((s))`, `Shape` be `decltype((shape))`, and `F` be `decltype((f))`. If `S` does not satisfy `execution::sender` or `Shape`
    does not satisfy `integral`, `execution::bulk` is ill-formed. Otherwise, the expression `execution::bulk(s, shape, f)` is expression-equivalent to:

    1. `tag_invoke(execution::bulk, get_completion_scheduler<set_value>(s), s, shape, f)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::bulk, s, shape, f)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, constructs a sender `s2`. When `s2` is connected with some receiver `out_r`, it:

        1. Constructs a receiver `r`:

            1. When `execution::set_value(r, args...)` is called, calls `f(i, args...)` for each `i` of type `Shape` from `0` to `shape`, then calls `execution::set_value(out_r, args...)`. If any of these operations throws an exception, it catches it and calls
                `execution::set_error(out_r, current_exception())`.

            2. When `execution::set_error(r, e)` is called, calls `execution::set_error(out_r, e)`.

            3. When `execution::set_done(r, e)` is called, calls `execution::set_done(out_r, e)`.

        2. Calls `execution::connect(s, r)`, which results in an operation state `op_state2`.

        3. Returns an operation state `op_state` that contains `op_state2`. When `execution::start(op_state)` is called, calls `execution::start(op_state2)`.

    If the function selected above does not return a sender which invokes `f(i, args...)` for each `i` of type `Shape` from `0` to `shape` when the input sender sends values `args...`, or does not propagate the values of the signals sent by the input sender to
        a connected receiver, the program is ill-formed with no diagnostic required.

#### Split adaptor <b>[execution.sender.adaptors.split]</b> #### {#spec-execution.sender.adaptors.split}

1. `execution::split` and `execution::lazy_split` are used to adapt an arbitrary sender into a sender that can be connected multiple times.

2. The name `execution::split` denotes a customization point object. For some subexpression `s`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::typed_sender`, `execution::split` is ill-formed. Otherwise, the expression `execution::split(s)` is
    expression-equivalent to:

    1. `tag_invoke(execution::split, get_completion_scheduler<set_value>(s), s)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::split, s)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, `lazy_split(s)`.

    If the function selected above does not return a sender which sends references to values sent by `s`, propagating the other channels, the program is ill-formed with no diagnostic required.

2. The name `execution::lazy_split` denotes a customization point object. For some subexpression `s`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::typed_sender`, `execution::lazy_split` is ill-formed. Otherwise, the expression
    `execution::lazy_split(s)` is expression-equivalent to:

    1. `tag_invoke(execution::lazy_split, get_completion_scheduler<set_value>(s), s)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::lazy_split, s)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise, constructs a sender `s2`, which:

        1. Creates an object `sh_state`. The lifetime of `sh_state` shall last for at least as long as the lifetime of the last operation state object returned from `execution::connect(s, some_r)` for some receiver `some_r`.

        2. Constructs a receiver `r`:

            1. When `execution::set_value(r, args...)` is called, saves the expressions `args...` as subobjects of `sh_state`.

            2. When `execution::set_error(r, e)` is called, saves the expression `e` as a subobject of `sh_state`.

            3. When `execution::set_done(r)` is called, saves this fact in `sh_state`.

        3. Calls `execution::connect(s, r)`, resulting in an operation state `op_state2`. `op_state2` is saved as a subobject of `sh_state`.

        4. When `s2` is connected with a receiver `out_r`, it returns an operation state object `op_state`. When `execution::start(op_state)` is called, it calls `execution::start(op_state2)`, if this is the first time this expression would be evaluated. When both
            `execution::start(op_state)` and <code><i>Signal</i>(r, args...)</code> have been called, calls <code><i>Signal</i>(out_r, args2...)</code>, where `args2...` is a pack of lvalues referencing the subobjects of `sh_state` that have been saved by the
            original call to <code><i>Signal</i>(r, args...)</code>.

    If the function selected above does not return a sender which sends references to values sent by `s`, propagating the other channels, the program is ill-formed with no diagnostic required.

#### When_all adaptor <b>[execution.sender.adaptors.when_all]</b> #### {#spec-execution.sender.adaptor.when_all}

1. `execution::when_all` is used to join multiple sender chains and create a sender whose execution is dependent on all of the input senders that only send a single set of values. `execution::when_all_with_variant`
    is used to join multiple sender chains and create a sender whose execution is dependent on all of the input senders, which may have one or more sets of sent values.

2. The name `execution::when_all` denotes a customization point object. For some subexpressions `s...`, let `S` be `decltype((s))`. If any type <code>S<i><sub>i</sub></i></code> in `S...` does not satisfy `execution::typed_sender`, or the number of the arguments
    <code>sender_traits&lt;S<i><sub>i</sub></i>>::value_types</code> passes into the `Variant` template parameter is not 1, `execution::when_all` is ill-formed. Otherwise, the expression `execution::when_all(s...)` is expression-equivalent to:

    1. `tag_invoke(execution::when_all, s...)`, if that expression is valid and its type satisfies `execution::sender`. If the function selected by `tag_invoke` does not return a sender which sends a concatenation of values sent by `s...` when they all complete with
        `set_value`, the program is ill-formed with no diagnostic required.

    2. Otherwise, constructs a sender `s`. When `s` is connected with some receiver `out_r`, it:

        1. For each sender <code>s<i><sub>i</sub></i></code> in `s...`, constructs a receiver <code>r<sub><i>i</i></sub></code>:

            2. If <code>execution::set_value(r<sub><i>i</i></sub>, t<sub><i>i</i></sub>...)</code> is called for every <code>r<sub><i>i</i></sub></code>,
                <code>execution::set_value(out_r, t<sub><i>0</i></sub>..., t<sub><i>1</i></sub>..., ..., t<sub><i>n</i></sub>...)</code> is called, where `n` is `sizeof...(s) - 1`.

            2. Otherwise, if <code>execution::set_error(r<sub><i>i</i></sub>, e)</code> is called for any <code>r<sub><i>i</i></sub></code>, `execution::set_error(out_r, e)` is called.

            3. Otherwise, if <code>execution::set_done(r<sub><i>i</i></sub>)</code> is called for any <code>r<sub><i>i</i></sub></code>, `execution::set_done(out_r)` is called.

        3. For each sender <code>s<i><sub>i</sub></i></code> in `s...`, calls <code>execution::connect(s<sub><i>i</i></sub>, r<sub><i>i</i></sub>)</code>, resulting in operation states <code>op_state<sub><i>i</i></sub></code>.

        4. Returns an operation state `op_state` that contains each operation state <code>op_state<sub><i>i</i></sub></code>. When `execution::start(op_state)` is called, calls <code>execution::start(op_state<sub><i>i</i></sub>)</code> for each
            <code>op_state<sub><i>i</i></sub></code>.

3. The name `execution::when_all_with_variant` denotes a customization point object. For some subexpressions `s...`, let `S` be `decltype((s))`. If any type <code>S<i><sub>i</sub></i></code> in `S...` does not satisfy `execution::typed_sender`,
    `execution::when_all_with_variant` is ill-formed. Otherwise, the expression `execution::when_all_with_variant(s...)` is expression-equivalent to:

    1. `tag_invoke(execution::when_all_with_variant, s...)`, if that expression is valid and its type satisfies `execution::sender`. If the function selected by `tag_invoke` does not return a sender which sends the types
        <code><i>into-variant-type</i>&lt;S>...</code> when they all complete with `set_value`, the program is ill-formed with no diagnostic required.

    2. Otherwise, `execution::when_all(execution::into_variant(s)...)`.

4. Adaptors defined in this subclause are strictly lazy.

5. Senders returned from adaptors defined in this subclause shall not expose the sender queries `get_completion_scheduler<CPO>`.

7. `tag_invoke` expressions used in the definitions of the sender adaptors in this subclause shall not consider member functions of their first non-tag arguments.

#### Reschedule_when_all adaptor <b>[execution.sender.adaptors.reschedule_when_all]</b> #### {#spec-execution.sender.adaptor.reschedule_when_all}

1. `execution::reschedule_when_all` and `execution::lazy_reschedule_when_all` are used to join multiple sender chains and create a sender whose execution is dependent on all of the input senders that only send a single set of values each, while also making sure
    that they complete on the specified scheduler. `execution::reschedule_when_all_with_variant` and `execution::lazy_reschedule_when_all_with_variant` are used to join multiple sender chains and create a sender whose execution is dependent on all of the input
    senders, which may have one or more sets of sent values. [<i>Note:</i> this can allow for better customization of the algorithm. --<i>end note</i>]

2. The name `execution::reschedule_when_all` denotes a customization point object. For some subexpressions `sch` and `s...`, let `Sch` be `decltype(sch)` and `S` be `decltype((s))`. If `Sch` does not satisfy `scheduler`, or any type <code>S<i><sub>i</sub></i></code>
    in `S...` does not satisfy `execution::typed_sender`,  or the number of the arguments <code>sender_traits&lt;S<i><sub>i</sub></i>>::value_types</code> passes into the `Variant` template parameter is not 1 `execution::reschedule_when_all` is ill-formed.
    Otherwise, the expression `execution::reschedule_when_all(sch, s...)` is expression-equivalent to:

    1. `tag_invoke(execution::reschedule_when_all, sch, s...)`, if that expression is valid and its type satisfies `execution::sender`. If the function selected by `tag_invoke` does not return a sender which sends a concatenation of values sent by `s...` when they
        all complete with `set_value`, or does not send its completion signals, other than ones resulting from a scheduling error, on an execution agent belonging to the associated execution context of `sch`, the program is ill-formed with no diagnostic required.

    2. Otherwise, `reschedule(when_all(s...), sch)`.

3. The name `execution::lazy_reschedule_when_all` denotes a customization point object. For some subexpressions `sch` and `s...`, let `Sch` be `decltype(sch)` and `S` be `decltype((s))`. If `Sch` does not satisfy `scheduler`, or any type
    <code>S<i><sub>i</sub></i></code> in `S...` does not satisfy `execution::typed_sender`, or the number of the arguments <code>sender_traits&lt;S<i><sub>i</sub></i>>::value_types</code> passes into the `Variant` template parameter is not 1,
    `execution::lazy_reschedule_when_all` is ill-formed. Otherwise, the expression `execution::lazy_reschedule_when_all(sch, s...)` is expression-equivalent to:

    1. `tag_invoke(execution::lazy_reschedule_when_all, sch, s...)`, if that expression is valid and its type satisfies `execution::sender`. If the function selected by `tag_invoke` does not return a sender which sends a concatenation of values sent by `s...` when
        they all complete with `set_value`, or does not send its completion signals, other than ones resulting from a scheduling error, on an execution agent belonging to the associated execution context of `sch`, the program is ill-formed with no diagnostic
        required.

    2. Otherwise, `lazy_reschedule(when_all(s...), sch)`.

4. The name `execution::reschedule_when_all_with_variant` denotes a customization point object. For some subexpressions `s...`, let `S` be `decltype((s))`. If any type <code>S<i><sub>i</sub></i></code> in `S...` does not satisfy `execution::typed_sender`,
    `execution::reschedule_when_all_with_variant` is ill-formed. Otherwise, the expression `execution::reschedule_when_all_with_variant(s...)` is expression-equivalent to:

    1. `tag_invoke(execution::reschedule_when_all_with_variant, s...)`, if that expression is valid and its type satisfies `execution::sender`. If the function selected by `tag_invoke` does not return a sender which sends the types
        <code><i>into-variant-type</i>&lt;S>...</code> when they all complete with `set_value`, the program is ill-formed with no diagnostic required.

    2. Otherwise, `execution::reschedule_when_all(sch, execution::into_variant(s)...)`.

5. The name `execution::lazy_reschedule_when_all_with_variant` denotes a customization point object. For some subexpressions `s...`, let `S` be `decltype((s))`. If any type <code>S<i><sub>i</sub></i></code> in `S...` does not satisfy `execution::typed_sender`,
    `execution::lazy_reschedule_when_all_with_variant` is ill-formed. Otherwise, the expression `execution::lazy_reschedule_when_all_with_variant(s...)` is expression-equivalent to:

    1. `tag_invoke(execution::lazy_reschedule_when_all_with_variant, s...)`, if that expression is valid and its type satisfies `execution::sender`. If the function selected by `tag_invoke` does not return a sender which sends the types
        <code><i>into-variant-type</i>&lt;S>...</code> when they all complete with `set_value`, the program is ill-formed with no diagnostic required.

    2. Otherwise, `execution::lazy_reschedule_when_all(sch, execution::into_variant(s)...)`.

4. Senders returned from `execution::reschedule_when_all` and `execution::lazy_reschedule_when_all` shall not propagate the sender queries `get_completion_scheduler<CPO>` to input senders. They shall return a scheduler equivalent to the `sch` argument from
    those queries.

#### Into_variant adaptor <b>[execution.sender.adaptors.into_variant]</b> #### {#spec-execution.sender.adaptors.into_variant}

1. `execution::into_variant` can be used to turn a typed sender which sends multiple sets of values into a sender which sends a variant of all of those sets of values.

2. The template <code><i>into-variant-type</i></code> is used to compute the type sent by a sender returned from `execution::into_variant`.

    <pre highlight=c++>
        template&lt;typed_sender S>
          using <i>into-with-variant-type</i> =
            typename execution::sender_traits&lt;remove_cvref_t&lt;S>>
              ::template value_types&lt;tuple, variant>;

        template&lt;typed_sender S>
          <i>see-below</i> into_variant(S && s);
    </pre>

3. <i>Effects:</i> Returns a sender `s2`. When `s2` is connected with some receiver `out_r`, it:

    1. Constructs a receiver `r`:

        1. If `execution::set_value(r, ts...)` is called, calls <code>execution:;set_value(out_r, <i>into-variant-type</i>&lt;S>(make_tuple(ts...)))</code>.

        2. If `execution::set_error(r, e)` is called, calls `execution:;set_error(out_r, e)`.

        3. If `execution::set_done(r)` is called, calls `execution::set_done(out_r)`.

    2. Calls `execution::connect(s, r)`, resulting in an operation state `op_state2`.

    3. Returns an operation state `op_state` that contains `op_state2`. When `execution::start(op_state)` is called, calls `execution::start(op_state2)`.

#### Unschedule adaptor <b>[execution.sender.adaptors.unschedule]</b> #### {#spec-execution.sender.adaptors.unschedule}

1. `execution::unschedule` can be used to remove the information about completion schedulers from a sender, in effect removing any scheduler-specific customizations of sender algorithms from that sender.

    <pre highlight=c++>
        template&lt;sender S>
          <i>see-below</i> unschedule(S && s) noexcept(<i>see-below</i>);
    </pre>

2. <i>Effects:</i> If `S` provides none of the `get_completion_scheduler<CPO>` sender queries, returns `std::forward<S>(s)`. Otherwise. returns a sender adaptor `s2` containing a subobject of type `remove_cvref_t<S>`, initialized with `std::forward<S>(s)`. `s2`
    propagates all customizations, except for `get_completion_scheduler<CPO>`, to `s`.

3. <i>Remarks:</i> The expression in the `noexcept-specifier` is equivalent to

    <pre highlight=c++>
        is_nothrow_constructible_v&lt;remove_cvref_t&lt;S>, S>
    </pre>

#### Ensure_started adaptor <b>[execution.sender.adaptors.ensure_started]</b> #### {#spec-execution.sender.adaptors.unschedule}

1. `execution::ensure_started` is used to eagerly start the execution of a sender, while also providing a way to attach further work to execute once it has completed.

2. The name `execution::ensure_started` denotes a customization point object. For some subexpression `s`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::typed_sender`, `execution::ensure_started` is ill-formed. Otherwise, the expression
    `execution::ensure_started(s)` is expression-equivalent to:

    1. `tag_invoke(execution::ensure_started, get_completion_scheduler<set_value>(s), s)`, if that expression is valid and its type satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::ensure_started, s)`, if that expression is valid and its type satisfies `execution::sender`.

    3. Otherwise:

        1. Constructs a receiver `r`.

        2. Calls `execution::connect(s, r)`, resulting in operation state `op_state`, and then calls `execution::start(op_state)`. If any of these operations throws an exception, it catches it and calls `execution::set_error(r, current_exception())`.

        3. Constructs a sender `s2`. When `s2` is connected with some receiver `out_r`, it results in an operation state `op_state2`. Once both `execution::start(op_state2)` and one of the receiver completion-signals has been called on `r`:

            1. If `execution::set_value(r, ts...)` has been called, calls `execution::set_value(out_r, ts...)`.

            2. If `execution::set_error(r, e)` has been called, calls `execution::set_error(out_r, e)`.

            3. If `execution::set_done(r)` has been called, calls `execution::set_done(out_r)`.

    If the function selected above does not eagerly start the sender `s` and return a sender which propagates the signals sent by `s` once started, the program is ill-formed with no diagnostic required.

### Sender algorithms <b>[execution.sender.algorithms]</b> ### {#spec-execution.sender.algorithms}

#### Start_detached algorithm <b>[execution.sender.algorithms.start_detached]</b> #### {#spec-execution.sender.algorithms.start_detached}

1. `execution::start_detached` is used to eagerly start a sender without the caller needing to manage the lifetimes of any objects.

2. The name `execution::start_detached` denotes a customization point object. For some subexpression `s`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::start_detached` is ill-formed. Otherwise, the expression
    `execution::start_detached(s)` is expression-equivalent to:

    1. `tag_invoke(execution::start_detached, get_completion_scheduler(s), s)`, if that expression is valid and its type is `void`.

    2. Otherwise, `tag_invoke(execution::start_detached, s)`, if that expression is valid and its type is `void`.

    3. Otherwise:

        1. Constructs a receiver `r`:

            1. When `set_value(r, ts...)` is called, it does nothing.

            2. When `set_error(r, e)` is called, it calls `std::terminate()`.

            3. When `set_done(r)` is called, it does nothing.

        2. Calls `execution::connect(s, r)`, resulting in an operation state `op_state`, then calls `execution::start(op_state)`.

    If the function selected above does not eagerly start the sender `s` after connecting it with a receiver which ignores the `set_value` and `set_done` signals and calls `std::terminate()` on the `set_error` signal, the program is ill-formed with no diagnostic
        required.

#### Sync_wait algorithm <b>[execution.sender.algorithms.sync_wait]</b> #### {#spec-execution.sender.algorithms.sync_wait}

1. `this_thread::sync_wait` and `this_thread::sync_wait_with_variant` are used to block a current thread until a sender passed into it as an argument has completed, and to obtain the values (if any) it completed with.

2. The templates <code><i>sync-wait-type</i></code> and <code><i>sync-wait-with-variant-type</i></code> are used to determine the return types of `this_thread::sync_wait` and `this_thread::sync_wait_with_variant`.

    <pre highlight=c++>
        template&lt;typed_sender S>
          using <i>sync-wait-type</i> = optional&lt;
            typename execution::sender_traits&lt;remove_cvref_t&lt;S>>
              ::template value_types&lt;tuple, type_identity>>;

        template&lt;typed_sender S>
          using <i>sync-wait-with-variant-type</i> = optional<<i>into-variant-type</i>&lt;S>>;
    </pre>

3. The name `this_thread::sync_wait` denotes a customization point object. For some subexpression `s`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::typed_sender`, or the number of the arguments `sender_traits<S>::value_types` passes into the
    `Variant` template parameter is not 1, `this_thread::sync_wait` is ill-formed. Otherwise, `this_thread::sync_wait` is expression-equivalent to:

    1. `tag_invoke(this_thread::sync_wait, get_completion_scheduler(s), s)`, if this expression is valid and its type is <code><i>sync-wait-type</i>&lt;S></code>.

    2. Otherwise, `tag_invoke(this_thread::sync_wait, s)`, if this expression is valid and its type is <code><i>sync-wait-type</i>&lt;S></code>.

    3. Otherwise:

        1. Constructs a receiver `r`.

        2. Calls `execution::connect(s, r)`, resulting in an operation state `op_state`, then calls `execution::start(op_state)`.

        3. Blocks the current thread until a receiver completion-signal of `r` is called. When it is:

            1. If `execution::set_value(r, ts...)` has been called, returns <code><i>sync-wait-type</i>&lt;S>(make_tuple(ts...))></code>.

            2. If `execution::set_error(r, e...)` has been called, if `remove_cvref_t(decltype(e))` is `exception_ptr`, calls `std::rethrow_exception(e)`. Otherwise, throws `e`.

            3. If `execution::set_done(r)` has been called, returns <code><i>sync-wait-type</i>&lt;S(nullopt)></code>.

3. The name `this_thread::sync_wait_with_variant` denotes a customization point object. For some subexpression `s`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::typed_sender`, `this_thread::sync_wait_with_variant` is ill-formed. Otherwise,
    `this_thread::sync_wait_with_variant` is expression-equivalent to:

    1. `tag_invoke(this_thread::sync_wait_with_variant, get_completion_scheduler(s), s)`, if this expression is valid and its type is <code><i>sync-wait-with-variant-type</i>&lt;S></code>.

    2. Otherwise, `tag_invoke(this_thread::sync_wait_with_variant, s)`, if this expression is valid and its type is <code><i>sync-wait-with-variant-type</i>&lt;S></code>.

    3. Otherwise, `execution::sync_wait(execution::into_variant(s))`.

4. Any receiver `r` created by an implementation of `sync_wait` and `sync_wait_with_variant` shall implement the `get_scheduler` receiver query. The scheduler returned from the query for the receiver created by the default implementation shall return an
    implementation-defined scheduler that is driven by the waiting thread, such that scheduled tasks run on the thread of the caller.

## One-way execution <b>[execution.execute]</b> ## {#spec-execution.execute}

1. `execution::execute` is used to create fire-and-forget tasks on a specified scheduler.

2. The name `execution::execute` denotes a customization point object. For some subexpressions `sch` and `f`, let `Sch` be `decltype((sch))` and `F` be `decltype((f))`. If `Sch` does not satisfy `execution::scheduler` or `F` does not satisfy `invocable<>`,
    `execution::execute` is ill-formed. Otherwise, `execution::execute` is expression-equivalent to:

    1. `tag_invoke(execution::execute, sch, f)`, if that expression is valid and its type is `void`. If the function selected by `tag_invoke` does not invoke the function `f` on an execution agent belonging to the associated execution context of `sch`, or if it
        does not call `std::terminate()` if an error occurs after control is returned to the caller, the program is ill-formed with no diagnostic required.

    2. Otherwise, `execution::start_detached(execution::then(execution::schedule(sch), f))`.
