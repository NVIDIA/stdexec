<pre class='metadata'>
Title: `std::execution`
H1: <code>std::execution</code>
Shortname: D2300
Revision: 6
Status: D
Group: WG21
Audience: SG1, LEWG
Editor: Michał Dominiak, griwes@griwes.info
Editor: Georgy Evtushenko, evtushenko.georgy@gmail.com
Editor: Lewis Baker, lewissbaker@gmail.com
Editor: Lucian Radu Teodorescu, lucteo@lucteo.ro
Editor: Lee Howes, xrikcus@gmail.com
Editor: Kirk Shoop, kirk.shoop@gmail.com
Editor: Michael Garland, mgarland@nvidia.com
Editor: Eric Niebler, eric.niebler@gmail.com
Editor: Bryce Adelstein Lelbach, brycelelbach@gmail.com
URL: https://wg21.link/P2300
!Source: <a href="https://github.com/brycelelbach/wg21_p2300_std_execution/blob/main/std_execution.bs">GitHub</a>
Issue Tracking: GitHub https://github.com/brycelelbach/wg21_p2300_std_execution/issues
Metadata Order: Editor, This Version, Source, Issue Tracking, Project, Audience
Markup Shorthands: markdown yes
Toggle Diffs: no
No Abstract: yes
Default Biblio Display: inline
</pre>

<style>
pre {
  margin-top: 0px;
  margin-bottom: 0px;
}
table, th, tr, td {
  border: 2px solid black !important;
}
@media (prefers-color-scheme: dark) {
  table, th, tr, td {
    border: 2px solid white !important;
  }
}
.ins, ins, ins *, span.ins, span.ins * {
  background-color: rgb(200, 250, 200);
  color: rgb(0, 136, 0);
  text-decoration: none;
}
.del, del, del *, span.del, span.del * {
  background-color: rgb(250, 200, 200);
  color: rgb(255, 0, 0);
  text-decoration: line-through;
  text-decoration-color: rgb(255, 0, 0);
}
math, span.math {
  font-family: serif;
  font-style: italic;
}
ul {
  list-style-type: "— ";
}
blockquote {
  counter-reset: paragraph;
}
div.numbered, div.newnumbered {
  margin-left: 2em;
  margin-top: 1em;
  margin-bottom: 1em;
}
div.numbered:before, div.newnumbered:before {
  position: absolute;
  margin-left: -2em;
  display-style: block;
}
div.numbered:before {
  content: counter(paragraph);
  counter-increment: paragraph;
}
div.newnumbered:before {
  content: "�";
}
div.numbered ul, div.newnumbered ul {
  counter-reset: list_item;
}
div.numbered li, div.newnumbered li {
  margin-left: 3em;
}
div.numbered li:before, div.newnumbered li:before {
  position: absolute;
  margin-left: -4.8em;
  display-style: block;
}
div.numbered li:before {
  content: "(" counter(paragraph) "." counter(list_item) ")";
  counter-increment: list_item;
}
div.newnumbered li:before {
  content: "(�." counter(list_item) ")";
  counter-increment: list_item;
}
</style>

# Introduction # {#intro}

This paper proposes a self-contained design for a Standard C++ framework for managing asynchronous execution on generic execution contexts. It is based on the ideas in [[P0443R14]] and its companion papers.

## Motivation ## {#motivation}

Today, C++ software is increasingly asynchronous and parallel, a trend that is likely to only continue going forward.
Asynchrony and parallelism appears everywhere, from processor hardware interfaces, to networking, to file I/O, to GUIs, to accelerators.
Every C++ domain and every platform needs to deal with asynchrony and parallelism, from scientific computing to video games to financial services, from the smallest mobile devices to your laptop to GPUs in the world's fastest supercomputer.

While the C++ Standard Library has a rich set of concurrency primitives (`std::atomic`, `std::mutex`, `std::counting_semaphore`, etc) and lower level building blocks (`std::thread`, etc), we lack a Standard vocabulary and framework for asynchrony and parallelism that C++ programmers desperately need.
`std::async`/`std::future`/`std::promise`, C++11's intended exposure for asynchrony, is inefficient, hard to use correctly, and severely lacking in genericity, making it unusable in many contexts.
We introduced parallel algorithms to the C++ Standard Library in C++17, and while they are an excellent start, they are all inherently synchronous and not composable.

This paper proposes a Standard C++ model for asynchrony, based around three key abstractions: schedulers, senders, and receivers, and a set of customizable asynchronous algorithms.

## Priorities ## {#priorities}

* Be composable and generic, allowing users to write code that can be used with many different types of execution contexts.
* Encapsulate common asynchronous patterns in customizable and reusable algorithms, so users don't have to invent things themselves.
* Make it easy to be correct by construction.
* Support the diversity of execution contexts and execution agents, because not all execution agents are created equal; some are less capable than others, but not less important.
* Allow everything to be customized by an execution context, including transfer to other execution contexts, but don't require that execution contexts customize everything.
* Care about all reasonable use cases, domains and platforms.
* Errors must be propagated, but error handling must not present a burden.
* Support cancellation, which is not an error.
* Have clear and concise answers for where things execute.
* Be able to manage and terminate the lifetimes of objects asynchronously.

## Examples: End User ## {#example-end-user}

In this section we demonstrate the end-user experience of asynchronous programming directly with the sender algorithms presented in this paper. See [[#design-sender-factories]], [[#design-sender-adaptors]], and [[#design-sender-consumers]] for short explanations of the algorithms used in these code examples.

### Hello world ### {#example-hello-world}

```c++
using namespace std::execution;

scheduler auto sch = thread_pool.scheduler();                                 // 1

sender auto begin = schedule(sch);                                            // 2
sender auto hi = then(begin, []{                                              // 3
    std::cout << "Hello world! Have an int.";                                 // 3
    return 13;                                                                // 3
});                                                                           // 3
sender auto add_42 = then(hi, [](int arg) { return arg + 42; });              // 4

auto [i] = this_thread::sync_wait(add_42).value();                            // 5
```

This example demonstrates the basics of schedulers, senders, and receivers:

1. First we need to get a scheduler from somewhere, such as a thread pool. A scheduler is a lightweight handle to an execution resource.
2. To start a chain of work on a scheduler, we call [[#design-sender-factory-schedule]], which returns a sender that completes on the scheduler. A sender describes asynchronous work and sends a signal (value, error, or stopped) to some recipient(s) when that work completes.
3. We use sender algorithms to produce senders and compose asynchronous work. [[#design-sender-adaptor-then]] is a sender adaptor that takes an input sender and a `std::invocable`, and calls the `std::invocable` on the signal sent by the input sender. The sender returned by `then` sends the result of that invocation. In this case, the input sender came from `schedule`, so its `void`, meaning it won't send us a value, so our `std::invocable` takes no parameters. But we return an `int`, which will be sent to the next recipient.
4. Now, we add another operation to the chain, again using [[#design-sender-adaptor-then]]. This time, we get sent a value - the `int` from the previous step. We add `42` to it, and then return the result.
5. Finally, we're ready to submit the entire asynchronous pipeline and wait for its completion. Everything up until this point has been completely asynchronous; the work may not have even started yet. To ensure the work has started and then block pending its completion, we use [[#design-sender-consumer-sync_wait]], which will either return a `std::optional<std::tuple<...>>` with the value sent by the last sender, or an empty `std::optional` if the last sender sent a stopped signal, or it throws an exception if the last sender sent an error.

### Asynchronous inclusive scan ### {#example-async-inclusive-scan}

```c++
using namespace std::execution;

sender auto async_inclusive_scan(scheduler auto sch,                          // 2
                                 std::span<const double> input,               // 1
                                 std::span<double> output,                    // 1
                                 double init,                                 // 1
                                 std::size_t tile_count)                      // 3
{
  std::size_t const tile_size = (input.size() + tile_count - 1) / tile_count;

  std::vector<double> partials(tile_count + 1);                               // 4
  partials[0] = init;                                                         // 4

  return transfer_just(sch, std::move(partials))                              // 5
       | bulk(tile_count,                                                     // 6
           [=](std::size_t i, std::vector<double>& partials) {                // 7
             auto start = i * tile_size;                                      // 8
             auto end   = std::min(input.size(), (i + 1) * tile_size);        // 8
             partials[i + 1] = *--std::inclusive_scan(begin(input) + start,   // 9
                                                      begin(input) + end,     // 9
                                                      begin(output) + start); // 9
           })                                                                 // 10
       | then(                                                                // 11
           [](std::vector<double>&& partials) {
             std::inclusive_scan(begin(partials), end(partials),              // 12
                                 begin(partials));                            // 12
             return std::move(partials);                                      // 13
           })
       | bulk(tile_count,                                                     // 14
           [=](std::size_t i, std::vector<double>& partials) {                // 14
             auto start = i * tile_size;                                      // 14
             auto end   = std::min(input.size(), (i + 1) * tile_size);        // 14
             std::for_each(begin(output) + start, begin(output) + end,        // 14
               [&] (double& e) { e = partials[i] + e; }                       // 14
             );
           })
       | then(                                                                // 15
           [=](std::vector<double>&& partials) {                              // 15
             return output;                                                   // 15
           });                                                                // 15
}
```

This example builds an asynchronous computation of an inclusive scan:

1. It scans a sequence of `double`s (represented as the `std::span<const double>` `input`) and stores the result in another sequence of `double`s (represented as `std::span<double>` `output`).
2. It takes a scheduler, which specifies what execution context the scan should be launched on.
3. It also takes a `tile_count` parameter that controls the number of execution agents that will be spawned.
4. First we need to allocate temporary storage needed for the algorithm, which we'll do with a `std::vector`, `partials`. We need one `double` of temporary storage for each execution agent we create.
5. Next we'll create our initial sender with [[#design-sender-factory-transfer_just]]. This sender will send the temporary storage, which we've moved into the sender. The sender has a completion scheduler of `sch`, which means the next item in the chain will use `sch`.
6. Senders and sender adaptors support composition via `operator|`, similar to C++ ranges. We'll use `operator|` to attach the next piece of work, which will spawn `tile_count` execution agents using [[#design-sender-adaptor-bulk]] (see [[#design-pipeable]] for details).
7. Each agent will call a `std::invocable`, passing it two arguments. The first is the agent's index (`i`) in the [[#design-sender-adaptor-bulk]] operation, in this case a unique integer in `[0, tile_count)`. The second argument is what the input sender sent - the temporary storage.
8. We start by computing the start and end of the range of input and output elements that this agent is responsible for, based on our agent index.
9. Then we do a sequential `std::inclusive_scan` over our elements. We store the scan result for our last element, which is the sum of all of our elements, in our temporary storage `partials`.
10. After all computation in that initial [[#design-sender-adaptor-bulk]] pass has completed, every one of the spawned execution agents will have written the sum of its elements into its slot in `partials`.
11. Now we need to scan all of the values in `partials`. We'll do that with a single execution agent which will execute after the [[#design-sender-adaptor-bulk]] completes. We create that execution agent with [[#design-sender-adaptor-then]].
12. [[#design-sender-adaptor-then]] takes an input sender and an `std::invocable` and calls the `std::invocable` with the value sent by the input sender. Inside our `std::invocable`, we call `std::inclusive_scan` on `partials`, which the input senders will send to us.
13. Then we return `partials`, which the next phase will need.
14. Finally we do another [[#design-sender-adaptor-bulk]] of the same shape as before. In this [[#design-sender-adaptor-bulk]], we will use the scanned values in `partials` to integrate the sums from other tiles into our elements, completing the inclusive scan.
15. `async_inclusive_scan` returns a sender that sends the output `std::span<double>`. A consumer of the algorithm can chain additional work that uses the scan result. At the point at which `async_inclusive_scan` returns, the computation may not have completed. In fact, it may not have even started.

### Asynchronous dynamically-sized read ### {#example-async-dynamically-sized-read}

```c++
using namespace std::execution;

sender_of<std::size_t> auto async_read(                                       // 1
    sender_of<std::span<std::byte>> auto buffer,                              // 1
    auto handle);                                                             // 1

struct dynamic_buffer {                                                       // 3
  std::unique_ptr<std::byte[]> data;                                          // 3
  std::size_t size;                                                           // 3
};                                                                            // 3

sender_of<dynamic_buffer> auto async_read_array(auto handle) {                // 2
  return just(dynamic_buffer{})                                               // 4
       | let_value([handle] (dynamic_buffer& buf) {                           // 5
           return just(std::as_writeable_bytes(std::span(&buf.size, 1))       // 6
                | async_read(handle)                                          // 7
                | then(                                                       // 8
                    [&buf] (std::size_t bytes_read) {                         // 9
                      assert(bytes_read == sizeof(buf.size));                 // 10
                      buf.data = std::make_unique<std::byte[]>(buf.size);     // 11
                      return std::span(buf.data.get(), buf.size);             // 12
                    })
                | async_read(handle)                                          // 13
                | then(
                    [&buf] (std::size_t bytes_read) {
                      assert(bytes_read == buf.size);                         // 14
                      return std::move(buf);                                  // 15
                    });
       });
}
```

This example demonstrates a common asynchronous I/O pattern - reading a payload of a dynamic size by first reading the size, then reading the number of bytes specified by the size:

1. `async_read` is a pipeable sender adaptor. It's a customization point object, but this is what it's call signature looks like. It takes a sender parameter which must send an input buffer in the form of a `std::span<std::byte>`, and a handle to an I/O context. It will asynchronously read into the input buffer, up to the size of the `std::span`. It returns a sender which will send the number of bytes read once the read completes.
2. `async_read_array` takes an I/O handle and reads a size from it, and then a buffer of that many bytes. It returns a sender that sends a `dynamic_buffer` object that owns the data that was sent.
3. `dynamic_buffer` is an aggregate struct that contains a `std::unique_ptr<std::byte[]>` and a size.
4. The first thing we do inside of `async_read_array` is create a sender that will send a new, empty `dynamic_array` object using [[#design-sender-factory-just]]. We can attach more work to the pipeline using `operator|` composition (see [[#design-pipeable]] for details).
5. We need the lifetime of this `dynamic_array` object to last for the entire pipeline. So, we use `let_value`, which takes an input sender and a `std::invocable` that must return a sender itself (see [[#design-sender-adaptor-let]] for details). `let_value` sends the value from the input sender to the `std::invocable`. Critically, the lifetime of the sent object will last until the sender returned by the `std::invocable` completes.
6. Inside of the `let_value` `std::invocable`, we have the rest of our logic. First, we want to initiate an `async_read` of the buffer size. To do that, we need to send a `std::span` pointing to `buf.size`. We can do that with [[#design-sender-factory-just]].
7. We chain the `async_read` onto the [[#design-sender-factory-just]] sender with `operator|`.
8. Next, we pipe a `std::invocable` that will be invoked after the `async_read` completes using [[#design-sender-adaptor-then]].
9. That `std::invocable` gets sent the number of bytes read.
10. We need to check that the number of bytes read is what we expected.
11. Now that we have read the size of the data, we can allocate storage for it.
12. We return a `std::span<std::byte>` to the storage for the data from the `std::invocable`. This will be sent to the next recipient in the pipeline.
13. And that recipient will be another `async_read`, which will read the data.
14. Once the data has been read, in another [[#design-sender-adaptor-then]], we confirm that we read the right number of bytes.
15. Finally, we move out of and return our `dynamic_buffer` object. It will get sent by the sender returned by `async_read_array`. We can attach more things to that sender to use the data in the buffer.

## Asynchronous Windows socket `recv` ## {#example-async-windows-socket-recv}

To get a better feel for how this interface might be used by low-level operations see this example implementation
of a cancellable `async_recv()` operation for a Windows Socket.

```c++
struct operation_base : WSAOVERALAPPED {
    using completion_fn = void(operation_base* op, DWORD bytesTransferred, int errorCode) noexcept;

    // Assume IOCP event loop will call this when this OVERLAPPED structure is dequeued.
    completion_fn* completed;
};

template<typename Receiver>
struct recv_op : operation_base {
    recv_op(SOCKET s, void* data, size_t len, Receiver r)
    : receiver(std::move(r))
    , sock(s) {
        this->Internal = 0;
        this->InternalHigh = 0;
        this->Offset = 0;
        this->OffsetHigh = 0;
        this->hEvent = NULL;
        this->completed = &recv_op::on_complete;
        buffer.len = len;
        buffer.buf = static_cast<CHAR*>(data);
    }

    friend void tag_invoke(std::tag_t<std::execution::start>, recv_op& self) noexcept {
        // Avoid even calling WSARecv() if operation already cancelled
        auto st = std::execution::get_stop_token(
          std::execution::get_env(self.receiver));
        if (st.stop_requested()) {
            std::execution::set_stopped(std::move(self.receiver));
            return;
        }

        // Store and cache result here in case it changes during execution
        const bool stopPossible = st.stop_possible();
        if (!stopPossible) {
            self.ready.store(true, std::memory_order_relaxed);
        }

        // Launch the operation
        DWORD bytesTransferred = 0;
        DWORD flags = 0;
        int result = WSARecv(self.sock, &self.buffer, 1, &bytesTransferred, &flags,
                             static_cast<WSAOVERLAPPED*>(&self), NULL);
        if (result == SOCKET_ERROR) {
            int errorCode = WSAGetLastError();
            if (errorCode != WSA_IO_PENDING)) {
                if (errorCode == WSA_OPERATION_ABORTED) {
                    std::execution::set_stopped(std::move(self.receiver));
                } else {
                    std::execution::set_error(std::move(self.receiver),
                                              std::error_code(errorCode, std::system_category()));
                }
                return;
            }
        } else {
            // Completed synchronously (assuming FILE_SKIP_COMPLETION_PORT_ON_SUCCESS has been set)
            execution::set_value(std::move(self.receiver), bytesTransferred);
            return;
        }

        // If we get here then operation has launched successfully and will complete asynchronously.
        // May be completing concurrently on another thread already.
        if (stopPossible) {
            // Register the stop callback
            self.stopCallback.emplace(std::move(st), cancel_cb{self});

            // Mark as 'completed'
            if (self.ready.load(std::memory_order_acquire) ||
                self.ready.exchange(true, std::memory_order_acq_rel)) {
                // Already completed on another thread
                self.stopCallback.reset();

                BOOL ok = WSAGetOverlappedResult(self.sock, (WSAOVERLAPPED*)&self, &bytesTransferred, FALSE, &flags);
                if (ok) {
                    std::execution::set_value(std::move(self.receiver), bytesTransferred);
                } else {
                    int errorCode = WSAGetLastError();
                    std::execution::set_error(std::move(self.receiver),
                                              std::error_code(errorCode, std::system_category()));
                }
            }
        }
    }

    struct cancel_cb {
        recv_op& op;

        void operator()() noexcept {
            CancelIoEx((HANDLE)op.sock, (OVERLAPPED*)(WSAOVERLAPPED*)&op);
        }
    };

    static void on_complete(operation_base* op, DWORD bytesTransferred, int errorCode) noexcept {
        recv_op& self = *static_cast<recv_op*>(op);

        if (ready.load(std::memory_order_acquire) ||
            ready.exchange(true, std::memory_order_acq_rel)) {
            // Unsubscribe any stop-callback so we know that CancelIoEx() is not accessing 'op'
            // any more
            stopCallback.reset();

            if (errorCode == 0) {
                std::execution::set_value(std::move(receiver), bytesTransferred);
            } else {
                std::execution::set_error(std::move(receiver),
                                          std::error_code(errorCode, std::system_category()));
            }
        }
    }

    Receiver receiver;
    SOCKET sock;
    WSABUF buffer;
    std::optional<typename stop_callback_type_t<Receiver>
        ::template callback_type<cancel_cb>> stopCallback;
    std::atomic<bool> ready{false};
};

struct recv_sender {
    SOCKET sock;
    void* data;
    size_t len;

    template<typename Receiver>
    friend recv_op<Receiver> tag_invoke(std::tag_t<std::execution::connect>
                                        const recv_sender& s,
                                        Receiver r) {
        return recv_op<Receiver>{s.sock, s.data, s.len, std::move(r)};
    }
};

recv_sender async_recv(SOCKET s, void* data, size_t len) {
    return recv_sender{s, data, len};
}
```

### More end-user examples ### {#example-moar}

#### Sudoku solver #### {#example-sudoku}

This example comes from Kirk Shoop, who ported an example from TBB's documentation to sender/receiver in his fork of the libunifex repo. It is a Sudoku solver that uses a configurable number of threads to explore the search space for solutions.

The sender/receiver-based Sudoku solver can be found [here](https://github.com/kirkshoop/libunifex/blob/sudoku/examples/sudoku.cpp). Some things that are worth noting about Kirk's solution:

1. Although it schedules asychronous work onto a thread pool, and each unit of work will schedule more work, its use of structured concurrency patterns make reference counting unnecessary. The solution does not make use of `shared_ptr`.

2. In addition to eliminating the need for reference counting, the use of structured concurrency makes it easy to ensure that resources are cleaned up on all code paths. In contrast, the TBB example that inspired this one [leaks memory](https://github.com/oneapi-src/oneTBB/issues/568).

For comparison, the TBB-based Sudoku solver can be found [here](https://github.com/oneapi-src/oneTBB/blob/40a9a1060069d37d5f66912c6ee4cf165144774b/examples/task_group/sudoku/sudoku.cpp).

#### File copy #### {#example-file-copy}

This example also comes from Kirk Shoop which uses sender/receiver to recursively copy the files a directory tree. It demonstrates how sender/receiver can be used to do IO, using a scheduler that schedules work on Linux's io_uring.

As with the Sudoku example, this example obviates the need for reference counting by employing structured concurrency. It uses iteration with an upper limit to avoid having too many open file handles.

You can find the example [here](https://github.com/kirkshoop/libunifex/blob/filecopy/examples/file_copy.cpp).

#### Echo server #### {#example-echo-server}

Dietmar Kuehl has a hobby project that implements networking APIs on top of sender/receiver. He recently implemented an echo server as a demo. His echo server code can be found [here](https://github.com/dietmarkuehl/kuhllib/blob/main/src/examples/echo_server.cpp).

Below, I show the part of the echo server code. This code is executed for each client that connects to the echo server. In a loop, it reads input from a socket and echos the input back to the same socket. All of this, including the loop, is implemented with generic async algorithms.

    <pre highlight="c++">
    outstanding.start(
        EX::repeat_effect_until(
              EX::let_value(
                  NN::async_read_some(ptr->d_socket,
                                      context.scheduler(),
                                      NN::buffer(ptr->d_buffer))
            | EX::then([ptr](::std::size_t n){
                ::std::cout &lt;&lt; "read='" &lt;&lt; ::std::string_view(ptr->d_buffer, n) &lt;&lt; "'\n";
                ptr->d_done = n == 0;
                return n;
            }),
              [&context, ptr](::std::size_t n){
                return NN::async_write_some(ptr->d_socket,
                                            context.scheduler(),
                                            NN::buffer(ptr->d_buffer, n));
              })
            | EX::then([](auto&&...){})
            , [owner = ::std::move(owner)]{ return owner->d_done; }
        )
    );
    </pre>

In this code, `NN::async_read_some` and `NN::async_write_some` are asynchronous socket-based networking APIs that return senders. `EX::repeat_effect_until`, `EX::let_value`, and `EX::then` are fully generic sender adaptor algorithms that accept and return senders.

This is a good example of seamless composition of async IO functions with non-IO operations. And by composing the senders in this structured way, all the state for the composite operation -- the `repeat_effect_until` expression and all its child operations -- is stored altogether in a single object.

## Examples: Algorithms ## {#example-algorithm}

In this section we show a few simple sender/receiver-based algorithm implementations.

### `then` ### {#example-then}

```c++
namespace exec = std::execution;

template<class R, class F>
class _then_receiver
    : exec::receiver_adaptor<_then_receiver<R, F>, R> {
  friend exec::receiver_adaptor<_then_receiver, R>;
  F f_;

  // Customize set_value by invoking the callable and passing the result to the inner receiver
  template<class... As>
  void set_value(As&&... as) && noexcept try {
    exec::set_value(std::move(*this).base(), std::invoke((F&&) f_, (As&&) as...));
  } catch(...) {
    exec::set_error(std::move(*this).base(), std::current_exception());
  }

 public:
  _then_receiver(R r, F f)
   : exec::receiver_adaptor<_then_receiver, R>{std::move(r)}
   , f_(std::move(f)) {}
};

template<exec::sender S, class F>
struct _then_sender {
  S s_;
  F f_;

  template <class... Args>
    using _set_value_t = exec::completion_signatures<
      exec::set_value_t(std::invoke_result_t<F, Args...>)>;

  // Compute the completion signatures
  template<class Env>
  friend auto tag_invoke(exec::get_completion_signatures_t, _then_sender&&, Env)
    -> exec::make_completion_signatures<S, Env,
        exec::completion_signatures<exec::set_error_t(std::exception_ptr)>,
        _set_value_t>;

  // Connect:
  template<exec::receiver R>
  friend auto tag_invoke(exec::connect_t, _then_sender&& self, R r)
    -> exec::connect_result_t<S, _then_receiver<R, F>> {
      return exec::connect(
        (S&&) self.s_, _then_receiver<R, F>{(R&&) r, (F&&) self.f_});
  }
};

template<exec::sender S, class F>
exec::sender auto then(S s, F f) {
  return _then_sender<S, F>{(S&&) s, (F&&) f};
}
```

This code builds a `then` algorithm that transforms the value(s) from the input sender
with a transformation function. The result of the transformation becomes the new value.
The other receiver functions (`set_error` and `set_stopped`), as well as all receiver queries,
are passed through unchanged.

In detail, it does the following:

1. Defines a receiver in terms of `execution::receiver_adaptor` that aggregates
    another receiver and an invocable that:
    * Defines a constrained `tag_invoke` overload for transforming the value
        channel.
    * Defines another constrained overload of `tag_invoke` that passes all other
        customizations through unchanged.

    The `tag_invoke` overloads are actually implemented by
    `execution::receiver_adaptor`; they dispatch either to named members, as
    shown above with `_then_receiver::set_value`, or to the adapted receiver.
2. Defines a sender that aggregates another sender and the invocable, which defines a `tag_invoke` customization for `std::execution::connect` that wraps the incoming receiver in the receiver from (1) and passes it and the incoming sender to `std::execution::connect`, returning the result. It also defines a `tag_invoke` customization of `get_completion_signatures` that declares the sender's completion signatures when executed within a particular environment.

### `retry` ### {#example-retry}

```c++
using namespace std;
namespace exec = execution;

template <class From, class To>
concept _decays_to = same_as<decay_t<From>, To>;

// _conv needed so we can emplace construct non-movable types into
// a std::optional.
template<invocable F>
  requires is_nothrow_move_constructible_v<F>
struct _conv {
  F f_;
  explicit _conv(F f) noexcept : f_((F&&) f) {}
  operator invoke_result_t<F>() && {
    return ((F&&) f_)();
  }
};

template<class S, class R>
struct _op;

// pass through all customizations except set_error, which retries the operation.
template<class S, class R>
struct _retry_receiver
  : exec::receiver_adaptor<_retry_receiver<S, R>> {
  _op<S, R>* o_;

  R&& base() && noexcept { return (R&&) o_->r_; }
  const R& base() const & noexcept { return o_->r_; }

  explicit _retry_receiver(_op<S, R>* o) : o_(o) {}

  void set_error(auto&&) && noexcept {
    o_->_retry(); // This causes the op to be retried
  }
};

// Hold the nested operation state in an optional so we can
// re-construct and re-start it if the operation fails.
template<class S, class R>
struct _op {
  S s_;
  R r_;
  optional<
      exec::connect_result_t<S&, _retry_receiver<S, R>>> o_;

  _op(S s, R r): s_((S&&)s), r_((R&&)r), o_{_connect()} {}
  _op(_op&&) = delete;

  auto _connect() noexcept {
    return _conv{[this] {
      return exec::connect(s_, _retry_receiver<S, R>{this});
    }};
  }
  void _retry() noexcept try {
    o_.emplace(_connect()); // potentially throwing
    exec::start(*o_);
  } catch(...) {
    exec::set_error((R&&) r_, std::current_exception());
  }
  friend void tag_invoke(exec::start_t, _op& o) noexcept {
    exec::start(*o.o_);
  }
};

template<class S>
struct _retry_sender {
  S s_;
  explicit _retry_sender(S s) : s_((S&&) s) {}

  template <class... Ts>
    using _value_t =
      exec::completion_signatures<exec::set_value_t(Ts...)>;
  template <class>
    using _error_t = exec::completion_signatures<>;

  // Declare the signatures with which this sender can complete
  template <class Env>
  friend auto tag_invoke(exec::get_completion_signatures_t, const _retry_sender&, Env)
    -> exec::make_completion_signatures<S&, Env,
        exec::completion_signatures<exec::set_error_t(std::exception_ptr)>,
        _value_t, _error_t>;

  template<exec::receiver R>
  friend _op<S, R> tag_invoke(exec::connect_t, _retry_sender&& self, R r) {
    return {(S&&) self.s_, (R&&) r};
  }
};

template<exec::sender S>
exec::sender auto retry(S s) {
  return _retry_sender{(S&&) s};
}
```

The `retry` algorithm takes a multi-shot sender and causes it to repeat on error, passing
through values and stopped signals. Each time the input sender is restarted, a new receiver
is connected and the resulting operation state is stored in an `optional`, which allows us
to reinitialize it multiple times.

This example does the following:

1. Defines a `_conv` utility that takes advantage of C++17's guaranteed copy elision to
    emplace a non-movable type in a `std::optional`.

2. Defines a `_retry_receiver` that holds a pointer back to the operation state. It passes
    all customizations through unmodified to the inner receiver owned by the operation state
    except for `set_error`, which causes a `_retry()` function to be called instead.

3. Defines an operation state that aggregates the input sender and receiver, and declares
    storage for the nested operation state in an `optional`. Constructing the operation
    state constructs a `_retry_receiver` with a pointer to the (under construction) operation
    state and uses it to connect to the aggregated sender.

4. Starting the operation state dispatches to `start` on the inner operation state.

5. The `_retry()` function reinitializes the inner operation state by connecting the sender
    to a new receiver, holding a pointer back to the outer operation state as before.

6. After reinitializing the inner operation state, `_retry()` calls `start` on it, causing
    the failed operation to be rescheduled.

7. Defines a `_retry_sender` that implements the `connect` customization point to return
    an operation state constructed from the passed-in sender and receiver.

8. `_retry_sender` also implements the `get_completion_signatures` customization point to describe the ways this sender may complete when executed in a particular execution context.

## Examples: Schedulers ## {#example-schedulers}

In this section we look at some schedulers of varying complexity.

### Inline scheduler ### {#example-schedulers-inline}

```c++
class inline_scheduler {
  template <class R>
    struct _op {
      [[no_unique_address]] R rec_;
      friend void tag_invoke(std::execution::start_t, _op& op) noexcept try {
        std::execution::set_value((R&&) op.rec_);
      } catch(...) {
        std::execution::set_error((R&&) op.rec_, std::current_exception());
      }
    };

  struct _sender {
    using completion_signatures =
      std::execution::completion_signatures<
        std::execution::set_value_t(),
        std::execution::set_error_t(std::exception_ptr)>;

    template <class R>
      friend auto tag_invoke(std::execution::connect_t, _sender, R&& rec)
        noexcept(std::is_nothrow_constructible_v<std::remove_cvref_t<R>, R>)
        -> _op<std::remove_cvref_t<R>> {
        return {(R&&) rec};
      }
  };

  friend _sender tag_invoke(std::execution::schedule_t, const inline_scheduler&) noexcept {
    return {};
  }

 public:
  inline_scheduler() = default;
  bool operator==(const inline_scheduler&) const noexcept = default;
};
```

The inline scheduler is a trivial scheduler that completes immediately and synchronously on
the thread that calls `std::execution::start` on the operation state produced by its sender.
In other words, <code>start(connect(schedule(<i>inline-scheduler</i>), receiver))</code> is
just a fancy way of saying `set_value(receiver)`, with the exception of the fact that `start`
wants to be passed an lvalue.

Although not a particularly useful scheduler, it serves to illustrate the basics of
implementing one. The `inline_scheduler`:

1. Customizes `execution::schedule` to return an instance of the sender type
    `_sender`.
2. The `_sender` type models the `sender` concept and provides the metadata
    needed to describe it as a sender of no values that can send an
    `exception_ptr` as an error and that never calls `set_stopped`. This
    metadata is provided with the help of the `execution::completion_signatures`
    utility.
3. The `_sender` type customizes `execution::connect` to accept a receiver of no
    values. It returns an instance of type `_op` that holds the receiver by
    value.
4. The operation state customizes `std::execution::start` to call
    `std::execution::set_value` on the receiver, passing any exceptions to
    `std::execution::set_error` as an `exception_ptr`.

### Single thread scheduler ### {#example-single-thread}

This example shows how to create a scheduler for an execution context that consists of a single
thread. It is implemented in terms of a lower-level execution context called `std::execution::run_loop`.

```c++
class single_thread_context {
  std::execution::run_loop loop_;
  std::thread thread_;

public:
  single_thread_context()
    : loop_()
    , thread_([this] { loop_.run(); })
  {}

  ~single_thread_context() {
    loop_.finish();
    thread_.join();
  }

  auto get_scheduler() noexcept {
    return loop_.get_scheduler();
  }

  std::thread::id get_thread_id() const noexcept {
    return thread_.get_id();
  }
};
```

The `single_thread_context` owns an event loop and a thread to drive it. In the destructor, it tells the event
loop to finish up what it's doing and then joins the thread, blocking for the event loop to drain.

The interesting bits are in the `execution::run_loop` context implementation. It
is slightly too long to include here, so we only provide [a reference to
it](https://github.com/brycelelbach/wg21_p2300_std_execution/blob/8bc0955c008652937948af784b7b6ccedecec23c/include/execution.hpp#L2720-L2887),
but there is one noteworthy detail about its implementation: It uses space in
its operation states to build an intrusive linked list of work items. In
structured concurrency patterns, the operation states of nested operations
compose statically, and in an algorithm like `this_thread::sync_wait`, the
composite operation state lives on the stack for the duration of the operation.
The end result is that work can be scheduled onto this thread with zero
allocations.

## Examples: Server theme ## {#example-server}

In this section we look at some examples of how one would use senders to implement an HTTP server. The examples ignore the low-level details of the HTTP server and looks at how senders can be combined to achieve the goals of the project.

General application context:
* server application that processes images
* execution contexts:
    - 1 dedicated thread for network I/O
    - N worker threads used for CPU-intensive work
    - M threads for auxiliary I/O
    - optional GPU context that may be used on some types of servers
* all parts of the applications can be asynchronous
* no locks shall be used in user code

### Composability with `execution::let_*` ### {#example-server-let}

Example context:
- we are looking at the flow of processing an HTTP request and sending back the response
- show how one can break the (slightly complex) flow into steps with `execution::let_*` functions
- different phases of processing HTTP requests are broken down into separate concerns
- each part of the processing might use different execution contexts (details not shown in this example)
- error handling is generic, regardless which component fails; we always send the right response to the clients

Goals:
- show how one can break more complex flows into steps with let_* functions
- exemplify the use of `let_value`, `let_error`, `let_stopped`, and `just` algorithms

```c++
namespace ex = std::execution;

// Returns a sender that yields an http_request object for an incoming request
ex::sender auto schedule_request_start(read_requests_ctx ctx) {...}
// Sends a response back to the client; yields a void signal on success
ex::sender auto send_response(const http_response& resp) {...}
// Validate that the HTTP request is well-formed; forwards the request on success
ex::sender auto validate_request(const http_request& req) {...}

// Handle the request; main application logic
ex::sender auto handle_request(const http_request& req) {
  //...
  return ex::just(http_response{200, result_body});
}

// Transforms server errors into responses to be sent to the client
ex::sender auto error_to_response(std::exception_ptr err) {
  try {
    std::rethrow_exception(err);
  } catch (const std::invalid_argument& e) {
    return ex::just(http_response{404, e.what()});
  } catch (const std::exception& e) {
    return ex::just(http_response{500, e.what()});
  } catch (...) {
    return ex::just(http_response{500, "Unknown server error"});
  }
}
// Transforms cancellation of the server into responses to be sent to the client
ex::sender auto stopped_to_response() {
  return ex::just(http_response{503, "Service temporarily unavailable"});
}
//...
// The whole flow for transforming incoming requests into responses
ex::sender auto snd =
    // get a sender when a new request comes
    schedule_request_start(the_read_requests_ctx)
    // make sure the request is valid; throw if not
    | ex::let_value(validate_request)
    // process the request in a function that may be using a different execution context
    | ex::let_value(handle_request)
    // If there are errors transform them into proper responses
    | ex::let_error(error_to_response)
    // If the flow is cancelled, send back a proper response
    | ex::let_stopped(stopped_to_response)
    // write the result back to the client
    | ex::let_value(send_response)
    // done
    ;
// execute the whole flow asynchronously
ex::start_detached(std::move(snd));
```
The example shows how one can separate out the concerns for interpreting requests, validating requests, running the main logic for handling the request, generating error responses, handling cancellation and sending the response back to the client.
They are all different phases in the application, and can be joined together with the `let_*` functions.

All our functions return `execution::sender` objects, so that they can all generate success, failure and cancellation paths.
For example, regardless where an error is generated (reading request, validating request or handling the response), we would have one common block to handle the error, and following error flows is easy.

Also, because of using `execution::sender` objects at any step, we might expect any of these steps to be completely asynchronous; the overall flow doesn't care.
Regardless of the execution context in which the steps, or part of the steps are executed in, the flow is still the same.

### Moving between execution contexts with `execution::on` and `execution::transfer` ### {#example-server-on}

Example context:
- reading data from the socket before processing the request
- reading of the data is done on the I/O context
- no processing of the data needs to be done on the I/O context

Goals:
- show how one can change the execution context
- exemplify the use of `on` and `transfer` algorithms


```c++
namespace ex = std::execution;

size_t legacy_read_from_socket(int sock, char* buffer, size_t buffer_len) {}
void process_read_data(const char* read_data, size_t read_len) {}
//...

// A sender that just calls the legacy read function
auto snd_read = ex::just(sock, buf, buf_len) | ex::then(legacy_read_from_socket);
// The entire flow
auto snd =
    // start by reading data on the I/O thread
    ex::on(io_sched, std::move(snd_read))
    // do the processing on the worker threads pool
    | ex::transfer(work_sched)
    // process the incoming data (on worker threads)
    | ex::then([buf](int read_len) { process_read_data(buf, read_len); })
    // done
    ;
// execute the whole flow asynchronously
ex::start_detached(std::move(snd));
```

The example assume that we need to wrap some legacy code of reading sockets, and handle execution context switching.
(This style of reading from socket may not be the most efficient one, but it's working for our purposes.)
For performance reasons, the reading from the socket needs to be done on the I/O thread, and all the processing needs to happen on a work-specific execution context (i.e., thread pool).

Calling `execution::on` will ensure that the given sender will be started on the given scheduler.
In our example, `snd_read` is going to be started on the I/O scheduler.
This sender will just call the legacy code.

The completion signal will be issued in the I/O execution context, so we have to move it to the work thread pool.
This is achieved with the help of the `execution::transfer` algorithm.
The rest of the processing (in our case, the last call to `then`) will happen in the work thread pool.

The reader should notice the difference between `execution::on` and `execution::transfer`.
The `execution::on` algorithm will ensure that the given sender will start in the specified context, and doesn't care where the completion signal for that sender is sent.
The `execution::transfer` algorithm will not care where the given sender is going to be started, but will ensure that the completion signal of will be transferred to the given context.

## What this proposal is **not** ## {#intro-is-not}

This paper is not a patch on top of [[P0443R14]]; we are not asking to update the existing paper, we are asking to retire it in favor of this paper, which is already self-contained; any example code within this paper can be written in Standard C++, without the need
to standardize any further facilities.

This paper is not an alternative design to [[P0443R14]]; rather, we have taken the design in the current executors paper, and applied targeted fixes to allow it to fulfill the promises of the sender/receiver model, as well as provide all the facilities we consider
essential when writing user code using standard execution concepts; we have also applied the guidance of removing one-way executors from the paper entirely, and instead provided an algorithm based around senders that serves the same purpose.

## Design changes from P0443 ## {#intro-compare}

1. The `executor` concept has been removed and all of its proposed functionality
    is now based on schedulers and senders, as per SG1 direction.
2. Properties are not included in this paper. We see them as a possible future
    extension, if the committee gets more comfortable with them.
3. Senders now advertise what scheduler, if any, their evaluation will complete
    on.
4. The places of execution of user code in P0443 weren't precisely defined,
    whereas they are in this paper. See [[#design-propagation]].
5. P0443 did not propose a suite of sender algorithms necessary for writing
    sender code; this paper does. See [[#design-sender-factories]],
    [[#design-sender-adaptors]], and [[#design-sender-consumers]].
6. P0443 did not specify the semantics of variously qualified `connect`
    overloads; this paper does. See [[#design-shot]].
7. This paper extends the sender traits/typed sender design to support typed
    senders whose value/error types depend on type information provided late via
    the receiver.
8. Support for untyped senders is dropped; the `typed_sender` concept is renamed
    `sender`; `sender_traits` is replaced with `completion_signatures_of_t`.
8. Specific type erasure facilities are omitted, as per LEWG direction. Type
    erasure facilities can be built on top of this proposal, as discussed in
    [[#design-dispatch]].
9. A specific thread pool implementation is omitted, as per LEWG direction.
10. Some additional utilities are added:
    * <b>`run_loop`</b>: An execution context that provides a multi-producer,
        single-consumer, first-in-first-out work queue.
    * <b>`receiver_adaptor`</b>: A utility for algorithm authors for defining one
        receiver type in terms of another.
    * <b>`completion_signatures`</b> and <b>`make_completion_signatures`</b>:
        Utilities for describing the ways in which a sender can complete in a
        declarative syntax.

## Prior art ## {#intro-prior-art}

This proposal builds upon and learns from years of prior art with asynchronous and parallel programming frameworks in C++. In this section, we discuss async abstractions that have previously been suggested as a possible basis for asynchronous algorithms and why they fall short.

### Futures ### {#intro-prior-art-futures}

A future is a handle to work that has already been scheduled for execution. It is one end of a communication channel; the other end is a promise, used to receive the result from the concurrent operation and to communicate it to the future.

Futures, as traditionally realized, require the dynamic allocation and management of a shared state, synchronization, and typically type-erasure of work and continuation. Many of these costs are inherent in the nature of "future" as a handle to work that is already scheduled for execution. These expenses rule out the future abstraction for many uses and makes it a poor choice for a basis of a generic mechanism.

### Coroutines ### {#intro-prior-art-coroutines}

C++20 coroutines are frequently suggested as a basis for asynchronous algorithms. It's fair to ask why, if we added coroutines to C++, are we suggesting the addition of a library-based abstraction for asynchrony. Certainly, coroutines come with huge syntactic and semantic advantages over the alternatives.

Although coroutines are lighter weight than futures, coroutines suffer many of the same problems. Since they typically start suspended, they can avoid synchronizing the chaining of dependent work. However in many cases, coroutine frames require an unavoidable dynamic allocation and indirect function calls. This is done to hide the layout of the coroutine frame from the C++ type system, which in turn makes possible the separate compilation of coroutines and certain compiler optimizations, such as optimization of the coroutine frame size.

Those advantages come at a cost, though. Because of the dynamic allocation of coroutine frames, coroutines in embedded or heterogeneous environments, which often lack support for dynamic allocation, require great attention to detail. And the allocations and indirections tend to complicate the job of the inliner, often resulting in sub-optimal codegen.

The coroutine language feature mitigates these shortcomings somewhat with the HALO optimization [[P0981R0]], which leverages existing compiler optimizations such as allocation elision and devirtualization to inline the coroutine, completely eliminating the runtime overhead. However, HALO requires a sophisiticated compiler, and a fair number of stars need to align for the optimization to kick in. In our experience, more often than not in real-world code today's compilers are not able to inline the coroutine, resulting in allocations and indirections in the generated code.

In a suite of generic async algorithms that are expected to be callable from hot code paths, the extra allocations and indirections are a deal-breaker. It is for these reasons that we consider coroutines a poor choise for a basis of all standard async.

### Callbacks ### {#intro-prior-art-callbacks}

Callbacks are the oldest, simplest, most powerful, and most efficient mechanism for creating chains of work, but suffer problems of their own. Callbacks must propagate either errors or values. This simple requirement yields many different interface possibilities. The lack of a standard callback shape obstructs generic design.

Additionally, few of these possibilities accommodate cancellation signals when the user requests upstream work to stop and clean up.

## Field experience ## {#intro-field-experience}

### libunifex ### {#intro-field-experience-libunifex}

This proposal draws heavily from our field experience with [libunifex](https://github.com/facebookexperimental/libunifex). Libunifex implements all of the concepts and customization points defined in this paper (with slight variations -- the design of P2300 has evolved due to LEWG feedback), many of this paper's algorithms (some under different names), and much more besides.

Libunifex has several concrete schedulers in addition to the `run_loop` suggested here (where it is called `manual_event_loop`). It has schedulers that dispatch efficiently to epoll and io_uring on Linux and the Windows Thread Pool on Windows.

In addition to the proposed interfaces and the additional schedulers, it has several important extensions to the facilities described in this paper, which demonstrate directions in which these abstractions may be evolved over time, including:

* Timed schedulers, which permit scheduling work on an execution context at a particular time or after a particular duration has elapsed. In addition, it provides time-based algorithms.
* File I/O schedulers, which permit filesystem I/O to be scheduled.
* Two complementary abstractions for streams (asynchronous ranges), and a set of stream-based algorithms.

Libunifex has seen heavy production use at Facebook. As of October 2021, it is currently used in production within the following applications and platforms:

* Facebook Messenger on iOS, Android, Windows, and macOS
* Instagram on iOS and Android
* Facebook on iOS and Android
* Portal
* An internal Facebook product that runs on Linux

All of these applications are making direct use of the sender/receiver abstraction as presented in this paper. One product (Instagram on iOS) is making use of the sender/coroutine integration as presented. The monthly active users of these products number in the billions.

### Other implementations ### {#intro-field-experience-other-implementations}

The authors are aware of a number of other implementations of sender/receiver from this paper. These are presented here in perceived order of maturity and field experience.

* <b>[[HPX]]</b>

    HPX is a general purpose C++ runtime system for parallel and distributed applications that has been under active development since 2007. HPX exposes a uniform, standards-oriented API, and keeps abreast of the latest standards and proposals. It is used in a wide variety of high-performance applications.

    The sender/receiver implementation in HPX has been under active development since May 2020. It is used to erase the overhead of futures and to make it possible to write efficient generic asynchronous algorithms that are agnostic to their execution context. In HPX, algorithms can migrate execution between execution contexts, even to GPUs and back, using a uniform standard interface with sender/receiver.

    Far and away, the HPX team has the greatest usage experience outside Facebook. Mikael Simberg summarizes the experience as follows:

    > Summarizing, for us the major benefits of sender/receiver compared to the old model are:
    >
    > 1. Proper hooks for transitioning between execution contexts.
    > 2. The adaptors. Things like `let_value` are really nice additions.
    > 3. Separation of the error channel from the value channel (also cancellation, but we don't have much use for it at the moment). Even from a teaching perspective having to explain that the future `f2` in the continuation will always be ready here `f1.then([](future<T> f2) {...})` is enough of a reason to separate the channels. All the other obvious reasons apply as well of course.
    > 4. For futures we have a thing called `hpx::dataflow` which is an optimized version of `when_all(...).then(...)` which avoids intermediate allocations. With the sender/receiver `when_all(...) | then(...)` we get that "for free".

* <b>[kuhllib](https://github.com/dietmarkuehl/kuhllib/) by Dietmar Kuehl</b>

    This is a prototype Standard Template Library with an implementation of sender/receiver that has been under development since May, 2021. It is significant mostly for its support for sender/receiver-based networking interfaces.

    Here, Dietmar Kuehl speaks about the perceived complexity of sender/receiver:

    > ... and, also similar to STL: as I had tried to do things in that space before I recognize sender/receivers as being maybe complicated in one way but a huge simplification in another one: like with STL I think those who use it will benefit - if not from the algorithm from the clarity of abstraction: the separation of concerns of STL (the algorithm being detached from the details of the sequence representation) is a major leap. Here it is rather similar: the separation of the asynchronous algorithm from the details of execution. Sure, there is some glue to tie things back together but each of them is simpler than the combined result.

    Elsewhere, he said:

    > ... to me it feels like sender/receivers are like iterators when STL emerged: they are different from what everybody did in that space. However, everything people are already doing in that space isn’t right.

    Kuehl also has experience teaching sender/receiver at Bloomberg. About that experience he says:

    > When I asked [my students] specifically about how complex they consider the sender/receiver stuff the feedback was quite unanimous that the sender/receiver parts aren’t trivial but not what contributes to the complexity.

* <b>[The reference implementation](https://github.com/brycelelbach/wg21_p2300_std_execution/tree/main/include)</b>

    This is a partial implementation written from the specification in this paper. Its primary purpose is to help find specification bugs and to harden the wording of the proposal. When finished, it will be a minimal and complete implementation of this proposal, fit for broad use and for contribution to libc++. It will be finished before this proposal is approved.

    It currently lacks some of the proposed sender adaptors and `execution::start_detached`, but otherwise implements the concepts, customization points, traits, queries, coroutine integration, sender factories, pipe support, `execution::receiver_adaptor`, and `execution::run_loop`.

* <b>[Reference implementation for the Microsoft STL](https://github.com/miscco/STL/tree/proposal/executors) by Michael Schellenberger Costa</b>

    This is another reference implementation of this proposal, this time in a fork of the Mircosoft STL implementation. Michael Schellenberger Costa is not affiliated with Microsoft. He intends to contribute this implementation upstream when it is complete.

### Inspirations ### {#intro-field-experience-inspirations}

This proposal also draws heavily from our experience with [Thrust](https://github.com/NVIDIA/thrust) and [Agency](https://github.com/agency-library/agency). It is also inspired by the needs of countless other C++ frameworks for asynchrony, parallelism, and concurrency, including:

* <a href="https://github.com/STEllAR-GROUP/hpx">HPX</a>
* [Folly](https://github.com/facebook/folly/blob/master/folly/docs/Futures.md)
* [stlab](https://stlab.cc/libraries/concurrency/)

# Revision history # {#revisions}

## R6 ## {#r6}

The changes since R5 are as follows:

<b>Enhancements:</b>

  * Reorder constraints of the `scheduler` concept to avoid constraint recursion
    when used in tandem with poorly-constrained, implicitly convertible types.

<b>Fixes:</b>					 

  * Fix typo in the specification of `in_place_stop_source` about the relative
    lifetimes of the tokens and the source that produced them.
					 
## R5 ## {#r5}

The changes since R4 are as follows:

<b>Fixes:</b>

  * `start_detached` requires its argument to be a `void` sender (sends no values
    to `set_value`).

<b>Enhancements:</b>

  * Receiver concepts refactored to no longer require an error channel for
    `exception_ptr` or a stopped channel.
  * `sender_of` concept and `connect` customization point additionally require
    that the receiver is capable of receiving all of the sender's possible
    completions.
  * `get_completion_signatures` is now required to return an instance of either
    `completion_signatures` or `dependent_completion_signatures`.
  * `make_completion_signatures` made more general.
  * `receiver_adaptor` handles `get_env` as it does the `set_*` members; that is,
    `receiver_adaptor` will look for a member named `get_env()` in the derived
    class, and if found dispatch the `get_env_t` tag invoke customization to it.
  * `just`, `just_error`, `just_stopped`, and `into_variant` have been respecified
    as customization point objects instead of functions, following LEWG guidance.

## R4 ## {#r4}

The changes since R3 are as follows:

<b>Fixes:</b>

  * Fix specification of `get_completion_scheduler` on the `transfer`, `schedule_from`
    and `transfer_when_all` algorithms; the completion scheduler cannot be guaranteed
    for `set_error`.
  * The value of `sends_stopped` for the default sender traits of types that are
    generally awaitable was changed from `false` to `true` to acknowledge the
    fact that some coroutine types are generally awaitable and may implement the
    `unhandled_stopped()` protocol in their promise types.
  * Fix the incorrect use of inline namespaces in the `<execution>` header.
  * Shorten the stable names for the sections.
  * `sync_wait` now handles `std::error_code` specially by throwing a
    `std::system_error` on failure.
  * Fix how ADL isolation from class template arguments is specified so it
    doesn't constrain implmentations.
  * Properly expose the tag types in the header `<execution>` synopsis.

<b>Enhancements:</b>

  * Support for "dependently-typed" senders, where the completion signatures -- and
    thus the sender metadata -- depend on the type of the receiver connected
    to it. See the section [dependently-typed
    senders](#dependently-typed-senders) below for more information.
  * Add a <code>read(<i>query</i>)</code> sender factory for issuing a query
    against a receiver and sending the result through the value channel. (This is
    a useful instance of a dependently-typed sender.)
  * Add `completion_signatures` utility for declaratively defining a typed
    sender's metadata and a `make_completion_signatures` utility for adapting
    another sender's completions in helpful ways.
  * Add `make_completion_signatures` utility for specifying a sender's completion
    signatures by adapting those of another sender.
  * Drop support for untyped senders and rename `typed_sender` to `sender`.
  * `set_done` is renamed to `set_stopped`. All occurances of "`done`" in
    indentifiers replaced with "`stopped`"
  * Add customization points for controlling the forwarding of scheduler,
    sender, receiver, and environment queries through layers of adaptors;
    specify the behavior of the standard adaptors in terms of the new
    customization points.
  * Add `get_delegatee_scheduler` query to forward a scheduler that can be used
    by algorithms or by the scheduler to delegate work and forward progress.
  * Add `schedule_result_t` alias template.
  * More precisely specify the sender algorithms, including precisely what their
    completion signatures are.
  * `stopped_as_error` respecified as a customization point object.
  * `tag_invoke` respecified to improve diagnostics.

### Dependently-typed senders ### {#dependently-typed-senders}

**Background:**

In the sender/receiver model, as with coroutines, contextual information about
the current execution is most naturally propagated from the consumer to the
producer. In coroutines, that means information like stop tokens, allocators and
schedulers are propagated from the calling coroutine to the callee. In
sender/receiver, that means that that contextual information is associated with
the receiver and is queried by the sender and/or operation state after the
sender and the receiver are `connect`-ed.

**Problem:**

The implication of the above is that the sender alone does not have all the
information about the async computation it will ultimately initiate; some of
that information is provided late via the receiver. However, the `sender_traits`
mechanism, by which an algorithm can introspect the value and error types the
sender will propagate, *only* accepts a sender parameter. It does not take into
consideration the type information that will come in late via the receiver. The
effect of this is that some senders cannot be typed senders when they
otherwise could be.

**Example:**

To get concrete, consider the case of the "`get_scheduler()`" sender: when
`connect`-ed and `start`-ed, it queries the receiver for its associated
scheduler and passes it back to the receiver through the value channel. That
sender's "value type" is the type of the *receiver's* scheduler. What then
should `sender_traits<get_scheduler_sender>::value_types` report for the
`get_scheduler()`'s value type? It can't answer because it doesn't know.

This causes knock-on problems since some important algorithms require a typed
sender, such as `sync_wait`. To illustrate the problem, consider the following
code:

<pre highlight="c++">
namespace ex = std::execution;

ex::sender auto task =
  ex::let_value(
    ex::get_scheduler(), // Fetches scheduler from receiver.
    [](auto current_sched) {
      // Lauch some nested work on the current scheduler:
      return ex::on(current_sched, <i>nested work...</i>);
    });

std::this_thread::sync_wait(std::move(task));
</pre>

The code above is attempting to schedule some work onto the `sync_wait`'s
`run_loop` execution context. But `let_value` only returns a typed sender when
the input sender is typed. As we explained above, `get_scheduler()` is not
typed, so `task` is likewise not typed. Since `task` isn't typed, it cannot be
passed to `sync_wait` which is expecting a typed sender. The above code would
fail to compile.

**Solution:**

The solution is conceptually quite simple: extend the `sender_traits` mechanism
to optionally accept a receiver in addition to the sender. The algorithms can
use <code>sender_traits&lt;<i>Sender</i>, <i>Receiver</i>></code> to inspect the
async operation's completion signals. The `typed_sender` concept would also need
to take an optional receiver parameter. This is the simplest change, and it
would solve the immediate problem.

**Design:**

Using the receiver type to compute the sender traits turns out to have pitfalls
in practice. Many receivers make use of that type information in their
implementation. It is very easy to create cycles in the type system, leading to
inscrutible errors. The design pursued in R4 is to give receivers an associated
*environment* object -- a bag of key/value pairs -- and to move the contextual
information (schedulers, etc) out of the receiver and into the environment. The
`sender_traits` template and the `typed_sender` concept, rather than taking a
receiver, take an environment. This is a much more robust design.

A further refinement of this design would be to separate the receiver and the
environment entirely, passing then as separate arguments along with the sender to
`connect`. This paper does not propose that change.

**Impact:**

This change, apart from increasing the expressive power of the sender/receiver abstraction, has the following impact:

  * Typed senders become moderately more challenging to write. (The new
    `completion_signatures` and `make_completion_signatures` utilities are added
    to ease this extra burden.)

  * Sender adaptor algorithms that previously constrained their sender arguments
    to satisfy the `typed_sender` concept can no longer do so as the receiver is
    not available yet. This can result in type-checking that is done later, when
    `connect` is ultimately called on the resulting sender adaptor.

  * Operation states that own receivers that add to or change the environment
    are typically larger by one pointer. It comes with the benefit of far fewer
    indirections to evaluate queries.

**"Has it been implemented?"**

Yes, the reference implementation, which can be found at
https://github.com/brycelelbach/wg21_p2300_std_execution, has implemented this
design as well as some dependently-typed senders to confirm that it works.

**Implementation experience**

Although this change has not yet been made in libunifex, the most widely adopted sender/receiver implementation, a similar design can be found in Folly's coroutine support library. In Folly.Coro, it is possible to await a special awaitable to obtain the current coroutine's associated scheduler (called an executor in Folly).

For instance, the following Folly code grabs the current executor, schedules a task for execution on that executor, and starts the resulting (scheduled) task by enqueueing it for execution.

```c++
// From Facebook's Folly open source library:
template <class T>
folly::coro::Task<void> CancellableAsyncScope::co_schedule(folly::coro::Task<T>&& task) {
  this->add(std::move(task).scheduleOn(co_await co_current_executor));
  co_return;
}
```

Facebook relies heavily on this pattern in its coroutine code. But as described
above, this pattern doesn't work with R3 of `std::execution` because of the lack
of dependently-typed schedulers. The change to `sender_traits` in R4 rectifies that.

**Why now?**

The authors are loathe to make any changes to the design, however small, at this
stage of the C++23 release cycle. But we feel that, for a relatively minor
design change -- adding an extra template parameter to `sender_traits` and
`typed_sender` -- the returns are large enough to justify the change. And there
is no better time to make this change than as early as possible.

One might wonder why this missing feature not been added to sender/receiver
before now. The designers of sender/receiver have long been aware of the need.
What was missing was a clean, robust, and simple design for the change, which we
now have.

**Drive-by:**

We took the opportunity to make an additional drive-by change: Rather than
providing the sender traits via a class template for users to specialize, we
changed it into a sender *query*: <code>get_completion_signatures(<i>sender</i>,
<i>env</i>)</code>. That function's return type is used as the sender's traits.
The authors feel this leads to a more uniform design and gives sender authors a
straightforward way to make the value/error types dependent on the cv- and
ref-qualification of the sender if need be.

**Details:**

Below are the salient parts of the new support for dependently-typed senders in
R4:

* Receiver queries have been moved from the receiver into a separate environment
    object.
* Receivers have an associated environment. The new `get_env` CPO retrieves a
    receiver's environment. If a receiver doesn't implement `get_env`, it returns
    an unspecified "empty" environment -- an empty struct.
* `sender_traits` now takes an optional `Env` parameter that is used to
    determine the error/value types.
* The primary `sender_traits` template is replaced with a `completion_signatures_of_t`
    alias implemented in terms of a new `get_completion_signatures` CPO that dispatches
    with `tag_invoke`. `get_completion_signatures` takes a sender and an optional
    environment. A sender can customize this to specify its value/error types.
* Support for untyped senders is dropped. The `typed_sender` concept has been
    renamed to `sender` and now takes an optional environment.
* The environment argument to the `sender` concept and the `get_completion_signatures`
    CPO defaults to `no_env`. All environment queries fail (are ill-formed) when
    passed an instance of `no_env`.
* A type `S` is required to satisfy <code>sender&lt;<i>S</i>></code> to be
    considered a sender. If it doesn't know what types it will complete with
    independent of an environment, it returns an instance of the placeholder
    traits `dependent_completion_signatures`.
* If a sender satisfies both <code>sender&lt;<i>S</i>></code> and
    <code>sender&lt;<i>S</i>, <i>Env</i>></code>, then the completion signatures
    for the two cannot be different in any way. It is possible for an
    implementation to enforce this statically, but not required.
* All of the algorithms and examples have been updated to work with
    dependently-typed senders.

## R3 ## {#r3}

The changes since R2 are as follows:

<b>Fixes:</b>

    * Fix specification of the `on` algorithm to clarify lifetimes of
        intermediate operation states and properly scope the `get_scheduler` query.
    * Fix a memory safety bug in the implementation of <code><i>connect-awaitable</i></code>.
    * Fix recursive definition of the `scheduler` concept.

<b>Enhancements:</b>

    * Add `run_loop` execution context.
    * Add `receiver_adaptor` utility to simplify writing receivers.
    * Require a scheduler's sender to model `sender_of` and provide a completion scheduler.
    * Specify the cancellation scope of the `when_all` algorithm.
    * Make `as_awaitable` a customization point.
    * Change `connect`'s handling of awaitables to consider those types that are awaitable owing to customization of `as_awaitable`.
    * Add `value_types_of_t` and `error_types_of_t` alias templates; rename `stop_token_type_t` to `stop_token_of_t`.
    * Add a design rationale for the removal of the possibly eager algorithms.
    * Expand the section on field experience.

## R2 ## {#r2}

The changes since R1 are as follows:

* Remove the eagerly executing sender algorithms.
* Extend the `execution::connect` customization point and the `sender_traits<>` template to recognize awaitables as `typed_sender`s.
* Add utilities `as_awaitable()` and `with_awaitable_senders<>` so a coroutine type can trivially make senders awaitable with a coroutine.
* Add a section describing the design of the sender/awaitable interactions.
* Add a section describing the design of the cancellation support in sender/receiver.
* Add a section showing examples of simple sender adaptor algorithms.
* Add a section showing examples of simple schedulers.
* Add a few more examples: a sudoku solver, a parallel recursive file copy, and an echo server.
* Refined the forward progress guarantees on the `bulk` algorithm.
* Add a section describing how to use a range of senders to represent async sequences.
* Add a section showing how to use senders to represent partial success.
* Add sender factories `execution::just_error` and `execution::just_stopped`.
* Add sender adaptors `execution::stopped_as_optional` and `execution::stopped_as_error`.
* Document more production uses of sender/receiver at scale.
* Various fixes of typos and bugs.

## R1 ## {#r1}

The changes since R0 are as follows:

* Added a new concept, `sender_of`.
* Added a new scheduler query, `this_thread::execute_may_block_caller`.
* Added a new scheduler query, `get_forward_progress_guarantee`.
* Removed the `unschedule` adaptor.
* Various fixes of typos and bugs.

## R0 ## {#r0}

Initial revision.

# Design - introduction # {#design-intro}

The following three sections describe the entirety of the proposed design.

* [[#design-intro]] describes the conventions used through the rest of the design sections, as well as an example illustrating how we envision code will be written using this proposal.
* [[#design-user]] describes all the functionality from the perspective we intend for users: it describes the various concepts they will interact with, and what their programming model is.
* [[#design-implementer]] describes the machinery that allows for that programming model to function, and the information contained there is necessary for people implementing senders and sender algorithms (including the standard library ones) - but is not necessary to use senders productively.

## Conventions ## {#design-conventions}

The following conventions are used throughout the design section:

  1. The namespace proposed in this paper is the same as in [[P0443R14]]: `std::execution`; however, for brevity, the `std::` part of this name is omitted. When you see `execution::foo`, treat that as `std::execution::foo`.
  2. Universal references and explicit calls to `std::move`/`std::forward` are omitted in code samples and signatures for simplicity; assume universal references and perfect forwarding unless stated otherwise.
  3. None of the names proposed here are names that we are particularly attached to; consider the names to be reasonable placeholders that can freely be changed, should the committee want to do so.

## Queries and algorithms ## {#design-queries-and-algorithms}

A <dfn export=true>query</dfn> is a `std::invocable` that takes some set of objects (usually one) as parameters and returns facts about those objects without modifying them. Queries are usually customization point objects, but in some cases may be functions.

An <dfn export=true>algorithm</dfn> is a `std::invocable` that takes some set of objects as parameters and causes those objects to do something. Algorithms are usually customization point objects, but in some cases may be functions.

# Design - user side # {#design-user}

## Execution contexts describe the place of execution ## {#design-contexts}

An <dfn export=true>execution context</dfn> is a resource that represents the *place* where execution will happen. This could be a concrete resource - like a specific thread pool object, or a GPU - or a more abstract one, like the current thread of execution. Execution contexts
don't need to have a representation in code; they are simply a term describing certain properties of execution of a function.

## Schedulers represent execution contexts ## {#design-schedulers}

A <dfn export=true>scheduler</dfn> is a lightweight handle that represents a strategy for scheduling work onto an *execution context*. Since execution contexts don't necessarily manifest in C++ code, it's not possible to program
directly against their API. A scheduler is a solution to that problem: the scheduler concept is defined by a single sender algorithm, `schedule`, which returns a sender that will complete on an execution context determined
by the scheduler. Logic that you want to run on that context can be placed in the receiver's completion-signalling method.

<pre highlight="c++">
execution::scheduler auto sch = thread_pool.scheduler();
execution::sender auto snd = execution::schedule(sch);
// snd is a sender (see below) describing the creation of a new execution resource
// on the execution context associated with sch
</pre>

Note that a particular scheduler type may provide other kinds of scheduling operations
which are supported by its associated execution context. It is not limited to scheduling
purely using the `execution::schedule` API.

Future papers will propose additional scheduler concepts that extend `scheduler`
to add other capabilities. For example:
* A `time_scheduler` concept that extends `scheduler` to support time-based scheduling.
    Such a concept might provide access to `schedule_after(sched, duration)`, `schedule_at(sched, time_point)` and `now(sched)` APIs.
* Concepts that extend `scheduler` to support opening, reading and writing files asynchronously.
* Concepts that extend `scheduler` to support connecting, sending data and receiving data over the network asynchronously.

## Senders describe work ## {#design-senders}

A <dfn export=true>sender</dfn> is an object that describes work. Senders are similar to futures in existing asynchrony designs, but unlike futures, the work that is being done to arrive at the values they will *send* is also directly described by the sender object itself. A
sender is said to <dfn export=true>send</dfn> some values if a receiver connected (see [[#design-connect]]) to that sender will eventually *receive* said values.

The primary defining sender algorithm is [[#design-connect]]; this function, however, is not a user-facing API; it is used to facilitate communication between senders and various sender algorithms, but end user code is not expected to invoke
it directly.

The way user code is expected to interact with senders is by using [=sender algorithms=].
This paper proposes an initial set of such sender algorithms, which are described in [[#design-composable]], [[#design-sender-factories]], [[#design-sender-adaptors]], and [[#design-sender-consumers]].
For example, here is how a user can create a new sender on a scheduler, attach a continuation to it, and then wait for execution of the continuation to complete:

<pre highlight="c++">
execution::scheduler auto sch = thread_pool.scheduler();
execution::sender auto snd = execution::schedule(sch);
execution::sender auto cont = execution::then(snd, []{
    std::fstream file{ "result.txt" };
    file << compute_result;
});

this_thread::sync_wait(cont);
// at this point, cont has completed execution
</pre>

## Senders are composable through sender algorithms ## {#design-composable}

Asynchronous programming often departs from traditional code structure and control flow that we are familiar with.
A successful asynchronous framework must provide an intuitive story for composition of asynchronous work: expressing dependencies, passing objects, managing object lifetimes, etc.

The true power and utility of senders is in their composability.
With senders, users can describe generic execution pipelines and graphs, and then run them on and across a variety of different schedulers.
Senders are composed using <dfn export=true>sender algorithms</dfn>:

* [=sender factories=], algorithms that take no senders and return a sender.
* [=sender adaptors=], algorithms that take (and potentially `execution::connect`) senders and return a sender.
* [=sender consumers=], algorithms that take (and potentially `execution::connect`) senders and do not return a sender.

## Senders can propagate completion schedulers ## {#design-propagation}

One of the goals of executors is to support a diverse set of execution contexts, including traditional thread pools, task and fiber frameworks (like <a href="https://github.com/STEllAR-GROUP/hpx">HPX</a> and [Legion](https://github.com/StanfordLegion/legion)), and GPUs and other accelerators (managed by runtimes such as CUDA or SYCL).
On many of these systems, not all execution agents are created equal and not all functions can be run on all execution agents.
Having precise control over the execution context used for any given function call being submitted is important on such systems, and the users of standard execution facilities will expect to be able to express such requirements.

[[P0443R14]] was not always clear about the <i>place of execution</i> of any given piece of code.
Precise control was present in the two-way execution API present in earlier executor designs, but it has so far been missing from the senders design. There has been a proposal ([[P1897R3]]) to provide a number of sender algorithms that would enforce certain rules on the places of execution
of the work described by a sender, but we have found those sender algorithms to be insufficient for achieving the best performance on all platforms that are of interest to us. The implementation strategies that we are aware of result in one of the following situations:

  1. trying to submit work to one execution context (such as a CPU thread pool) from another execution context (such as a GPU or a task framework), which assumes that all execution agents are as capable as a `std::thread` (which they aren't).
  2. forcibly interleaving two adjacent execution graph nodes that are both executing on one execution context (such as a GPU) with glue code that runs on another execution context (such as a CPU), which is prohibitively expensive for some execution contexts (such as CUDA or SYCL).
  3. having to customise most or all sender algorithms to support an execution context, so that you can avoid problems described in 1. and 2, which we believe is impractical and brittle based on months of field experience attempting this in [Agency](https://github.com/agency-library/agency).

None of these implementation strategies are acceptable for many classes of parallel runtimes, such as task frameworks (like <a href="https://github.com/STEllAR-GROUP/hpx">HPX</a>) or accelerator runtimes (like CUDA or SYCL).

Therefore, in addition to the `on` sender algorithm from [[P1897R3]], we are proposing a way for senders to advertise what scheduler (and by extension what execution context) they will complete on.
Any given sender <b>may</b> have <dfn export=true>completion schedulers</dfn> for some or all of the signals (value, error, or stopped) it completes with (for more detail on the completion signals, see [[#design-receivers]]).
When further work is attached to that sender by invoking sender algorithms, that work will also complete on an appropriate completion scheduler.

### `execution::get_completion_scheduler` ### {#design-sender-query-get_completion_scheduler}

`get_completion_scheduler` is a query that retrieves the [=completion scheduler=] for a specific completion signal from a sender.
Calling `get_completion_scheduler` on a sender that does not have a completion scheduler for a given signal is ill-formed.
If a sender advertises a completion scheduler for a signal in this way, that sender <b>must</b> ensure that it [=send|sends=] that signal on an execution agent belonging to an execution context represented by a scheduler returned from this function.
See [[#design-propagation]] for more details.

<pre highlight="c++">
execution::scheduler auto cpu_sched = new_thread_scheduler{};
execution::scheduler auto gpu_sched = cuda::scheduler();

execution::sender auto snd0 = execution::schedule(cpu_sched);
execution::scheduler auto completion_sch0 =
  execution::get_completion_scheduler&lt;execution::set_value_t>(snd0);
// completion_sch0 is equivalent to cpu_sched

execution::sender auto snd1 = execution::then(snd0, []{
    std::cout << "I am running on cpu_sched!\n";
});
execution::scheduler auto completion_sch1 =
  execution::get_completion_scheduler&lt;execution::set_value_t>(snd1);
// completion_sch1 is equivalent to cpu_sched

execution::sender auto snd2 = execution::transfer(snd1, gpu_sched);
execution::sender auto snd3 = execution::then(snd2, []{
    std::cout << "I am running on gpu_sched!\n";
});
execution::scheduler auto completion_sch3 =
  execution::get_completion_scheduler&lt;execution::set_value_t>(snd3);
// completion_sch3 is equivalent to gpu_sched
</pre>

## Execution context transitions are explicit ## {#design-transitions}

[[P0443R14]] does not contain any mechanisms for performing an execution context transition. The only sender algorithm that can create a sender that will move execution to a *specific* execution context is `execution::schedule`, which does not take an input sender.
That means that there's no way to construct sender chains that traverse different execution contexts. This is necessary to fulfill the promise of senders being able to replace two-way executors, which had this capability.

We propose that, for senders advertising their [=completion scheduler=], all execution context transitions <b>must</b> be explicit; running user code anywhere but where they defined it to run <b>must</b> be considered a bug.

The `execution::transfer` sender adaptor performs a transition from one execution context to another:

<pre highlight="c++">
execution::scheduler auto sch1 = ...;
execution::scheduler auto sch2 = ...;

execution::sender auto snd1 = execution::schedule(sch1);
execution::sender auto then1 = execution::then(snd1, []{
    std::cout << "I am running on sch1!\n";
});

execution::sender auto snd2 = execution::transfer(then1, sch2);
execution::sender auto then2 = execution::then(snd2, []{
    std::cout << "I am running on sch2!\n";
});

this_thread::sync_wait(then2);
</pre>

## Senders can be either multi-shot or single-shot ## {#design-shot}

Some senders may only support launching their operation a single time, while others may be repeatable
and support being launched multiple times. Executing the operation may consume resources owned by the
sender.

For example, a sender may contain a `std::unique_ptr` that it will be transferring ownership of to the
operation-state returned by a call to `execution::connect` so that the operation has access to
this resource. In such a sender, calling `execution::connect` consumes the sender such that after
the call the input sender is no longer valid. Such a sender will also typically be move-only so that
it can maintain unique ownership of that resource.

A <dfn export=true>single-shot sender</dfn> can only be connected to a receiver at most once. Its implementation of
`execution::connect` only has overloads for an rvalue-qualified sender. Callers must pass the sender
as an rvalue to the call to `execution::connect`, indicating that the call consumes the sender.

A <dfn export=true>multi-shot sender</dfn> can be connected to multiple receivers and can be launched multiple
times. Multi-shot senders customise `execution::connect` to accept an lvalue reference to the
sender. Callers can indicate that they want the sender to remain valid after the call to `execution::connect`
by passing an lvalue reference to the sender to call these overloads. Multi-shot senders should also define
overloads of `execution::connect` that accept rvalue-qualified senders to allow the sender to be also used in places
where only a single-shot sender is required.

If the user of a sender does not require the sender to remain valid after connecting it to a
receiver then it can pass an rvalue-reference to the sender to the call to `execution::connect`.
Such usages should be able to accept either single-shot or multi-shot senders.

If the caller does wish for the sender to remain valid after the call then it can pass an lvalue-qualified sender
to the call to `execution::connect`. Such usages will only accept multi-shot senders.

Algorithms that accept senders will typically either decay-copy an input sender and store it somewhere
for later usage (for example as a data-member of the returned sender) or will immediately call
`execution::connect` on the input sender, such as in `this_thread::sync_wait` or `execution::start_detached`.

Some multi-use sender algorithms may require that an input sender be copy-constructible but will only call
`execution::connect` on an rvalue of each copy, which still results in effectively executing the operation multiple times.
Other multi-use sender algorithms may require that the sender is move-constructible but will invoke `execution::connect`
on an lvalue reference to the sender.

For a sender to be usable in both multi-use scenarios, it will generally be required to be both copy-constructible and lvalue-connectable.

## Senders are forkable ## {#design-forkable}

Any non-trivial program will eventually want to fork a chain of senders into independent streams of work, regardless of whether they are single-shot or multi-shot.
For instance, an incoming event to a middleware system may be required to trigger events on more than one downstream system.
This requires that we provide well defined mechanisms for making sure that connecting a sender multiple times is possible and correct.

The `split` sender adaptor facilitates connecting to a sender multiple times, regardless of whether it is single-shot or multi-shot:

<pre highlight=c++>
auto some_algorithm(execution::sender auto&& input) {
    execution::sender auto multi_shot = split(input);
    // "multi_shot" is guaranteed to be multi-shot,
    // regardless of whether "input" was multi-shot or not

    return when_all(
      then(multi_shot, [] { std::cout << "First continuation\n"; }),
      then(multi_shot, [] { std::cout << "Second continuation\n"; })
    );
}
</pre>

## Senders are joinable ## {#design-join}

Similarly to how it's hard to write a complex program that will eventually want to fork sender chains into independent streams, it's also hard to write a program that does not want to eventually create join nodes, where multiple independent streams of execution are
merged into a single one in an asynchronous fashion.

`when_all` is a sender adaptor that returns a sender that completes when the last of the input senders completes. It [=send|sends=] a pack of values, where the elements of said pack are the values sent by the input senders, in order. `when_all` returns a sender that also does not have an associated scheduler.

`transfer_when_all` accepts an additional scheduler argument. It returns a sender whose value [=completion scheduler=] is the scheduler provided as an argument, but otherwise behaves the same as `when_all`. You can think of it as a composition of
`transfer(when_all(inputs...), scheduler)`, but one that allows for better efficiency through customization.

## Senders support cancellation ## {#design-cancellation}

Senders are often used in scenarios where the application may be concurrently executing
multiple strategies for achieving some program goal. When one of these strategies succeeds
(or fails) it may not make sense to continue pursuing the other strategies as their results
are no longer useful.

For example, we may want to try to simultaneously connect to multiple network servers and use
whichever server responds first. Once the first server responds we no longer need to continue
trying to connect to the other servers.

Ideally, in these scenarios, we would somehow be able to request that those other strategies
stop executing promptly so that their resources (e.g. cpu, memory, I/O bandwidth) can be
released and used for other work.

While the design of senders has support for cancelling an operation before it starts
by simply destroying the sender or the operation-state returned from `execution::connect()`
before calling `execution::start()`, there also needs to be a standard, generic mechanism
to ask for an already-started operation to complete early.

The ability to be able to cancel in-flight operations is fundamental to supporting some kinds
of generic concurrency algorithms.

For example:
* a `when_all(ops...)` algorithm should cancel other operations as soon as one operation fails
* a `first_successful(ops...)` algorithm should cancel the other operations as soon as one operation completes successfuly
* a generic `timeout(src, duration)` algorithm needs to be able to cancel the `src` operation after the timeout duration has elapsed.
* a `stop_when(src, trigger)` algorithm should cancel `src` if `trigger` completes first and cancel `trigger` if `src` completes first


The mechanism used for communcating cancellation-requests, or stop-requests, needs to have a uniform interface
so that generic algorithms that compose sender-based operations, such as the ones listed above, are able to
communicate these cancellation requests to senders that they don't know anything about.

The design is intended to be composable so that cancellation of higher-level operations can propagate
those cancellation requests through intermediate layers to lower-level operations that need to actually
respond to the cancellation requests.

For example, we can compose the algorithms mentioned above so that child operations
are cancelled when any one of the multiple cancellation conditions occurs:
<pre highlight=c++>
sender auto composed_cancellation_example(auto query) {
  return stop_when(
    timeout(
      when_all(
        first_successful(
          query_server_a(query),
          query_server_b(query)),
        load_file("some_file.jpg")),
      5s),
    cancelButton.on_click());
}
</pre>

In this example, if we take the operation returned by `query_server_b(query)`, this operation will
receive a stop-request when any of the following happens:
* `first_successful` algorithm will send a stop-request if `query_server_a(query)` completes successfully
* `when_all` algorithm will send a stop-request if the `load_file("some_file.jpg")` operation completes with an error or stopped result.
* `timeout` algorithm will send a stop-request if the operation does not complete within 5 seconds.
* `stop_when` algorithm will send a stop-request if the user clicks on the "Cancel" button in the user-interface.
* The parent operation consuming the `composed_cancellation_example()` sends a stop-request


Note that within this code there is no explicit mention of cancellation, stop-tokens, callbacks, etc.
yet the example fully supports and responds to the various cancellation sources.

The intent of the design is that the common usage of cancellation in sender/receiver-based code is
primarily through use of concurrency algorithms that manage the detailed plumbing of cancellation
for you. Much like algorithms that compose senders relieve the user from having to write their own
receiver types, algorithms that introduce concurrency and provide higher-level cancellation semantics
relieve the user from having to deal with low-level details of cancellation.

### Cancellation design summary ### {#design-cancellation-summary}

The design of cancellation described in this paper is built on top of and extends the `std::stop_token`-based
cancellation facilities added in C++20, first proposed in [[P2175R0]].

At a high-level, the facilities proposed by this paper for supporting cancellation include:
* Add `std::stoppable_token` and `std::stoppable_token_for` concepts that generalise the interface of `std::stop_token` type to allow other types with different implementation strategies.
* Add `std::unstoppable_token` concept for detecting whether a `stoppable_token` can never receive a stop-request.
* Add `std::in_place_stop_token`, `std::in_place_stop_source` and `std::in_place_stop_callback<CB>` types that provide a more efficient implementation of a stop-token for use in structured concurrency situations.
* Add `std::never_stop_token` for use in places where you never want to issue a stop-request
* Add `std::execution::get_stop_token()` CPO for querying the stop-token to use for an operation from its receiver's execution environment.
* Add `std::execution::stop_token_of_t<T>` for querying the type of a stop-token returned from `get_stop_token()`

In addition, there are requirements added to some of the algorithms to specify what their cancellation
behaviour is and what the requirements of customisations of those algorithms are with respect to
cancellation.

The key component that enables generic cancellation within sender-based operations is the `execution::get_stop_token()` CPO.
This CPO takes a single parameter, which is the execution environment of the receiver passed to `execution::connect`, and returns a `std::stoppable_token`
that the operation can use to check for stop-requests for that operation.

As the caller of `execution::connect` typically has control over the receiver
type it passes, it is able to customise the `execution::get_env()` CPO for that
receiver to return an execution environment that hooks the
`execution::get_stop_token()` CPO to return a stop-token that the receiver has
control over and that it can use to communicate a stop-request to the operation
once it has started.

### Support for cancellation is optional ### {#design-cancellation-optional}

Support for cancellation is optional, both on part of the author of the receiver and on part of the author of the sender.

If the receiver's execution environment does not customise the
`execution::get_stop_token()` CPO then invoking the CPO on that receiver's
environment will invoke the default implementation which returns
`std::never_stop_token`. This is a special `stoppable_token` type that is
statically known to always return `false` from the `stop_possible()` method.

Sender code that tries to use this stop-token will in general result in code that handles stop-requests being
compiled out and having little to no run-time overhead.

If the sender doesn't call `execution::get_stop_token()`, for example because the operation does not support
cancellation, then it will simply not respond to stop-requests from the caller.

Note that stop-requests are generally racy in nature as there is often a race betwen an operation completing
naturally and the stop-request being made. If the operation has already completed or past the point at which
it can be cancelled when the stop-request is sent then the stop-request may just be ignored. An application
will typically need to be able to cope with senders that might ignore a stop-request anyway.

### Cancellation is inherently racy ### {#design-cancellation-racy}

Usually, an operation will attach a stop-callback at some point inside the call to `execution::start()` so that
a subsequent stop-request will interrupt the logic.

A stop-request can be issued concurrently from another thread. This means the implementation of `execution::start()`
needs to be careful to ensure that, once a stop-callback has been registered, that there are no data-races between
a potentially concurrently-executing stop-callback and the rest of the `execution::start()` implementation.

An implementation of `execution::start()` that supports cancellation will generally need to perform (at least)
two separate steps: launch the operation, subscribe a stop-callback to the receiver's stop-token. Care needs
to be taken depending on the order in which these two steps are performed.

If the stop-callback is subscribed first and then the operation is launched, care needs to be taken to ensure
that a stop-request that invokes the stop-callback on another thread after the stop-callback is registered
but before the operation finishes launching does not either result in a missed cancellation request or a
data-race. e.g. by performing an atomic write after the launch has finished executing

If the operation is launched first and then the stop-callback is subscribed, care needs to be taken to ensure
that if the launched operation completes concurrently on another thread that it does not destroy the operation-state
until after the stop-callback has been registered. e.g. by having the `execution::start` implementation write to
an atomic variable once it has finished registering the stop-callback and having the concurrent completion handler
check that variable and either call the completion-signalling operation or store the result and defer calling the
receiver's completion-signalling operation to the `execution::start()` call (which is still executing).

For an example of an implementation strategy for solving these data-races see [[#example-async-windows-socket-recv]].

### Cancellation design status ### {#design-cancellation-status}

This paper currently includes the design for cancellation as proposed in
[[P2175R0]] - "Composable cancellation for sender-based async operations".
P2175R0 contains more details on the background motivation and prior-art and design rationale of this design.

It is important to note, however, that initial review of this design in the SG1 concurrency subgroup raised some concerns
related to runtime overhead of the design in single-threaded scenarios and these concerns are still being investigated.

The design of P2175R0 has been included in this paper for now, despite its potential to change, as we believe that
support for cancellation is a fundamental requirement for an async model and is required in some form to be able to
talk about the semantics of some of the algorithms proposed in this paper.

This paper will be updated in the future with any changes that arise from the investigations into P2175R0.

## Sender factories and adaptors are lazy ## {#design-lazy-algorithms}

In an earlier revision of this paper, some of the proposed algorithms supported
executing their logic eagerly; <i>i.e.</i>, before the returned sender has been
connected to a receiver and started. These algorithms were removed because eager
execution has a number of negative semantic and performance implications.

We have originally included this functionality in the paper because of a long-standing
belief that eager execution is a mandatory feature to be included in the standard Executors
facility for that facility to be acceptable for accelerator vendors. A particular concern
was that we must be able to write generic algorithms that can run either eagerly or lazily,
depending on the kind of an input sender or scheduler that have been passed into them as
arguments. We considered this a requirement, because the _latency_ of launching work on an
accelerator can sometimes be considerable.

However, in the process of working on this paper and implementations of the features
proposed within, our set of requirements has shifted, as we understood the different
implementation strategies that are available for the feature set of this paper better,
and, after weighting the earlier concerns against the points presented below, we
have arrived at the conclusion that a purely lazy model is enough for most algorithms,
and users who intend to launch work earlier may use an algorithm such as `ensure_started`
to achieve that goal. We have also come to deeply appreciate the fact that a purely
lazy model allows both the implementation and the compiler to have a much better
understanding of what the complete graph of tasks looks like, allowing them to better
optimize the code - also when targetting accelerators.

### Eager execution leads to detached work or worse ### {#design-lazy-algorithms-detached}

One of the questions that arises with APIs that can potentially return
eagerly-executing senders is "What happens when those senders are destructed
without a call to `execution::connect`?" or similarly, "What happens if a call
to `execution::connect` is made, but the returned operation state is destroyed
before `execution::start` is called on that operation state"?

In these cases, the operation represented by the sender is potentially executing
concurrently in another thread at the time that the destructor of the sender
and/or operation-state is running. In the case that the operation has not
completed executing by the time that the destructor is run we need to decide
what the semantics of the destructor is.

There are three main strategies that can be adopted here, none of which is
particularly satisfactory:

1.  Make this undefined-behaviour - the caller must ensure that any
    eagerly-executing sender is always joined by connecting and starting that
    sender. This approach is generally pretty hostile to programmers,
    particularly in the presence of exceptions, since it complicates the ability
    to compose these operations.

    Eager operations typically need to acquire resources when they are first
    called in order to start the operation early. This makes eager algorithms
    prone to failure. Consider, then, what might happen in an expression such as
    `when_all(eager_op_1(), eager_op_2())`. Imagine `eager_op_1()` starts an
    asynchronous operation successfully, but then `eager_op_2()` throws. For
    lazy senders, that failure happens in the context of the `when_all`
    algorithm, which handles the failure and ensures that async work joins on
    all code paths. In this case though -- the eager case -- the child operation
    has failed even before `when_all` has been called.

    It then becomes the responsibility, not of the algorithm, but of the end
    user to handle the exception and ensure that `eager_op_1()` is joined before
    allowing the exception to propagate. If they fail to do that, they incur
    undefined behavior.

2.  Detach from the computation - let the operation continue in the background -
    like an implicit call to `std::thread::detach()`. While this approach can
    work in some circumstances for some kinds of applications, in general it is
    also pretty user-hostile; it makes it difficult to reason about the safe
    destruction of resources used by these eager operations. In general,
    detached work necessitates some kind of garbage collection; <i>e.g.</i>,
    `std::shared_ptr`, to ensure resources are kept alive until the operations
    complete, and can make clean shutdown nigh impossible.

3.  Block in the destructor until the operation completes. This approach is
    probably the safest to use as it preserves the structured nature of the
    concurrent operations, but also introduces the potential for deadlocking the
    application if the completion of the operation depends on the current thread
    making forward progress.

      The risk of deadlock might occur, for example, if a thread-pool with a
    small number of threads is executing code that creates a sender representing
    an eagerly-executing operation and then calls the destructor of that sender
    without joining it (e.g. because an exception was thrown). If the current
    thread blocks waiting for that eager operation to complete and that eager
    operation cannot complete until some entry enqueued to the thread-pool's
    queue of work is run then the thread may wait for an indefinite amount of
    time. If all thread of the thread-pool are simultaneously performing such
    blocking operations then deadlock can result.

There are also minor variations on each of these choices. For example:

4.  A variation of (1): Call `std::terminate` if an eager sender is destructed
    without joining it. This is the approach that `std::thread` destructor
    takes.

5.  A variation of (2): Request cancellation of the operation before detaching.
    This reduces the chances of operations continuing to run indefinitely in the
    background once they have been detached but does not solve the
    lifetime- or shutdown-related challenges.

6.  A variation of (3): Request cancellation of the operation before blocking on
    its completion. This is the strategy that `std::jthread` uses for its
    destructor. It reduces the risk of deadlock but does not eliminate it.

### Eager senders complicate algorithm implementations ### {#design-lazy-algorithms-complexity}

Algorithms that can assume they are operating on senders with strictly lazy
semantics are able to make certain optimizations that are not available if
senders can be potentially eager. With lazy senders, an algorithm can safely
assume that a call to `execution::start` on an operation state strictly happens
before the execution of that async operation. This frees the algorithm from
needing to resolve potential race conditions. For example, consider an algorithm
`sequence` that puts async operations in sequence by starting an operation only
after the preceding one has completed. In an expression like `sequence(a(),
then(src, [] { b(); }), c())`, one my reasonably assume that `a()`, `b()` and
`c()` are sequenced and therefore do not need synchronisation. Eager algorithms
break that assumption.

When an algorithm needs to deal with potentially eager senders, the potential
race conditions can be resolved one of two ways, neither of which is desirable:

1.  Assume the worst and implement the algorithm defensively, assuming all
    senders are eager. This obviously has overheads both at runtime and in
    algorithm complexity. Resolving race conditions is hard.

2.  Require senders to declare whether they are eager or not with a query.
    Algorithms can then implement two different implementation strategies, one
    for strictly lazy senders and one for potentially eager senders. This
    addresses the performance problem of (1) while compounding the complexity
    problem.

### Eager senders incur cancellation-related overhead ### {#design-lazy-algorithms-runtime}

Another implication of the use of eager operations is with regards to
cancellation. The eagerly executing operation will not have access to the
caller's stop token until the sender is connected to a receiver. If we still
want to be able to cancel the eager operation then it will need to create a new
stop source and pass its associated stop token down to child operations. Then
when the returned sender is eventually connected it will register a stop
callback with the receiver's stop token that will request stop on the eager
sender's stop source.

As the eager operation does not know at the time that it is launched what the
type of the receiver is going to be, and thus whether or not the stop token
returned from `execution::get_stop_token` is an `std::unstoppable_token` or not,
the eager operation is going to need to assume it might be later connected to a
receiver with a stop token that might actually issue a stop request. Thus it
needs to declare space in the operation state for a type-erased stop callback
and incur the runtime overhead of supporting cancellation, even if cancellation
will never be requested by the caller.

The eager operation will also need to do this to support sending a stop request
to the eager operation in the case that the sender representing the eager work
is destroyed before it has been joined (assuming strategy (5) or (6) listed
above is chosen).

### Eager senders cannot access execution context from the receiver ### {#design-lazy-algorithms-context}

In sender/receiver, contextual information is passed from parent operations to
their children by way of receivers. Information like stop tokens, allocators,
current scheduler, priority, and deadline are propagated to child operations
with custom receivers at the time the operation is connected. That way, each
operation has the contextual information it needs before it is started.

But if the operation is started before it is connected to a receiver, then there
isn't a way for a parent operation to communicate contextual information to its
child operations, which may complete before a receiver is ever attached.

## Schedulers advertise their forward progress guarantees ## {#design-fpg}

To decide whether a scheduler (and its associated execution context) is sufficient for a specific task, it may be necessary to know what kind of forward progress guarantees it provides for the execution agents it creates. The C++ Standard defines the following
forward progress guarantees:

* <i>concurrent</i>, which requires that a thread makes progress <i>eventually</i>;
* <i>parallel</i>, which requires that a thread makes progress once it executes a step; and
* <i>weakly parallel</i>, which does not require that the thread makes progress.

This paper introduces a scheduler query function, `get_forward_progress_guarantee`, which returns one of the enumerators of a new `enum` type, `forward_progress_guarantee`. Each enumerator of `forward_progress_guarantee` corresponds to one of the aforementioned
guarantees.

## Most sender adaptors are pipeable ## {#design-pipeable}

To facilitate an intuitive syntax for composition, most sender adaptors are <dfn export=true>pipeable</dfn>; they can be composed (<dfn export=true>piped</dfn>) together with `operator|`.
This mechanism is similar to the `operator|` composition that C++ range adaptors support and draws inspiration from piping in *nix shells.
Pipeable sender adaptors take a sender as their first parameter and have no other sender parameters.

`a | b` will pass the sender `a` as the first argument to the pipeable sender adaptor `b`. Pipeable sender adaptors support partial application of the parameters after the first. For example, all of the following are equivalent:

<pre highlight=c++>
execution::bulk(snd, N, [] (std::size_t i, auto d) {});
execution::bulk(N, [] (std::size_t i, auto d) {})(snd);
snd | execution::bulk(N, [] (std::size_t i, auto d) {});
</pre>

Piping enables you to compose together senders with a linear syntax.
Without it, you'd have to use either nested function call syntax, which would cause a syntactic inversion of the direction of control flow, or you'd have to introduce a temporary variable for each stage of the pipeline.
Consider the following example where we want to execute first on a CPU thread pool, then on a CUDA GPU, then back on the CPU thread pool:

<table>
<tr>
<th>Syntax Style
<th>Example
<tr>
<th>Function call <br/> (nested)
<td><pre highlight=c++>
auto snd = execution::then(
             execution::transfer(
               execution::then(
                 execution::transfer(
                   execution::then(
                     execution::schedule(thread_pool.scheduler())
                     []{ return 123; }),
                   cuda::new_stream_scheduler()),
                 [](int i){ return 123 * 5; }),
               thread_pool.scheduler()),
             [](int i){ return i - 5; });
auto [result] = this_thread::sync_wait(snd).value();
// result == 610
</pre>
<tr>
<th>Function call <br/> (named temporaries)
<td><pre highlight=c++>
auto snd0 = execution::schedule(thread_pool.scheduler());
auto snd1 = execution::then(snd0, []{ return 123; });
auto snd2 = execution::transfer(snd1, cuda::new_stream_scheduler());
auto snd3 = execution::then(snd2, [](int i){ return 123 * 5; })
auto snd4 = execution::transfer(snd3, thread_pool.scheduler())
auto snd5 = execution::then(snd4, [](int i){ return i - 5; });
auto [result] = *this_thread::sync_wait(snd4);
// result == 610
</pre>
<tr>
<th>Pipe
<td><pre highlight=c++>
auto snd = execution::schedule(thread_pool.scheduler())
         | execution::then([]{ return 123; })
         | execution::transfer(cuda::new_stream_scheduler())
         | execution::then([](int i){ return 123 * 5; })
         | execution::transfer(thread_pool.scheduler())
         | execution::then([](int i){ return i - 5; });
auto [result] = this_thread::sync_wait(snd).value();
// result == 610
</pre>
</table>

Certain sender adaptors are not pipeable, because using the pipeline syntax can result in confusion of the semantics of the adaptors involved. Specifically, the following sender adaptors are not pipeable.

* `execution::when_all` and `execution::when_all_with_variant`: Since this sender adaptor takes a variadic pack of senders, a partially applied form would be ambiguous with a non partially applied form with an arity of one less.
* `execution::on`: This sender adaptor changes how the sender passed to it is executed, not what happens to its result, but allowing it in a pipeline makes it read as if it performed a function more similar to `transfer`.

Sender consumers could be made pipeable, but we have chosen to not do so.
However, since these are terminal nodes in a pipeline and nothing can be piped after them, we believe a pipe syntax may be confusing as well as unnecessary, as consumers cannot be chained.
We believe sender consumers read better with function call syntax.

## A range of senders represents an async sequence of data ## {#design-range-of-senders}

Senders represent a single unit of asynchronous work. In many cases though, what is being modelled is a sequence of data arriving asynchronously, and you want computation to happen on demand, when each element arrives. This requires nothing more than what is in this paper and the range support in C++20. A range of senders would allow you to model such input as keystrikes, mouse movements, sensor readings, or network requests.

Given some expression <code><i>R</i></code> that is a range of senders, consider the following in a coroutine that returns an async generator type:

    <pre highlight="c++">
    for (auto snd : <i>R</i>) {
      if (auto opt = co_await execution::stopped_as_optional(std::move(snd)))
        co_yield fn(*std::move(opt));
      else
        break;
    }
    </pre>

This transforms each element of the asynchronous sequence <code><i>R</i></code> with the function `fn` on demand, as the data arrives. The result is a new asynchronous sequence of the transformed values.

Now imagine that <code><i>R</i></code> is the simple expression `views::iota(0) | views::transform(execution::just)`. This creates a lazy range of senders, each of which completes immediately with monotonically increasing integers. The above code churns through the range, generating a new infine asynchronous range of values [`fn(0)`, `fn(1)`, `fn(2)`, ...].

Far more interesting would be if <code><i>R</i></code> were a range of senders representing, say, user actions in a UI. The above code gives a simple way to respond to user actions on demand.

## Senders can represent partial success ## {#design-partial-success}

Receivers have three ways they can complete: with success, failure, or cancellation. This begs the question of how they can be used to represent async operations that *partially* succeed. For example, consider an API that reads from a socket. The connection could drop after the API has filled in some of the buffer. In cases like that, it makes sense to want to report both that the connection dropped and that some data has been successfully read.

Often in the case of partial success, the error condition is not fatal nor does it mean the API has failed to satisfy its post-conditions. It is merely an extra piece of information about the nature of the completion. In those cases, "partial success" is another way of saying "success". As a result, it is sensible to pass both the error code and the result (if any) through the value channel, as shown below:

    <pre highlight="c++">
    // Capture a buffer for read_socket_async to fill in
    execution::just(array&lt;byte, 1024>{})
      | execution::let_value([socket](array&lt;byte, 1024>& buff) {
          // read_socket_async completes with two values: an error_code and
          // a count of bytes:
          return read_socket_async(socket, span{buff})
              // For success (partial and full), specify the next action:
            | execution::let_value([](error_code err, size_t bytes_read) {
                if (err != 0) {
                  // OK, partial success. Decide how to deal with the partial results
                } else {
                  // OK, full success here.
                }
              });
        })
    </pre>

In other cases, the partial success is more of a partial *failure*. That happens when the error condition indicates that in some way the function failed to satisfy its post-conditions. In those cases, sending the error through the value channel loses valuable contextual information. It's possible that bundling the error and the incomplete results into an object and passing it through the error channel makes more sense. In that way, generic algorithms will not miss the fact that a post-condition has not been met and react inappropriately.

Another possibility is for an async API to return a *range* of senders: if the API completes with full success, full error, or cancellation, the returned range contains just one sender with the result. Otherwise, if the API partially fails (doesn't satisfy its post-conditions, but some incomplete result is available), the returned range would have *two* senders: the first containing the partial result, and the second containing the error. Such an API might be used in a coroutine as follows:

    <pre highlight="c++">
    // Declare a buffer for read_socket_async to fill in
    array&lt;byte, 1024> buff;

    for (auto snd : read_socket_async(socket, span{buff})) {
      try {
        if (optional&lt;size_t> bytes_read =
              co_await execution::stopped_as_optional(std::move(snd)))
          // OK, we read some bytes into buff. Process them here....
        } else {
          // The socket read was cancelled and returned no data. React
          // appropriately.
        }
      } catch (...) {
        // read_socket_async failed to meet its post-conditions.
        // Do some cleanup and propagate the error...
      }
    }
    </pre>

Finally, it's possible to combine these two approaches when the API can both partially succeed (meeting its post-conditions) and partially fail (not meeting its post-conditions).

## All awaitables are senders ## {#design-awaitables-are-senders}

Since C++20 added coroutines to the standard, we expect that coroutines and awaitables will be how a great many will choose to express their asynchronous code. However, in this paper, we are proposing to add a suite of asynchronous algorithms that accept senders, not awaitables. One might wonder whether and how these algorithms will be accessible to those who choose coroutines instead of senders.

In truth there will be no problem because all generally awaitable types
automatically model the `sender` concept. The adaptation is transparent and
happens in the sender customization points, which are aware of awaitables. (By
"generally awaitable" we mean types that don't require custom `await_transform`
trickery from a promise type to make them awaitable.)

For an example, imagine a coroutine type called `task<T>` that knows nothing
about senders. It doesn't implement any of the sender customization points.
Despite that fact, and despite the fact that the `this_thread::sync_wait`
algorithm is constrained with the `sender` concept, the following would compile
and do what the user wants:

```c++
task<int> doSomeAsyncWork();

int main() {
  // OK, awaitable types satisfy the requirements for senders:
  auto o = this_thread::sync_wait(doSomeAsyncWork());
}
```

Since awaitables are senders, writing a sender-based asynchronous algorithm is trivial if you have a coroutine task type: implement the algorithm as a coroutine. If you are not bothered by the possibility of allocations and indirections as a result of using coroutines, then there is no need to ever write a sender, a receiver, or an operation state.

## Many senders can be trivially made awaitable ## {#design-senders-are-awaitable}

If you choose to implement your sender-based algorithms as coroutines, you'll run into the issue of how to retrieve results from a passed-in sender. This is not a problem. If the coroutine type opts in to sender support -- trivial with the `execution::with_awaitable_senders` utility -- then a large class of senders are transparently awaitable from within the coroutine.

For example, consider the following trivial implementation of the sender-based `retry` algorithm:

<pre highlight="c++">
template &lt;class S>
  requires <i>single-sender</i>&lt;S&> // See <a href="#spec-execution.coro_utils.as_awaitable">[exec.as_awaitable]</a>
task&lt;<i>single-sender-value-type</i>&lt;S>> retry(S s) {
  for (;;) {
    try {
      co_return co_await s;
    } catch(...) {
    }
  }
}
</pre>

Only *some* senders can be made awaitable directly because of the fact that callbacks are more expressive than coroutines. An awaitable expression has a single type: the result value of the async operation. In contrast, a callback can accept multiple arguments as the result of an operation. What's more, the callback can have overloaded function call signatures that take different sets of arguments. There is no way to automatically map such senders into awaitables. The `with_awaitable_senders` utility recognizes as awaitables those senders that send a single value of a single type. To await another kind of sender, a user would have to first map its value channel into a single value of a single type -- say, with the `into_variant` sender algorithm -- before `co_await`-ing that sender.

## Cancellation of a sender can unwind a stack of coroutines ## {#design-native-coro-unwind}

When looking at the sender-based `retry` algorithm in the previous section, we can see that the value and error cases are correctly handled. But what about cancellation? What happens to a coroutine that is suspended awaiting a sender that completes by calling `execution::set_stopped`?

When your task type's promise inherits from `with_awaitable_senders`, what happens is this: the coroutine behaves as if an *uncatchable exception* had been thrown from the `co_await` expression. (It is not really an exception, but it's helpful to think of it that way.) Provided that the promise types of the calling coroutines also inherit from `with_awaitable_senders`, or more generally implement a member function called `unhandled_stopped`, the exception unwinds the chain of coroutines as if an exception were thrown except that it bypasses `catch(...)` clauses.

In order to "catch" this uncatchable stopped exception, one of the calling coroutines in the stack would have to await a sender that maps the stopped channel into either a value or an error. That is achievable with the `execution::let_stopped`, `execution::upon_stopped`, `execution::stopped_as_optional`, or `execution::stopped_as_error` sender adaptors. For instance, we can use `execution::stopped_as_optional` to "catch" the stopped signal and map it into an empty optional as shown below:

```c++
if (auto opt = co_await execution::stopped_as_optional(some_sender)) {
  // OK, some_sender completed successfully, and opt contains the result.
} else {
  // some_sender completed with a cancellation signal.
}
```

As described in the section <a href="#design-awaitables-are-senders">"All awaitables are senders"</a>, the sender customization points recognize awaitables and adapt them transparently to model the sender concept. When `connect`-ing an awaitable and a receiver, the adaptation layer awaits the awaitable within a coroutine that implements `unhandled_stopped` in its promise type. The effect of this is that an "uncatchable" stopped exception propagates seamlessly out of awaitables, causing `execution::set_stopped` to be called on the receiver.

Obviously, `unhandled_stopped` is a library extension of the coroutine promise interface. Many promise types will not implement `unhandled_stopped`. When an uncatchable stopped exception tries to propagate through such a coroutine, it is treated as an unhandled exception and `terminate` is called. The solution, as described above, is to use a sender adaptor to handle the stopped exception before awaiting it. It goes without saying that any future Standard Library coroutine types ought to implement `unhandled_stopped`. The author of [[P1056R1]], which proposes a standard coroutine task type, is in agreement.

## Composition with parallel algorithms ## {#design-parallel-algorithms}

The C++ Standard Library provides a large number of algorithms that offer the potential for non-sequential execution via the use of execution policies. The set of algorithms with execution policy overloads are often referred to as "parallel algorithms", although
additional policies are available.

Existing policies, such as `execution::par`, give the implementation permission to execute the algorithm in parallel. However, the choice of execution resources used to perform the work is left to the implementation.

We will propose a customization point for combining schedulers with policies in order to provide control over where work will execute.

<pre highlight="c++">
template&lt;class ExecutionPolicy>
<i>implementation-defined</i> executing_on(
    execution::scheduler auto scheduler,
    ExecutionPolicy && policy
);
</pre>

This function would return an object of an implementation-defined type which can be used in place of an execution policy as the first argument to one of the parallel algorithms. The overload selected by that object should execute its computation as requested by
`policy` while using `scheduler` to create any work to be run. The expression may be ill-formed if `scheduler` is not able to support the given policy.

The existing parallel algorithms are synchronous; all of the effects performed by the computation are complete before the algorithm returns to its caller. This remains unchanged with the `executing_on` customization point.

In the future, we expect additional papers will propose asynchronous forms of the parallel algorithms which (1) return senders rather than values or `void` and (2) where a customization point pairing a sender with an execution policy would similarly be used to
obtain an object of implementation-defined type to be provided as the first argument to the algorithm.

## User-facing sender factories ## {#design-sender-factories}

A <dfn export=true>sender factory</dfn> is an [=algorithm=] that takes no senders as parameters and returns a sender.

### `execution::schedule` ### {#design-sender-factory-schedule}

<pre highlight="c++">
execution::sender auto schedule(
    execution::scheduler auto scheduler
);
</pre>

Returns a sender describing the start of a task graph on the provided scheduler. See [[#design-schedulers]].

<pre highlight="c++">
execution::scheduler auto sch1 = get_system_thread_pool().scheduler();

execution::sender auto snd1 = execution::schedule(sch1);
// snd1 describes the creation of a new task on the system thread pool
</pre>

### `execution::just` ### {#design-sender-factory-just}

<pre highlight="c++">
execution::sender auto just(
    auto ...&& values
);
</pre>

Returns a sender with no [=completion scheduler|completion schedulers=], which [=send|sends=] the provided values. The input values are decay-copied into the returned sender. When the returned sender is connected to a receiver, the values are moved into the operation state if the sender is an rvalue; otherwise, they are copied. Then xvalues referencing the values in the operation state are passed to the receiver's `set_value`.

```c++
execution::sender auto snd1 = execution::just(3.14);
execution::sender auto then1 = execution::then(snd1, [] (double d) {
  std::cout << d << "\n";
});

execution::sender auto snd2 = execution::just(3.14, 42);
execution::sender auto then2 = execution::then(snd1, [] (double d, int i) {
  std::cout << d << ", " << i << "\n";
});

std::vector v3{1, 2, 3, 4, 5};
execution::sender auto snd3 = execution::just(v3);
execution::sender auto then3 = execution::then(snd3, [] (std::vector<int>&& v3copy) {
  for (auto&& e : v3copy) { e *= 2; }
  return std::move(v3copy);
}
auto&& [v3copy] = this_thread::sync_wait(then3).value();
// v3 contains {1, 2, 3, 4, 5}; v3copy will contain {2, 4, 6, 8, 10}.

execution::sender auto snd4 = execution::just(std::vector{1, 2, 3, 4, 5});
execution::sender auto then4 = execution::then(std::move(snd4), [] (std::vector<int>&& v4) {
  for (auto&& e : v4) { e *= 2; }
  return std::move(v4);
});
auto&& [v4] = this_thread::sync_wait(std::move(then4)).value();
// v4 contains {2, 4, 6, 8, 10}. No vectors were copied in this example.
```

### `execution::transfer_just` ### {#design-sender-factory-transfer_just}

<pre highlight="c++">
execution::sender auto transfer_just(
    execution::scheduler auto scheduler,
    auto ...&& values
);
</pre>

Returns a sender whose value [=completion scheduler=] is the provided scheduler, which [=send|sends=] the provided values in the same manner as `just`.

<pre highlight="c++">
execution::sender auto vals = execution::transfer_just(
    get_system_thread_pool().scheduler(),
    1, 2, 3
);
execution::sender auto snd = execution::then(vals, [](auto... args) {
    std::print(args...);
});
// when snd is executed, it will print "123"
</pre>

This adaptor is included as it greatly simplifies lifting values into senders.

### `execution::just_error` ### {#design-sender-factory-just_error}

<pre highlight="c++">
execution::sender auto just_error(
    auto && error
);
</pre>

Returns a sender with no [=completion scheduler|completion schedulers=], which completes with the specified error. If the provided error is an lvalue reference, a copy is made inside the returned sender and a non-const lvalue reference to the copy is sent to the receiver's `set_error`. If the provided value is an rvalue reference, it is moved into the returned sender and an rvalue reference to it is sent to the receiver's `set_error`.

### `execution::just_stopped` ### {#design-sender-factory-just_stopped}

<pre highlight="c++">
execution::sender auto just_stopped();
</pre>

Returns a sender with no [=completion scheduler|completion schedulers=], which completes immediately by calling the receiver's `set_stopped`.

### `execution::read` ### {#design-sender-factory-read}

<pre highlight="c++">
execution::sender auto read(auto tag);

execution::sender auto get_scheduler() {
  return read(execution::get_scheduler);
}
execution::sender auto get_delegatee_scheduler() {
  return read(execution::get_delegatee_scheduler);
}
execution::sender auto get_allocator() {
  return read(execution::get_allocator);
}
execution::sender auto get_stop_token() {
  return read(execution::get_stop_token);
}
</pre>

Returns a sender that reaches into a receiver's environment and pulls out the current value associated with the customization point denoted by `Tag`. It then sends the value read back to the receiver through the value channel. For instance, `get_scheduler()` (with no arguments) is a sender that asks the receiver for the currently suggested `scheduler` and passes it to the receiver's `set_value` completion-signal.

This can be useful when scheduling nested dependent work. The following sender pulls the current schduler into the value channel and then schedules more work onto it.

    <pre highlight="c++">
    execution::sender auto task =
      execution::get_scheduler()
        | execution::let_value([](auto sched) {
            return execution::on(sched, <i>some nested work here</i>);
        });

    this_thread::sync_wait( std::move(task) ); // wait for it to finish
    </pre>

This code uses the fact that `sync_wait` associates a scheduler with the receiver that it connects with `task`. `get_scheduler()` reads that scheduler out of the receiver, and passes it to `let_value`'s receiver's `set_value` function, which in turn passes it to the lambda. That lambda returns a new sender that uses the scheduler to schedule some nested work onto `sync_wait`'s scheduler.

## User-facing sender adaptors ## {#design-sender-adaptors}

A <dfn export=true>sender adaptor</dfn> is an [=algorithm=] that takes one or more senders, which it may `execution::connect`, as parameters, and returns a sender, whose completion is related to the sender arguments it has received.

Sender adaptors are <i>lazy</i>, that is, they are never allowed to submit any work for execution prior to the returned sender being <dfn lt="start" export=true>started</dfn> later on, and are also guaranteed to not start any input senders passed into them. Sender consumers
such as [[#design-sender-consumer-start_detached]] and [[#design-sender-consumer-sync_wait]] start senders.

For more implementer-centric description of starting senders, see [[#design-laziness]].

### `execution::transfer` ### {#design-sender-adaptor-transfer}

<pre highlight="c++">
execution::sender auto transfer(
    execution::sender auto input,
    execution::scheduler auto scheduler
);
</pre>

Returns a sender describing the transition from the execution agent of the input sender to the execution agent of the target scheduler. See [[#design-transitions]].

<pre highlight="c++">
execution::scheduler auto cpu_sched = get_system_thread_pool().scheduler();
execution::scheduler auto gpu_sched = cuda::scheduler();

execution::sender auto cpu_task = execution::schedule(cpu_sched);
// cpu_task describes the creation of a new task on the system thread pool

execution::sender auto gpu_task = execution::transfer(cpu_task, gpu_sched);
// gpu_task describes the transition of the task graph described by cpu_task to the gpu
</pre>

### `execution::then` ### {#design-sender-adaptor-then}

<pre highlight="c++">
execution::sender auto then(
    execution::sender auto input,
    std::invocable<<i>values-sent-by(input)</i>...> function
);
</pre>

`then` returns a sender describing the task graph described by the input sender, with an added node of invoking the provided function with the values [=send|sent=] by the input sender as arguments.

`then` is **guaranteed** to not begin executing `function` until the returned sender is started.

<pre highlight="c++">
execution::sender auto input = get_input();
execution::sender auto snd = execution::then(input, [](auto... args) {
    std::print(args...);
});
// snd describes the work described by pred
// followed by printing all of the values sent by pred
</pre>

This adaptor is included as it is necessary for writing any sender code that actually performs a useful function.

### `execution::upon_*` ### {#design-sender-adaptor-upon}

<pre highlight="c++">
execution::sender auto upon_error(
    execution::sender auto input,
    std::invocable&lt;<i>errors-sent-by(input)</i>...> function
);

execution::sender auto upon_stopped(
    execution::sender auto input,
    std::invocable auto function
);
</pre>

`upon_error` and `upon_stopped` are similar to `then`, but where `then` works with values sent by the input sender, `upon_error` works with errors, and `upon_stopped` is invoked when the "stopped" signal is sent.

### `execution::let_*` ### {#design-sender-adaptor-let}

<pre highlight="c++">
execution::sender auto let_value(
    execution::sender auto input,
    std::invocable<<i>values-sent-by(input)</i>...> function
);

execution::sender auto let_error(
    execution::sender auto input,
    std::invocable<<i>errors-sent-by(input)</i>...> function
);

execution::sender auto let_stopped(
    execution::sender auto input,
    std::invocable auto function
);
</pre>

`let_value` is very similar to `then`: when it is started, it invokes the provided function with the values [=send|sent=] by the input sender as arguments. However, where the sender returned from `then` sends exactly what that function ends up returning -
`let_value` requires that the function return a sender, and the sender returned by `let_value` sends the values sent by the sender returned from the callback. This is similar to the notion of "future unwrapping" in future/promise-based frameworks.

`let_value` is **guaranteed** to not begin executing `function` until the returned sender is started.

`let_error` and `let_stopped` are similar to `let_value`, but where `let_value` works with values sent by the input sender, `let_error` works with errors, and `let_stopped` is invoked when the "stopped" signal is sent.

### `execution::on` ### {#design-sender-adaptor-on}

<pre highlight="c++">
execution::sender auto on(
    execution::scheduler auto sched,
    execution::sender auto snd
);
</pre>

Returns a sender which, when started, will start the provided sender on an execution agent belonging to the execution context associated with the provided scheduler. This returned sender has no [=completion scheduler|completion schedulers=].

### `execution::into_variant` ### {#design-sender-adaptor-into_variant}

<pre highlight=c++>
execution::sender auto into_variant(
    execution::sender auto snd
);
</pre>

Returns a sender which sends a variant of tuples of all the possible sets of types sent by the input sender. Senders can send multiple sets of values depending on runtime conditions; this is a helper function that turns them into a single variant value.

### `execution::stopped_as_optional` ### {#design-sender-adaptor-stopped_as_optional}

<pre highlight=c++>
execution::sender auto stopped_as_optional(
    <i>single-sender</i> auto snd
);
</pre>

Returns a sender that maps the value channel from a `T` to an `optional<decay_t<T>>`, and maps the stopped channel to a value of an empty `optional<decay_t<T>>`.

### `execution::stopped_as_error` ### {#design-sender-adaptor-stopped_as_error}

<pre highlight=c++>
template&lt;move_constructible Error>
execution::sender auto stopped_as_error(
    execution::sender auto snd,
    Error err
);
</pre>

Returns a sender that maps the stopped channel to an error of `err`.

### `execution::bulk` ### {#design-sender-adaptor-bulk}

<pre highlight="c++">
execution::sender auto bulk(
    execution::sender auto input,
    std::integral auto shape,
    invocable&lt;decltype(size), <i>values-sent-by(input)</i>...> function
);
</pre>

Returns a sender describing the task of invoking the provided function with every index in the provided shape along with the values sent by the input sender. The returned sender completes once all invocations have completed, or an error has occurred. If it completes
by sending values, they are equivalent to those sent by the input sender.

No instance of `function` will begin executing until the returned sender is started. Each invocation of `function` runs in an execution agent whose forward progress guarantees are determined by the scheduler on which they are run. All agents created by a single use
of `bulk` execute with the same guarantee. This allows, for instance, a scheduler to execute all invocations of the function in parallel.

The `bulk` operation is intended to be used at the point where the number of agents to be created is known and provided to `bulk` via its `shape` parameter. For some parallel computations, the number of agents to be created may be a function of the input data or
dynamic conditions of the execution environment. In such cases, `bulk` can be combined with additional operations such as `let_value` to deliver dynamic shape information to the `bulk` operation.

In this proposal, only integral types are used to specify the shape of the bulk section. We expect that future papers may wish to explore extensions of the interface to explore additional kinds of shapes, such as multi-dimensional grids, that are commonly used for
parallel computing tasks.

### `execution::split` ### {#design-sender-adaptor-split}

<pre highlight="c++">
execution::sender auto split(execution::sender auto sender);
</pre>

If the provided sender is a multi-shot sender, returns that sender. Otherwise, returns a multi-shot sender which sends values equivalent to the values sent by the provided sender. See [[#design-shot]].

### `execution::when_all` ### {#design-sender-adaptor-when_all}

<pre highlight="c++">
execution::sender auto when_all(
    execution::sender auto ...inputs
);

execution::sender auto when_all_with_variant(
    execution::sender auto ...inputs
);
</pre>

`when_all` returns a sender that completes once all of the input senders have completed. It is constrained to only accept senders that can complete with a single set of values (_i.e._, it only calls one overload of `set_value` on its receiver). The values sent by this sender are the values sent by each of the input senders, in order of the arguments passed to `when_all`. It completes inline on the execution context on which the last input sender completes, unless stop is requested before `when_all` is started, in which case it completes inline within the call to `start`.

`when_all_with_variant` does the same, but it adapts all the input senders using `into_variant`, and so it does not constrain the input arguments as `when_all` does.

The returned sender has no [=completion scheduler|completion schedulers=].

See [[#design-join]].

<pre highlight="c++">
execution::scheduler auto sched = thread_pool.scheduler();

execution::sender auto sends_1 = ...;
execution::sender auto sends_abc = ...;

execution::sender auto both = execution::when_all(sched,
    sends_1,
    sends_abc
);

execution::sender auto final = execution::then(both, [](auto... args){
    std::cout << std::format("the two args: {}, {}", args...);
});
// when final executes, it will print "the two args: 1, abc"
</pre>

### `execution::transfer_when_all` ### {#design-sender-adaptor-transfer_when_all}

<pre highlight="c++">
execution::sender auto transfer_when_all(
    execution::scheduler auto sched,
    execution::sender auto ...inputs
);

execution::sender auto transfer_when_all_with_variant(
    execution::scheduler auto sched,
    execution::sender auto ...inputs
);
</pre>

Similar to [[#design-sender-adaptor-when_all]], but returns a sender whose value [=completion scheduler=] is the provided scheduler.

See [[#design-join]].

### `execution::ensure_started` ### {#design-sender-adaptor-ensure_started}

<pre highlight="c++">
execution::sender auto ensure_started(
    execution::sender auto sender
);
</pre>

Once `ensure_started` returns, it is known that the provided sender has been [=connect|connected=] and `start` has been called on the resulting operation state (see [[#design-states]]); in other words, the work described by the provided sender has been submitted
for execution on the appropriate execution contexts. Returns a sender which completes when the provided sender completes and sends values equivalent to those of the provided sender.

If the returned sender is destroyed before `execution::connect()` is called, or if `execution::connect()` is called but the
returned operation-state is destroyed before `execution::start()` is called, then a stop-request is sent to the eagerly launched
operation and the operation is detached and will run to completion in the background. Its result will be discarded when it
eventually completes.

Note that the application will need to make sure that resources are kept alive in the case that the operation detaches.
e.g. by holding a `std::shared_ptr` to those resources or otherwise having some out-of-band way to signal completion of
the operation so that resource release can be sequenced after the completion.

## User-facing sender consumers ## {#design-sender-consumers}

A <dfn export=true>sender consumer</dfn> is an [=algorithm=] that takes one or more senders, which it may `execution::connect`, as parameters, and does not return a sender.

### `execution::start_detached` ### {#design-sender-consumer-start_detached}

<pre highlight="c++">
void start_detached(
    execution::sender auto sender
);
</pre>

Like `ensure_started`, but does not return a value; if the provided sender sends an error instead of a value, `std::terminate` is called.

### `this_thread::sync_wait` ### {#design-sender-consumer-sync_wait}

<pre highlight="c++">
auto sync_wait(
    execution::sender auto sender
) requires (<i>always-sends-same-values</i>(sender))
    -> std::optional&lt;std::tuple&lt;<i>values-sent-by</i>(sender)>>;
</pre>

`this_thread::sync_wait` is a sender consumer that submits the work described by the provided sender for execution, similarly to `ensure_started`, except that it blocks <b>the current `std::thread` or thread of `main`</b> until the work is completed, and returns
an optional tuple of values that were sent by the provided sender on its completion of work. Where [[#design-sender-factory-schedule]] and [[#design-sender-factory-transfer_just]] are meant to <i>enter</i> the domain of senders, `sync_wait` is meant to <i>exit</i> the domain of
senders, retrieving the result of the task graph.

If the provided sender sends an error instead of values, `sync_wait` throws that error as an exception, or rethrows the original exception if the error is of type `std::exception_ptr`.

If the provided sender sends the "stopped" signal instead of values, `sync_wait` returns an empty optional.

For an explanation of the `requires` clause, see [[#design-typed]]. That clause also explains another sender consumer, built on top of `sync_wait`: `sync_wait_with_variant`.

Note: This function is specified inside `std::this_thread`, and not inside `execution`. This is because `sync_wait` has to block the <i>current</i> execution agent, but determining what the current execution agent is is not reliable. Since the standard
does not specify any functions on the current execution agent other than those in `std::this_thread`, this is the flavor of this function that is being proposed. If C++ ever obtains fibers, for instance, we expect that a variant of this function called
`std::this_fiber::sync_wait` would be provided. We also expect that runtimes with execution agents that use different synchronization mechanisms than `std::thread`'s will provide their own flavors of `sync_wait` as well (assuming their execution agents have the means
to block in a non-deadlock manner).

## `execution::execute` ## {#design-execute}

In addition to the three categories of functions presented above, we also propose to include a convenience function for fire-and-forget eager one-way submission of an invocable to a scheduler, to fulfil the role of one-way executors from P0443.

<pre highlight="c++">
void execution::execute(
    execution::schedule auto sched,
    std::invocable<void> auto fn
);
</pre>

Submits the provided function for execution on the provided scheduler, as-if by:

<pre highlight="c++">
auto snd = execution::schedule(sched);
auto work = execution::then(snd, fn);
execution::start_detached(work);
</pre>

# Design - implementer side # {#design-implementer}

## Receivers serve as glue between senders ## {#design-receivers}

A <dfn export=true>receiver</dfn> is a callback that supports more than one channel. In fact, it supports three of them:

* `set_value`, which is the moral equivalent of an `operator()` or a function call, which signals successful completion of the operation its execution depends on;
* `set_error`, which signals that an error has happened during scheduling of the current work, executing the current work, or at some earlier point in the sender chain; and
* `set_stopped`, which signals that the operation completed without succeeding (`set_value`) and without failing (`set_error`). This result is often used to indicate that the operation stopped early, typically because it was asked to do so because the result is no
    longer needed.

Exactly one of these channels must be successfully (i.e. without an exception being thrown) invoked on a receiver before it is destroyed; if a call to `set_value` failed with an exception, either `set_error` or `set_stopped` must be invoked on the same receiver. These
requirements are know as the <dfn export=true>receiver contract</dfn>.

While the receiver interface may look novel, it is in fact very similar to the interface of `std::promise`, which provides the first two signals as `set_value` and `set_error`, and it's possible to emulate the third channel with lifetime management of the promise.

Receivers are not a part of the end-user-facing API of this proposal; they are necessary to allow unrelated senders communicate with each other, but the only users who will interact with receivers directly are authors of senders.

Receivers are what is passed as the second argument to [[#design-connect]].

## Operation states represent work ## {#design-states}

An <dfn export=true>operation state</dfn> is an object that represents work. Unlike senders, it is not a chaining mechanism; instead, it is a concrete object that packages the work described by a full sender chain, ready to be executed. An operation state is neither movable nor
copyable, and its interface consists of a single algorithm: `start`, which serves as the submission point of the work represented by a given operation state.

Operation states are not a part of the user-facing API of this proposal; they are necessary for implementing sender consumers like `execution::ensure_started` and `this_thread::sync_wait`, and the knowledge of them is necessary to implement senders, so the only users who will
interact with operation states directly are authors of senders and authors of sender algorithms.

The return value of [[#design-connect]] must satisfy the operation state concept.

## `execution::connect` ## {#design-connect}

`execution::connect` is a customization point which <dfn lt="connect">connects</dfn> senders with receivers, resulting in an operation state that will ensure that the [=receiver contract=] of the receiver passed to `connect` will be fulfilled.

<pre highlight="c++">
execution::sender auto snd = <i>some input sender</i>;
execution::receiver auto rcv = <i>some receiver</i>;
execution::operation_state auto state = execution::connect(snd, rcv);

execution::start(state);
// at this point, it is guaranteed that the work represented by state has been submitted
// to an execution context, and that execution context will eventually fulfill the
// receiver contract of rcv

// operation states are not movable, and therefore this operation state object must be
// kept alive until the operation finishes
</pre>

## Sender algorithms are customizable ## {#design-customization}

Senders being able to advertise what their [=completion schedulers=] are fulfills one of the promises of senders: that of being able to customize an implementation of a sender algorithm based on what scheduler any work it depends on will complete on.

The simple way to provide customizations for functions like `then`, that is for [=sender adaptors=] and [=sender consumers=], is to follow the customization scheme that has been adopted for C++20 ranges library; to do that, we would define
the expression `execution::then(sender, invocable)` to be equivalent to:

  1. `sender.then(invocable)`, if that expression is well formed; otherwise
  2. `then(sender, invocable)`, performed in a context where this call always performs ADL, if that expression is well formed; otherwise
  3. a default implementation of `then`, which returns a sender adaptor, and then define the exact semantics of said adaptor.

However, this definition is problematic. Imagine another sender adaptor, `bulk`, which is a structured abstraction for a loop over an index space. Its default implementation is just a for loop. However, for accelerator runtimes like CUDA, we would like sender algorithms
like `bulk` to have specialized behavior, which invokes a kernel of more than one thread (with its size defined by the call to `bulk`); therefore, we would like to customize `bulk` for CUDA senders to achieve this. However, there's no reason for CUDA kernels to
necessarily customize the `then` sender adaptor, as the generic implementation is perfectly sufficient. This creates a problem, though; consider the following snippet:

<pre highlight="c++">
execution::scheduler auto cuda_sch = cuda_scheduler{};

execution::sender auto initial = execution::schedule(cuda_sch);
// the type of initial is a type defined by the cuda_scheduler
// let's call it cuda::schedule_sender&lt;>

execution::sender auto next = execution::then(cuda_sch, []{ return 1; });
// the type of next is a standard-library implementation-defined sender adaptor
// that wraps the cuda sender
// let's call it execution::then_sender_adaptor&lt;cuda::schedule_sender&lt;>>

execution::sender auto kernel_sender = execution::bulk(next, shape, [](int i){ ... });
</pre>

How can we specialize the `bulk` sender adaptor for our wrapped `schedule_sender`? Well, here's one possible approach, taking advantage of ADL (and the fact that the definition of "associated namespace" also recursively enumerates the associated namespaces of all template
parameters of a type):

<pre highlight="c++">
namespace cuda::for_adl_purposes {
template&lt;typename... SentValues>
class schedule_sender {
    execution::operation_state auto connect(execution::receiver auto rcv);
    execution::scheduler auto get_completion_scheduler() const;
};

execution::sender auto bulk(
    execution::sender auto && input,
    execution::shape auto && shape,
    invocable<<i>sender-values(input)</i>> auto && fn)
{
    // return a cuda sender representing a bulk kernel launch
}
} // namespace cuda::for_adl_purposes
</pre>

However, if the input sender is not just a `then_sender_adaptor` like in the example above, but another sender that overrides `bulk` by itself, as a member function, because its author believes they know an optimization for bulk - the specialization above will no
longer be selected, because a member function of the first argument is a better match than the ADL-found overload.

This means that well-meant specialization of sender algorithms that are entirely scheduler-agnostic can have negative consequences.
The scheduler-specific specialization - which is essential for good performance on platforms providing specialized ways to launch certain sender algorithms - would not be selected in such cases.
But it's really the scheduler that should control the behavior of sender algorithms when a non-default implementation exists, not the sender. Senders merely describe work; schedulers, however, are the handle to the
runtime that will eventually execute said work, and should thus have the final say in *how* the work is going to be executed.

Therefore, we are proposing the following customization scheme (also modified to take [[#design-dispatch]] into account): the expression `execution::<sender-algorithm>(sender, args...)`, for any given sender algorithm that accepts a sender as its first argument, should be
equivalent to:

  1. <code>tag_invoke(&lt;sender-algorithm>, get_completion_scheduler&lt;<i>Signal</i>>(sender), sender, args...)</code>, if that expression is well-formed; otherwise
  2. `tag_invoke(<sender-algorithm>, sender, args...)`, if that expression is well-formed; otherwise
  4. a default implementation, if there exists a default implementation of the given sender algorithm.

where <code><i>Signal</i></code> is one of `set_value`, `set_error`, or `set_stopped`; for most sender algorithms, the completion scheduler for `set_value` would be used, but for some (like `upon_error` or `let_stopped`), one of the others would be used.

For sender algorithms which accept concepts other than `sender` as their first argument, we propose that the customization scheme remains as it has been in [[P0443R14]] so far, except it should also use `tag_invoke`.

## Sender adaptors are lazy ## {#design-laziness}

Contrary to early revisions of this paper, we propose to make all sender adaptors perform strictly lazy submission, unless specified otherwise (the one notable exception in this paper is [[#design-sender-adaptor-ensure_started]], whose sole purpose is to start an
input sender).

 <dfn export=true>Strictly lazy submission</dfn> means that there is a guarantee that no work is submitted to an execution context before a receiver is connected to a sender, and `execution::start` is called on the resulting operation state.

## Lazy senders provide optimization opportunities ## {#design-fusion}

Because lazy senders fundamentally *describe* work, instead of describing or representing the submission of said work to an execution context, and thanks to the flexibility of the customization of most sender algorithms, they provide an opportunity for fusing
multiple algorithms in a sender chain together, into a single function that can later be submitted for execution by an execution context. There are two ways this can happen.

The first (and most common) way for such optimizations to happen is thanks to the structure of the implementation: because all the work is done within callbacks invoked on the completion of an earlier sender, recursively up to the original source of computation,
the compiler is able to see a chain of work described using senders as a tree of tail calls, allowing for inlining and removal of most of the sender machinery. In fact, when work is not submitted to execution contexts outside of the current thread of execution,
compilers are capable of removing the senders abstraction entirely, while still allowing for composition of functions across different parts of a program.

The second way for this to occur is when a sender algorithm is specialized for a specific set of arguments. For instance, we expect that, for senders which are known to have been started already, [[#design-sender-adaptor-ensure_started]] will be an identity transformation,
because the sender algorithm will be specialized for such senders. Similarly, an implementation could recognize two subsequent [[#design-sender-adaptor-bulk]]s of compatible shapes, and merge them together into a single submission of a GPU kernel.

## Execution context transitions are two-step ## {#design-transition-details}

Because `execution::transfer` takes a sender as its first argument, it is not actually directly customizable by the target scheduler. This is by design: the target scheduler may not know how to transition <i>from</i> a scheduler such as a CUDA scheduler;
transitioning away from a GPU in an efficient manner requires making runtime calls that are specific to the GPU in question, and the same is usually true for other kinds of accelerators too (or for scheduler running on remote systems). To avoid this problem,
specialized schedulers like the ones mentioned here can still hook into the transition mechanism, and inject a sender which will perform a transition to the regular CPU execution context, so that any sender can be attached to it.

This, however, is a problem: because customization of sender algorithms must be controlled by the scheduler they will run on (see [[#design-customization]]), the type of the sender returned from `transfer` must be controllable by the target scheduler. Besides, the target
scheduler may itself represent a specialized execution context, which requires additional work to be performed to transition <i>to</i> it. GPUs and remote node schedulers are once again good examples of such schedulers: executing code on their execution contexts
requires making runtime API calls for work submission, and quite possibly for the data movement of the values being sent by the input sender passed into `transfer`.

To allow for such customization from both ends, we propose the inclusion of a secondary transitioning sender adaptor, called `schedule_from`. This adaptor is a form of `schedule`, but takes an additional, second argument: the input sender. This adaptor is not
meant to be invoked manually by the end users; they are always supposed to invoke `transfer`, to ensure that both schedulers have a say in how the transitions are made. Any scheduler that specializes `transfer(snd, sch)` shall ensure that the
return value of their customization is equivalent to `schedule_from(sch, snd2)`, where `snd2` is a successor of `snd` that sends values equivalent to those sent by `snd`.

The default implementation of `transfer(snd, sched)` is `schedule_from(sched, snd)`.

## All senders are typed ## {#design-typed}

All senders must advertise the types they will [=send=] when they complete.
This is necessary for a number of features, and writing code in a way that's
agnostic of whether an input sender is typed or not in common sender adaptors
such as `execution::then` is hard.

The mechanism for this advertisement is similar to the one in [[P0443R14]]; the
way to query the types is through `completion_signatures_of_t<S,
[Env]>::value_types<tuple_like, variant_like>`.

`completion_signatures_of_t::value_types` is a template that takes two
arguments: one is a tuple-like template, the other is a variant-like template.
The tuple-like argument is required to represent senders sending more than one
value (such as `when_all`). The variant-like argument is required to represent
senders that choose which specific values to send at runtime.

There's a choice made in the specification of
[[#design-sender-consumer-sync_wait]]: it returns a tuple of values sent by the
sender passed to it, wrapped in `std::optional` to handle the `set_stopped`
signal. However, this assumes that those values can be represented as a tuple,
like here:

<pre highlight=c++>
execution::sender auto sends_1 = ...;
execution::sender auto sends_2 = ...;
execution::sender auto sends_3 = ...;

auto [a, b, c] = this_thread::sync_wait(
    execution::transfer_when_all(
        execution::get_completion_scheduler&lt;execution::set_value_t>(sends_1),
        sends_1,
        sends_2,
        sends_3
    )).value();
// a == 1
// b == 2
// c == 3
</pre>

This works well for senders that always send the same set of arguments. If we ignore the possibility of having a sender that sends different sets of arguments into a receiver, we can specify the "canonical" (i.e. required to be followed by all senders) form of
`value_types` of a sender which sends `Types...` to be as follows:

<pre highlight=c++>
template&lt;template&lt;typename ...> typename TupleLike>
using value_types = TupleLike<Types...>;
</pre>

If senders could only ever send one specific set of values, this would probably need to be the required form of `value_types` for all senders; defining it otherwise would cause very weird results and should be considered a bug.

This matter is somewhat complicated by the fact that (1) `set_value` for receivers can be overloaded and accept different sets of arguments, and (2) senders are allowed to send multiple different sets of values, depending on runtime conditions, the data they
consumed, and so on. To accomodate this, [[P0443R14]] also includes a second template parameter to `value_types`, one that represents a variant-like type. If we permit such senders, we would almost certainly need to require that the canonical form of `value_types`
for *all* senders (to ensure consistency in how they are handled, and to avoid accidentally interpreting a user-provided variant as a sender-provided one) sending the different sets of arguments `Types1...`, `Types2...`, ..., `TypesN...` to be as follows:

<pre highlight=c++>
template&lt;
    template&lt;typename ...> typename TupleLike,
    template&lt;typename ...> typename VariantLike
>
using value_types = VariantLike&lt;
    TupleLike&lt;Types1...>,
    TupleLike&lt;Types2...>,
    ...,
    TupleLike&lt;Types3...>
>;
</pre>

This, however, introduces a couple of complications:

1. A `just(1)` sender would also need to follow this structure, so the correct type for storing the value sent by it would be `std::variant<std::tuple<int>>` or some such. This introduces a lot of compile time overhead for the simplest senders, and this overhead
    effectively exists in all places in the code where `value_types` is queried, regardless of the tuple-like and variant-like templates passed to it. Such overhead does exist if only the tuple-like parameter exists, but is made much worse by adding this second
    wrapping layer.
2. As a consequence of (1): because `sync_wait` needs to store the above type, it can no longer return just a `std::tuple<int>` for `just(1)`; it has to return `std::variant<std::tuple<int>>`. C++ currently does not have an easy way to destructure this; it may get
    less awkward with pattern matching, but even then it seems extremely heavyweight to involve variants in this API, and for the purpose of generic code, the kind of the return type of `sync_wait` must be the same across all sender types.

One possible solution to (2) above is to place a requirement on `sync_wait` that it can only accept senders which send only a single set of values, therefore removing the need for `std::variant` to appear in its API; because of this, we propose to expose both
`sync_wait`, which is a simple, user-friendly version of the sender consumer, but requires that `value_types` have only one possible variant, and `sync_wait_with_variant`, which accepts any sender, but returns an optional whose value type is the variant of all the
possible tuples sent by the input sender:

<pre highlight=c++>
auto sync_wait_with_variant(
    execution::sender auto sender
) -> std::optional&lt;std::variant&lt;
        std::tuple&lt;<i>values<i><sub>0</sub></i>-sent-by</i>(sender)>,
        std::tuple&lt;<i>values<i><sub>1</sub></i>-sent-by</i>(sender)>,
        ...,
        std::tuple&lt;<i>values<i><sub>n</sub></i>-sent-by</i>(sender)>
    >>;

auto sync_wait(
    execution::sender auto sender
) requires (<i>always-sends-same-values</i>(sender))
    -> std::optional&lt;std::tuple&lt;<i>values-sent-by</i>(sender)>>;
</pre>

## Ranges-style CPOs vs `tag_invoke` ## {#design-dispatch}

The contemporary technique for customization in the Standard Library is customization point objects. A customization point object, will it look for member functions and then for nonmember functions with the same name as the customization point, and calls those if
they match. This is the technique used by the C++20 ranges library, and previous executors proposals ([[P0443R14]] and [[P1897R3]]) intended to use it as well. However, it has several unfortunate consequences:

1. It does not allow for easy propagation of customization points unknown to the adaptor to a wrapped object, which makes writing universal adapter types much harder - and this proposal uses quite a lot of those.

2. It effectively reserves names globally. Because neither member names nor ADL-found functions can be qualified with a namespace, every customization point object that uses the ranges scheme reserves the name for all types in all namespaces. This is unfortunate
    due to the sheer number of customization points already in the paper, but also ones that we are envisioning in the future. It's also a big problem for one of the operations being proposed already: `sync_wait`. We imagine that if, in the future, C++ was to
    gain fibers support, we would want to also have `std::this_fiber::sync_wait`, in addition to `std::this_thread::sync_wait`. However, because we would want the names to be the same in both cases, we would need to make the names of the customizations not match the
    names of the customization points. This is undesirable.

This paper proposes to instead use the mechanism described in [[P1895R0]]: `tag_invoke`; the wording for `tag_invoke` has been incorporated into the proposed specification in this paper.

In short, instead of using globally reserved names, `tag_invoke` uses the <i>type</i> of the customization point object itself as the mechanism to find customizations. It globally reserves only a single name - `tag_invoke` - which itself is used the same way that
ranges-style customization points are used. All other customization points are defined in terms of `tag_invoke`. For example, the customization for `std::this_thread::sync_wait(s)` will call `tag_invoke(std::this_thread::sync_wait, s)`, instead of attempting
to invoke `s.sync_wait()`, and then `sync_wait(s)` if the member call is not valid.

Using `tag_invoke` has the following benefits:

1. It reserves only a single global name, instead of reserving a global name for every customization point object we define.

2. It is possible to propagate customizations to a subobject, because the information of which customization point is being resolved is in the type of an argument, and not in the name of the function:

    <pre highlight=c++>
    // forward most customizations to a subobject
    template&lt;typename Tag, typename ...Args>
    friend auto tag_invoke(Tag && tag, wrapper & self, Args &&... args) {
        return std::forward&lt;Tag>(tag)(self.subobject, std::forward&lt;Args>(args)...);
    }

    // but override one of them with a specific value
    friend auto tag_invoke(specific_customization_point_t, wrapper & self) {
        return self.some_value;
    }
    </pre>

3. It is possible to pass those as template arguments to types, because the information of which customization point is being resolved is in the type. Similarly to how [[P0443R14]] defines a polymorphic executor wrapper which accepts a list of properties it
    supports, we can imagine scheduler and sender wrappers that accept a list of queries and operations they support. That list can contain the types of the customization point objects, and the polymorphic wrappers can then specialize those customization points on
    themselves using `tag_invoke`, dispatching to manually constructed vtables containing pointers to specialized implementations for the wrapped objects. For an example of such a polymorphic wrapper, see
    <code>[unifex::any_unique](https://github.com/facebookexperimental/libunifex/blob/1a6fbfc9cc3829356ccbdcf9e8d1f3cc33a6d9e0/include/unifex/any_unique.hpp)</code>
    ([example](https://github.com/facebookexperimental/libunifex/blob/1a6fbfc9cc3829356ccbdcf9e8d1f3cc33a6d9e0/examples/any_unique.cpp)).

# Specification # {#spec}

Much of this wording follows the wording of [[P0443R14]].

[[#spec-library]] is meant to be a diff relative to the wording of the <b>[library]</b> clause of [[N4885]].

[[#spec-utilities]] is meant to be a diff relative to the wording of the <b>[utilities]</b> clause of [[N4885]]. This diff applies changes from [[P1895R0]].

[[#spec-thread]] is meant to be a diff relative to the wording of the <b>[thread]</b> clause of [[N4885]]. This diff applies changes from [[P2175R0]].

[[#spec-execution]] is meant to be added as a new library clause to the working draft of C++.

# Library introduction <b>[library]</b> # {#spec-library}

[*Editorial:* Add the header `<execution>` to Table 23: C++ library headers [tab:headers.cpp]]

In subclause [conforming], after [lib.types.movedfrom], add the following new subclause with suggested stable name [lib.tmpl-heads].

<ins>
<blockquote>
**16.4.6.17  Class template-heads**

1. If a class template's template-head is marked with "*arguments are not
    associated entities*"", any template arguments do not contribute to the
    associated entities ([basic.lookup.argdep]) of a function call where a
    specialization of the class template is an associated entity. In such a case,
    the class template may be implemented as an alias template referring to a
    templated class, or as a class template where the template arguments
    themselves are templated classes.

2. [*Example:*

    <pre highlight="c++">
    template&lt;class T> // arguments are not associated entities
    struct S {};

    namespace N {
      int f(auto);
      struct A {};
    }

    int x = f(S&lt;N::A>{});  // error: N::f not a candidate
    </pre>

    The template `S` specified above may be implemented as

    <pre highlight="c++">
    template&lt;class T>
    struct <i>s-impl</i> {
      struct type { };
    };

    template&lt;class T>
    using S = typename <i>s-impl</i>&lt;T>::type;
    </pre>

    or as

    <pre highlight="c++">
    template&lt;class T>
    struct <i>hidden</i> {
      using type = struct _ {
        using type = T;
      };
    };

    template&lt;class HiddenT>
    struct <i>s-impl</i> {
      using T = typename HiddenT::type;
    };

    template&lt;class T>
    using S = <i>s-impl</i>&lt;typename <i>hidden</i>&lt;T>::type>;
    </pre>

    -- <i>end example</i>]
    </blockquote>
    </ins>

# General utilities library <b>[utilities]</b> # {#spec-utilities}

## Function objects <b>[function.objects]</b> ## {#spec-function.objects}

### Header `<functional>` synopsis <b>[functional.syn]</b> ### {#spec-functional.syn}

At the end of this subclause, insert the following declarations into the synopsis within `namespace std`:

<ins>
<blockquote>
<pre highlight=c++>
// Expositon-only:
template &lt;class Fn, class... Args>
  concept <i>callable</i> =
    requires (Fn&& fn, Args&&... args) {
      std::forward&lt;Fn>(fn)(std::forward&lt;Args>(args)...);
    };
template &lt;class Fn, class... Args>
  concept <i>nothrow-callable</i> =
    <i>callable</i>&lt;Fn, Args...> &amp;&amp;
    requires (Fn&& fn, Args&&... args) {
      { std::forward&lt;Fn>(fn)(std::forward&lt;Args>(args)...) } noexcept;
    };
template &lt;class Fn, class... Args>
  using <i>call-result-t</i> = decltype(declval&lt;Fn>()(declval&lt;Args>()...));

// [func.tag_invoke], tag_invoke
namespace <i>tag-invoke</i> { <i>// exposition only</i>
  void tag_invoke();

  template &lt;class Tag, class... Args>
    concept tag_invocable =
      requires (Tag&& tag, Args&&... args) {
        tag_invoke(std::forward&lt;Tag>(tag), std::forward&lt;Args>(args)...);
      };

  template &lt;class Tag, class... Args>
    concept nothrow_tag_invocable =
      tag_invocable&lt;Tag, Args...> &&
      requires (Tag&& tag, Args&&... args) {
        { tag_invoke(std::forward&lt;Tag>(tag), std::forward&lt;Args>(args)...) } noexcept;
      };

  template &lt;class Tag, class... Args>
    using tag_invoke_result_t =
      decltype(tag_invoke(declval&lt;Tag>(), declval&lt;Args>()...));

  template &lt;class Tag, class... Args>
    struct tag_invoke_result {};

  template &lt;class Tag, class... Args>
      requires tag_invocable&lt;Tag, Args...>
    struct tag_invoke_result&lt;Tag, Args...> {
      using type = tag_invoke_result_t&lt;Tag, Args...>;
    };

  struct <i>tag</i>; <i>// exposition only</i>
}
inline constexpr <i>tag-invoke</i>::<i>tag</i> tag_invoke {};
using <i>tag-invoke</i>::tag_invocable;
using <i>tag-invoke</i>::nothrow_tag_invocable;
using <i>tag-invoke</i>::tag_invoke_result_t;
using <i>tag-invoke</i>::tag_invoke_result;

template&lt;auto& Tag>
  using tag_t = decay_t&lt;decltype(Tag)>;
</pre>
</blockquote>
</ins>

### `tag_invoke` <b>[func.tag_invoke]</b> ### {#spec-func.tag_invoke}

Insert this section as a new subclause, between Searchers <b>[func.search]</b> and Class template `hash` <b>[unord.hash]</b>.

<ins>
<blockquote>

1. The name `std::tag_invoke` denotes a customization point object [customization.point.object]. Given subexpressions `T` and `A...`, the expression `std::tag_invoke(T, A...)` is expression-equivalent [defns.expression-equivalent] to `tag_invoke(T, A...)` if it is a well-formed expression with overload resolution performed in a context in which unqualified lookup for `tag_invoke` finds only the declaration

    ```c++
    void tag_invoke();
    ```

    Otherwise, `std::tag_invoke(T, A...)` is ill-formed.

2. [Note: Diagnosable ill-formed cases above result in substitution failure when `std::tag_invoke(T, A...)` appears in the immediate context of a template instantiation. —end note]

</blockquote>
</ins>

# Thread support library <b>[thread]</b> # {#spec-thread}

## Stop tokens <b>[thread.stoptoken]</b> ## {#spec-thread.stoptoken}

### Header `<stop_token>` synopsis <b>[thread.stoptoken.syn]</b> ### {#spec-thread.stoptoken.syn}

At the beginning of this subclause, insert the following declarations into the synopsis within `namespace std`:

<ins>
<blockquote>
<pre>
template&lt;template&lt;typename> class>
  struct <i>check-type-alias-exists</i>; // exposition-only

template&lt;typename T>
  concept stoppable_token = <i>see-below</i>;

template&lt;typename T, typename CB, typename Initializer = CB>
  concept stoppable_token_for = <i>see-below</i>;

template&lt;typename T>
  concept unstoppable_token = <i>see-below</i>;
</pre>
</blockquote>
</ins>

At the end of this subclause, insert the following declarations into the synopsis of within `namespace std`:

<ins>
<blockquote>
<pre>
// [stoptoken.never], class never_stop_token
class never_stop_token;

// [stoptoken.inplace], class in_place_stop_token
class in_place_stop_token;

// [stopsource.inplace], class in_place_stop_source
class in_place_stop_source;

// [stopcallback.inplace], class template in_place_stop_callback
template&lt;typename Callback>
class in_place_stop_callback;
</pre>
</blockquote>
</ins>

### Stop token concepts <b>[thread.stoptoken.concepts]</b> ### {#spec-thread.stoptoken.concepts}

Insert this section as a new subclause between Header `<stop_token>` synopsis <b>[thread.stoptoken.syn]</b> and Class `stop_token` <b>[stoptoken]</b>.

<ins>
<blockquote>
1. The `stoppable_token` concept checks for the basic interface of a “stop token” which is copyable and allows polling to see if stop has been requested and also whether a stop request is possible. It also requires an associated nested template-type-alias,
    `T::callback_type<CB>`, that identifies the stop-callback type to use to register a callback to be executed if a stop-request is ever made on a stoppable_token of type, `T`. The `stoppable_token_for` concept checks for a stop token type compatible with a given
    callback type. The `unstoppable_token` concept checks for a stop token type that does not allow stopping.

<pre>
template&lt;typename T>
  concept stoppable_token =
    copy_constructible&lt;T> &&
    move_constructible&lt;T> &&
    is_nothrow_copy_constructible_v&lt;T> &&
    is_nothrow_move_constructible_v&lt;T> &&
    equality_comparable&lt;T> &&
    requires (const T& token) {
      { token.stop_requested() } noexcept -> boolean-testable;
      { token.stop_possible() } noexcept -> boolean-testable;
      typename <i>check-type-alias-exists</i>&lt;T::template callback_type>;
    };

template&lt;typename T, typename CB, typename Initializer = CB>
  concept stoppable_token_for =
    stoppable_token&lt;T> &&
    invocable&lt;CB> &&
    requires {
      typename T::template callback_type&lt;CB>;
    } &&
    constructible_from&lt;CB, Initializer> &&
    constructible_from&lt;typename T::template callback_type&lt;CB>, T, Initializer> &&
    constructible_from&lt;typename T::template callback_type&lt;CB>, T&, Initializer> &&
    constructible_from&lt;typename T::template callback_type&lt;CB>, const T, Initializer> &&
    constructible_from&lt;typename T::template callback_type&lt;CB>, const T&, Initializer>;

template&lt;typename T>
  concept unstoppable_token =
    stoppable_token&lt;T> &&
    requires {
      { T::stop_possible() } -> boolean-testable;
    } &&
    (!T::stop_possible());
</pre>

2. Let `t` and `u` be distinct object of type `T`. The type `T` models `stoppable_token` only if:

    1. All copies of a `stoppable_token` reference the same logical shared stop state and shall report values consistent with each other.

    2. If `t.stop_possible()` evaluates to `false` then, if `u`, references the same logical shared stop state, `u.stop_possible()` shall also subsequently evaluate to `false` and `u.stop_requested()` shall also subsequently evaluate to `false`.

    3. If `t.stop_requested()` evaluates to `true` then, if `u`, references the same logical shared stop state, `u.stop_requested()` shall also subsequently evaluate to `true` and `u.stop_possible()` shall also subsequently evaluate to `true`.

    4. Given a callback-type, CB, and a callback-initializer argument, `init`, of type `Initializer` then constructing an instance, `cb`, of type `T::callback_type<CB>`, passing `t` as the first argument and `init` as the second argument to the constructor, shall,
        if `t.stop_possible()` is `true`, construct an instance, `callback`, of type `CB`, direct-initialized with `init`, and register callback with `t`’s shared stop state such that callback will be invoked with an empty argument list if a stop request is made on
        the shared stop state.

        1. If `t.stop_requested()` is `true` at the time callback is registered then callback may be invoked immediately inline inside the call to `cb`’s constructor.

        2. If callback is invoked then, if `u` references the same shared stop state as `t`, an evaluation of `u.stop_requested()` will be `true` if the beginning of the invocation of callback strongly-happens-before the evaluation of `u.stop_requested()`.

        3. If `t.stop_possible()` evaluates to `false` then the construction of `cb` is not required to construct and initialize `callback`.

    5. Construction of a `T::callback_type<CB>` instance shall only throw exceptions thrown by the initialization of the `CB` instance from the value of type `Initializer`.

    6. Destruction of the `T::callback_type<CB>` object, `cb`, removes `callback` from the shared stop state such that `callback` will not be invoked after the destructor returns.

        1. If `callback` is currently being invoked on another thread then the destructor of `cb` will block until the invocation of `callback` returns such that the return from the invocation of `callback` strongly-happens-before the destruction of `callback`.

        2. Destruction of a callback `cb` shall not block on the completion of the invocation of some other callback registered with the same shared stop state.

</blockquote>
</ins>

### Class `stop_token` <b>[stoptoken]</b> ### {#spec-stoptoken}

#### General <b>[stoptoken.general]</b> #### {#spec-stoptoken.general}

Modify the synopsis of class `stop_token` in section General <b>[stoptoken.general]</b> as follows:

<pre highlight=c++>
namespace std {
  class stop_token {
  public:
<ins>    template&lt;class T>
    using callback_type = stop_callback&lt;T>;</ins>

    // [stoptoken.cons], constructors, copy, and assignment
    stop_token() noexcept;

    // ...
</pre>

### Class `never_stop_token` <b>[stoptoken.never]</b> ### {#spec-stoptoken.never}

Insert a new subclause, Class `never_stop_token` <b>[stoptoken.never]</b>, after section Class template `stop_callback` <b>[stopcallback]</b>, as a new subclause of Stop tokens <b>[thread.stoptoken]</b>.

#### General <b>[stoptoken.never.general]</b> #### {#spec-stoptoken.never.general}

1. The class `never_stop_token` provides an implementation of the `unstoppable_token` concept. It provides a stop token interface, but also provides static information that a stop is never possible nor requested.

<pre highlight=c++>
namespace std
{
  class never_stop_token {
    // exposition only
    struct <i>callback</i> {
      explicit <i>callback</i>(never_stop_token, auto&&) noexcept {}
    };
  public:
    template&lt;class>
    using callback_type = <i>callback</i>;

    static constexpr bool stop_requested() noexcept { return false; }
    static constexpr bool stop_possible() noexcept { return false; }
  };
}
</pre>

### Class `in_place_stop_token` <b>[stoptoken.inplace]</b> ### {#spec-stoptoken.inplace}

Insert a new subclause, Class `in_place_stop_token` <b>[stoptoken.inplace]</b>, after the section added above, as a new subclause of Stop tokens <b>[thread.stoptoken]</b>.

#### General <b>[stoptoken.inplace.general]</b> #### {#spec-stoptoken.inplace.general}

1. The class `in_place_stop_token` provides an interface for querying whether a stop request has been made (`stop_requested`) or can ever be made (`stop_possible`) using an associated `in_place_stop_source` object ([stopsource.inplace]).
    An `in_place_stop_token` can also be passed to an `in_place_stop_callback` ([stopcallback.inplace]) constructor to register a callback to be called when a stop request has been made from an associated `in_place_stop_source`.

<pre highlight=c++>
namespace std {
  class in_place_stop_token {
  public:
    template&lt;class CB>
    using callback_type = in_place_stop_callback&lt;CB>;

    // [stoptoken.inplace.cons], constructors, copy, and assignment
    in_place_stop_token() noexcept;
    ~in_place_stop_token();
    void swap(in_place_stop_token&) noexcept;

    // [stoptoken.inplace.mem], stop handling
    [[nodiscard]] bool stop_requested() const noexcept;
    [[nodiscard]] bool stop_possible() const noexcept;

    [[nodiscard]] bool operator==(const in_place_stop_token&) const noexcept = default;
    friend void swap(in_place_stop_token& lhs, in_place_stop_token& rhs) noexcept;

  private:
    friend class in_place_stop_source;
    const in_place_stop_source* source_; // exposition only
    explicit in_place_stop_token(const in_place_stop_source* source) noexcept;
  };
}
</pre>

#### Constructors, copy, and assignment <b>[stoptoken.inplace.cons]</b> #### {#spec-stoptoken.inplace.cons}

<pre highlight=c++>
in_place_stop_token() noexcept;
</pre>

1. *Effects*: initializes `source_` with `nullptr`.

<pre highlight=c++>
explicit in_place_stop_token(const in_place_stop_source* source) noexcept;
</pre>

1. *Effects*: initializes `source_` with `source`.

<pre highlight=c++>
void swap(stop_token& rhs) noexcept;
</pre>

2. *Effects*: Exchanges the values of `source_` and `rhs.source_`.

#### Members <b>[stoptoken.inplace.mem]</b> #### {#spec-stoptoken.inplace.mem}

<pre highlight=c++>
[[nodiscard]] bool stop_requested() const noexcept;
</pre>

1. Returns: `source_ != nullptr && source_->stop_requested()`.

2. *Remarks*: If `source_ != nullptr`, then any calls to this function must strongly happen before the beginning of invocation of the destructor of `*source_`.

<pre highlight=c++>
[[nodiscard]] bool stop_possible() const noexcept;
</pre>

3. *Returns*: `source_ != nullptr && source_->stop_possible()`.

2. *Remarks*: If `source_ != nullptr`, then any calls to this function must strongly happen before the beginning of invocation of the destructor of `*source_`.

#### Non-member functions <b>[stoptoken.inplace.nonmembers]</b> #### {#spec-stoptoken.inplace.nonmembers}

<pre highlight=c++>
friend void swap(in_place_stop_token& x, in_place_stop_token& y) noexcept;
</pre>

2. *Effects*: Equivalent to: `x.swap(y)`.

### Class `in_place_stop_source` <b>[stopsource.inplace]</b> ### {#spec-stopsource.inplace}

Insert a new subclause, Class `in_place_stop_source` <b>[stopsource.inplace]</b>, after the section added above, as a new subclause of Stop tokens <b>[thread.stoptoken]</b>.

#### General <b>[stopsource.inplace.general]</b> #### {#spec-stopsource.inplace.general}

1. The class `in_place_stop_source` implements the semantics of making a stop request, without the need for a dynamic allocation of a shared state.
    A stop request made on a `in_place_stop_source` object is visible to all associated `in_place_stop_token` ([stoptoken.inplace]) objects.
    Once a stop request has been made it cannot be withdrawn (a subsequent stop request has no effect).
    All uses of `in_place_stop_token` objects associated with a given `in_place_stop_source` object must happen before the invocation of the destructor of that `in_place_stop_source` object.

<pre highlight=c++>
namespace std {
  class in_place_stop_source {
  public:
    // [stopsource.inplace.cons], constructors, copy, and assignment
    in_place_stop_source() noexcept;

    in_place_stop_source(in_place_stop_source&&) noexcept = delete;
    ~in_place_stop_source();

    //[stopsource.inplace.mem], stop handling
    [[nodiscard]] in_place_stop_token get_token() const noexcept;
    [[nodiscard]] bool stop_possible() const noexcept;
    [[nodiscard]] bool stop_requested() const noexcept;
    bool request_stop() noexcept;
  };
}
</pre>

#### Constructors, copy, and assignment <b>[stopsource.inplace.cons]</b> #### {#spec-stopsource.inplace.cons}

<pre highlight=c++>
in_place_stop_source() noexcept;
</pre>

1. *Effects*: Initializes a new stop state inside `*this`.

2. *Postconditions*: `stop_possible()` is `true` and `stop_requested()` is `false`.

#### Members <b>[stopsource.inplace.mem]</b> #### {#spec-stopsource.inplace.mem}

<pre highlight=c++>
[[nodiscard]] in_place_stop_token get_token() const noexcept;
</pre>

1. *Returns*: `in_place_stop_token{this}`

<pre highlight=c++>
[[nodiscard]] bool stop_possible() const noexcept;
</pre>

2. Returns: `true` if the stop state inside `*this` has not yet received a stop request; otherwise, `false`.

<pre highlight=c++>
[[nodiscard]] bool stop_requested() const noexcept;
</pre>

3. *Returns*: `true` if the stop state inside `*this` has received a stop request; otherwise, `false`.

<pre highlight=c++>
bool request_stop() noexcept;
</pre>

4. *Effects*: Atomically determines whether the stop state inside `*this` has received a stop request, and if not, makes a stop request.
    The determination and making of the stop request are an atomic read-modify-write operation ([intro.races]).
    If the request was made, the callbacks registered by associated `in_place_stop_callback` objects are synchronously called.
    If an invocation of a callback exits via an exception then `terminate` is invoked ([except.terminate]).

5. *Postconditions*: `stop_possible()` is `false` and `stop_requested()` is true.

6. *Returns*: `true` if this call made a stop request; otherwise `false`.

### Class template `in_place_stop_callback` <b>[stopcallback.inplace]</b> ### {#spec-stopcallback.inplace}

Insert a new subclause, Class template `in_place_stop_callback` <b>[stopcallback.inplace]</b>, after the section added above, as a new subclause of Stop tokens <b>[thread.stoptoken]</b>.

#### General <b>[stopcallback.inplace.general]</b> #### {#spec-stopcallback.inplace.general}

1.

    <pre highlight=c++>
    namespace std {
      template&lt;class Callback>
      class in_place_stop_callback {
      public:
        using callback_type = Callback;

        // [stopcallback.inplace.cons], constructors and destructor
        template&lt;class C>
          explicit in_place_stop_callback(in_place_stop_token st, C&& cb)
            noexcept(is_nothrow_constructible_v&lt;Callback, C>);
        ~in_place_stop_callback();

        in_place_stop_callback(in_place_stop_callback&&) = delete;

      private:
        Callback callback_;      // exposition only
      };

      template&lt;class Callback>
        in_place_stop_callback(in_place_stop_token, Callback)
          -> in_place_stop_callback&lt;Callback>;
    }
    </pre>

2. *Mandates*: `in_place_stop_callback` is instantiated with an argument for the template parameter `Callback` that satisfies both `invocable` and `destructible`.

3. *Preconditions*: `in_place_stop_callback` is instantiated with an argument for the template parameter `Callback` that models both `invocable` and `destructible`.

4. *Recommended practice*: Implementation should use the storage of the `in_place_stop_callback` objects to store the state necessary for their association with an `in_place_stop_source` object.

#### Constructors and destructor <b>[stopcallback.inplace.cons]</b> #### {#spec-stopcallback.inplace.cons}

<pre highlight=c++>
template<class C>
explicit in_place_stop_callback(in_place_stop_token st, C&& cb)
  noexcept(is_nothrow_constructible_v&lt;Callback, C>);
</pre>

1. *Constraints*: `Callback` and `C` satisfy `constructible_from<Callback, C>`.

2. *Preconditions*: `Callback` and `C` model `constructible_from<Callback, C>`.

3. *Effects*: Initializes `callback_` with `std::forward<C>(cb)`.
    If `st.stop_requested()` is `true`, then `std::forward<Callback>(callback_)()` is evaluated in the current thread before the constructor returns.
    Otherwise, if `st` has an associated `in_place_stop_source` object, registers the callback with the stop state of the `in_place_stop_source` that `st` is associated with such that `std::forward<Callback>(callback_)()` is evaluated by the first call to `request_stop()` on an associated `in_place_stop_source`.
    The `in_place_stop_callback` object being initialized becomes associated with the `in_place_stop_source` object that `st` is associated with, if any.

4. *Throws*: Any exception thrown by the initialization of `callback_`.

5. *Remarks*: If evaluating `std::forward<Callback>(callback_)()` exits via an exception, then `terminate` is invoked ([except.terminate]).

<pre highlight=c++>
~in_place_stop_callback();
</pre>

6. *Effects*: Unregisters the callback from the stop state of the associated `in_place_stop_source` object, if any.
    The destructor does not block waiting for the execution of another callback registered by an associated stop_­callback.
    If `callback_` is concurrently executing on another thread, then the return from the invocation of `callback_` strongly happens before ([intro.races]) `callback_` is destroyed.
    If `callback_` is executing on the current thread, then the destructor does not block ([defns.block]) waiting for the return from the invocation of `callback_`.

7. *Remarks*: A program has undefined behavior if the invocation of this function does not strongly happen before the beginning of the invocation of the destructor of the associated `in_place_stop_source` object, if any.

# Execution control library <b>[exec]</b> # {#spec-execution}

1. This Clause describes components supporting execution of function objects [function.objects].

2. The following subclauses describe the requirements, concepts, and components for execution control primitives as summarized in Table 1.

<table>
<caption>Table 1: Execution control library summary <b>[tab:execution.summary]</b></caption>
<th><td>Subclause</td><td>Header</td></th>
<tr style="border-bottom-style: hidden;"><td><a href="#spec-execution.schedulers">[exec.sched]</a></td><td>Schedulers</td><td>`<execution>`</td></tr>
<tr style="border-bottom-style: hidden;"><td><a href="#spec-execution.receivers">[exec.recv]</a></td><td>Receivers</td><td></td></tr>
<tr style="border-bottom-style: hidden;"><td><a href="#spec-execution.op_state">[exec.op_state]</a></td><td>Operation states</td><td></td></tr>
<tr style="border-bottom-style: hidden;"><td><a href="#spec-execution.senders">[exec.snd]</a></td><td>Senders</td><td></td></tr>
<tr><td><a href="#spec-execution.execute">[exec.execute]</a></td><td>One-way execution</td><td></td></tr>
</table>

3. [<i>Note:</i> A large number of execution control primitives are customization point objects. For an object one might define multiple types of customization point objects, for which different rules apply.**** Table 2 shows the types of customization point objects used in the execution control library:

<table>
<caption>Table 2: Types of customization point objects in the execution control library <b>[tab:execution.cpos]</b></caption>
<tr>
    <th>Customization point object type</th>
    <th>Purpose</th>
    <th>Examples</th>
</tr>
<tr>
    <td>core</td>
    <td>provide core execution functionality, and connection between core components</td>
    <td>`connect`, `start`, `execute`</td>
</tr>
<tr>
    <td>completion signals</td>
    <td>called by senders to announce the completion of the work (success, error, or cancellation)</td>
    <td>`set_value`, `set_error`, `set_stopped`</td>
</tr>
<tr>
    <td><a href="#spec-execution.senders">senders</a></td>
    <td>allow the specialization of the provided sender algorithms</td>
    <td>
        <ul>
            <li>sender factories (`schedule`, `transfer_just`, `read`, ...)</li>
            <li>sender adaptors (`transfer`, `then`, `let_value`, ...)</li>
            <li>sender consumers (`start_detached`, `sync_wait`)</li>
        </ul>
    </td>
</tr>
<tr>
    <td><a href="#spec-execution.queries">general queries</a></td>
    <td>allow querying different properties of execution objects</td>
    <td> `get_scheduler`, `get_delegatee_scheduler`, `get_allocator`, `get_stop_token`</td>
</tr>
<tr>
    <td><a href="#spec-execution.schedulers.queries">scheduler queries</a></td>
    <td>allow querying schedulers properties</td>
    <td> `get_forward_progress_guarantee`, `execute_may_block_caller`</td>
</tr>
<tr>
    <td><a href="#spec-execution.senders.queries">sender queries</a></td>
    <td>allow querying senders properties</td>
    <td> `get_completion_scheduler`</td>
</tr>
</table>

-- <i>end note</i>]

## Header `<execution>` synopsis <b>[exec.syn]</b> ## {#spec-execution.syn}

<pre highlight=c++>
namespace std::execution {
  // [exec.helpers], helper concepts
  template&lt;class T>
    concept <i>movable-value</i> = <i>see-below</i>; // exposition only

  template&lt;class From, class To>
    concept <i>decays-to</i> = same_as&lt;decay_t&lt;From>, To>; // exposition only

  template&lt;class T>
    concept <i>class-type</i> = <i>decays-to</i>&lt;T, T> && is_class_v&lt;T>;  // exposition only

  // [exec.queries], general queries
  namespace <i>general-queries</i> { // exposition only
    struct get_scheduler_t;
    struct get_delegatee_scheduler_t;
    struct get_allocator_t;
    struct get_stop_token_t;
  }
  using <i>general-queries</i>::get_scheduler_t;
  using <i>general-queries</i>::get_delegatee_scheduler_t;
  using <i>general-queries</i>::get_allocator_t;
  using <i>general-queries</i>::get_stop_token_t;
  inline constexpr get_scheduler_t get_scheduler{};
  inline constexpr get_delegatee_scheduler_t get_delegatee_scheduler{};
  inline constexpr get_allocator_t get_allocator{};
  inline constexpr get_stop_token_t get_stop_token{};

  template &lt;class T>
    using stop_token_of_t =
      remove_cvref_t&lt;decltype(get_stop_token(declval&lt;T>()))>;

  // [exec.env], execution environments
  namespace <i>exec-envs</i> { // exposition only
    struct no_env;
    struct <i>empty-env</i> {}; // exposition only
    struct get_env_t;
    struct forwarding_env_query_t;
  }
  using <i>exec-envs</i>::no_env;
  using <i>exec-envs</i>::<i>empty-env</i>;
  using <i>exec-envs</i>::get_env_t;
  using <i>exec-envs</i>::forwarding_env_query_t;
  inline constexpr get_env_t get_env {};
  inline constexpr forwarding_env_query_t forwarding_env_query{};
  template &lt;class T>
    concept <i>forwarding-env-query</i> = // exposition only
      forwarding_env_query(T{});

  template &lt;class T>
    using env_of_t = decltype(get_env(declval&lt;T>()));

  // [exec.sched], schedulers
  template&lt;class S>
    concept scheduler = <i>see-below</i>;

  // [exec.sched_queries], scheduler queries
  enum class forward_progress_guarantee;
  namespace <i>schedulers-queries</i> { // exposition only
    struct forwarding_scheduler_query_t;
    struct get_forward_progress_guarantee_t;
  }
  using <i>schedulers-queries</i>::forwarding_scheduler_query_t;
  using <i>schedulers-queries</i>::get_forward_progress_guarantee_t;
  inline constexpr forwarding_scheduler_query_t forwarding_scheduler_query{};
  inline constexpr get_forward_progress_guarantee_t get_forward_progress_guarantee{};
}

namespace std::this_thread {
  namespace <i>this-thread-queries</i> { // exposition only
    struct execute_may_block_caller_t;
  }
  using <i>this-thread-queries</i>::execute_may_block_caller_t;
  inline constexpr execute_may_block_caller_t execute_may_block_caller{};
}

namespace std::execution {
  // [exec.recv], receivers
  template &lt;class T>
    concept receiver = <i>see-below</i>;

  template &lt;class T, class Completions>
    concept receiver_of = <i>see-below</i>;

  namespace <i>receivers</i> { // exposition only
    struct set_value_t;
    struct set_error_t;
    struct set_stopped_t;
  }
  using <i>receivers</i>::set_value_t;
  using <i>receivers</i>::set_error_t;
  using <i>receivers</i>::set_stopped_t;
  inline constexpr set_value_t set_value{};
  inline constexpr set_error_t set_error{};
  inline constexpr set_stopped_t set_stopped{};

  // [exec.recv_queries], receiver queries
  namespace <i>receivers-queries</i> { // exposition only
    struct forwarding_receiver_query_t;
  }
  using <i>receivers-queries</i>::forwarding_receiver_query_t;
  inline constexpr forwarding_receiver_query_t forwarding_receiver_query{};
  template &lt;class T>
    concept <i>forwarding-receiver-query</i> = // exposition only
      forwarding_receiver_query(T{});

  // [exec.op_state], operation states
  template&lt;class O>
    concept operation_state = <i>see-below</i>;

  namespace <i>op-state</i> { // exposition only
    struct start_t;
  }
  using <i>op-state</i>::start_t;
  inline constexpr start_t start{};

  // [exec.snd], senders
  template&lt;class S, class E = no_env>
    concept sender = <i>see-below</i>;

  template&lt;class S, class R>
    concept sender_to = <i>see-below</i>;

  template&ltclass S, class E = no_env, class... Ts>
    concept sender_of = <i>see below</i>;

  template&lt;class... Ts>
    struct <i>type-list</i>; // exposition only

  template&lt;class S, class E = no_env>
    using <i>single-sender-value-type</i> = <i>see below</i>; // exposition only

  template &lt;class S, class E = no_env>
    concept <i>single-sender</i> = <i>see below</i>; // exposition only

  // [exec.sndtraits], completion signatures
  namespace <i>completion-signatures</i> { // exposition only
    struct get_completion_signatures_t;
  }
  using <i>completion-signatures</i>::get_completion_signatures_t;
  inline constexpr get_completion_signatures_t get_completion_signatures {};

  template &lt;class S, class E = no_env>
      requires sender&lt;S, E>
    using completion_signatures_of_t = <i>see below</i>;

  template &lt;class E> // arguments are not associated entities ([lib.tmpl-heads])
    struct dependent_completion_signatures;

  template &lt;class... Ts>
    using <i>decayed-tuple</i> = tuple&lt;decay_t&lt;Ts>...>; // exposition only

  template &lt;class... Ts>
    using <i>variant-or-empty</i> = <i>see below</i>; // exposition only

  template&lt;class S,
           class E = no_env,
           template &lt;class...> class Tuple = <i>decayed-tuple</i>,
           template &lt;class...> class Variant = <i>variant-or-empty</i>>
      requires sender&lt;S, E>
    using value_types_of_t = <i>see below</i>;

  template&lt;class S,
           class E = no_env,
           template &lt;class...> class Variant = <i>variant-or-empty</i>>
      requires sender&lt;S, E>
    using error_types_of_t = <i>see below</i>;

  template&lt;class S, class E = no_env>
      requries sender&lt;S, E>
    inline constexpr bool sends_stopped = <i>see below</i>;

  // [exec.connect], the connect sender algorithm
  namespace <i>senders-connect</i> { // exposition only
    struct connect_t;
  }
  using <i>senders-connect</i>::connect_t;
  inline constexpr connect_t connect{};

  template &lt;class S, class R>
    using connect_result_t = decltype(connect(declval&lt;S>(), declval&lt;R>()));

  // [exec.snd_queries], sender queries
  namespace <i>senders-queries</i> { // exposition only
    struct forwarding_sender_query_t;

    template &lt;class CPO>
    struct get_completion_scheduler_t;
  }
  using <i>senders-queries</i>::forwarding_sender_query_t;
  using <i>senders-queries</i>::get_completion_scheduler_t;
  inline constexpr forwarding_sender_query_t forwarding_sender_query{};

  namespace <i>senders-queries</i> { // exposition only
    template &lt;class T>
      concept <i>forwarding-sender-query</i> = // exposition only
        forwarding_sender_query(T{});
  }

  template &lt;class CPO>
  inline constexpr get_completion_scheduler_t&lt;CPO> get_completion_scheduler{};

  // [exec.factories], sender factories
  namespace <i>senders-factories</i> { // exposition only
    struct schedule_t;
    struct transfer_just_t;
  }
  inline constexpr <i>unspecified</i> just{};
  inline constexpr <i>unspecified</i> just_error{};
  inline constexpr <i>unspecified</i> just_stopped{};
  using <i>senders-factories</i>::schedule_t;
  using <i>senders-factories</i>::transfer_just_t;
  inline constexpr schedule_t schedule{};
  inline constexpr transfer_just_t transfer_just{};
  inline constexpr <i>unspecified</i> read{};

  template &lt;scheduler S>
    using schedule_result_t = decltype(schedule(declval&lt;S>()));

  // [exec.adapt], sender adaptors
  namespace <i>sender-adaptor-closure</i> { // exposition only
    template&lt;<i>class-type</i> D>
      struct sender_adaptor_closure { };
  }
  using <i>sender-adaptor-closure</i>::sender_adaptor_closure;

  namespace <i>sender-adaptors</i> { // exposition only
    struct on_t;
    struct transfer_t;
    struct schedule_from_t;
    struct then_t;
    struct upon_error_t;
    struct upon_stopped_t;
    struct let_value_t;
    struct let_error_t;
    struct let_stopped_t;
    struct bulk_t;
    struct split_t;
    struct when_all_t;
    struct when_all_with_variant_t;
    struct transfer_when_all_t;
    struct transfer_when_all_with_variant_t;
    struct into_variant_t;
    struct stopped_as_optional_t;
    struct stopped_as_error_t;
    struct ensure_started_t;
  }
  using <i>sender-adaptors</i>::on_t;
  using <i>sender-adaptors</i>::transfer_t;
  using <i>sender-adaptors</i>::schedule_from_t;
  using <i>sender-adaptors</i>::then_t;
  using <i>sender-adaptors</i>::upon_error_t;
  using <i>sender-adaptors</i>::upon_stopped_t;
  using <i>sender-adaptors</i>::let_value_t;
  using <i>sender-adaptors</i>::let_error_t;
  using <i>sender-adaptors</i>::let_stopped_t;
  using <i>sender-adaptors</i>::bulk_t;
  using <i>sender-adaptors</i>::split_t;
  using <i>sender-adaptors</i>::when_all_t;
  using <i>sender-adaptors</i>::when_all_with_variant_t;
  using <i>sender-adaptors</i>::transfer_when_all_t;
  using <i>sender-adaptors</i>::transfer_when_all_with_variant_t;
  using <i>sender-adaptors</i>::into_variant_t;
  using <i>sender-adaptors</i>::stopped_as_optional_t;
  using <i>sender-adaptors</i>::stopped_as_error_t;
  using <i>sender-adaptors</i>::ensure_started_t;

  inline constexpr on_t on{};
  inline constexpr transfer_t transfer{};
  inline constexpr schedule_from_t schedule_from{};

  inline constexpr then_t then{};
  inline constexpr upon_error_t upon_error{};
  inline constexpr upon_stopped_t upon_stopped{};

  inline constexpr let_value_t let_value{};
  inline constexpr let_error_t let_error{};
  inline constexpr let_stopped_t let_stopped{};

  inline constexpr bulk_t bulk{};

  inline constexpr split_t split{};
  inline constexpr when_all_t when_all{};
  inline constexpr when_all_with_variant_t when_all_with_variant{};
  inline constexpr transfer_when_all_t transfer_when_all{};
  inline constexpr transfer_when_all_with_variant_t
    transfer_when_all_with_variant{};

  inline constexpr into_variant_t into_variant{};

  inline constexpr stopped_as_optional_t stopped_as_optional;

  inline constexpr stopped_as_error_t stopped_as_error;

  inline constexpr ensure_started_t ensure_started{};

  // [exec.consumers], sender consumers
  namespace <i>sender-consumers</i> { // exposition only
    struct start_detached_t;
  }
  using <i>sender-consumers</i>::start_detached_t;
  inline constexpr start_detached_t start_detached{};

  // [exec.utils], sender and receiver utilities
  // [exec.utils.rcvr_adptr]
  template&lt;
      <i>class-type</i> Derived,
      receiver Base = <i>unspecified</i>> // arguments are not associated entities ([lib.tmpl-heads])
    class receiver_adaptor;

  template &lt;class Fn>
    concept <i>completion-signature</i> = <i>// exposition only</i>
      <i>see below</i>;

  // [exec.utils.cmplsigs]
  template &lt;<i>completion-signature</i>... Fns>
    struct completion_signatures {};

  template &lt;class... Args> <i>// exposition only</i>
    using <i>default-set-value</i> =
      completion_signatures&lt;set_value_t(Args...)>;

  template &lt;class Err> <i>// exposition only</i>
    using <i>default-set-error</i> =
      completion_signatures&lt;set_error_t(Err)>;

  template &lt;class Sigs, class E> // exposition only
    concept <i>valid-completion-signatures</i> = <i>see below</i>;

  // [exec.utils.mkcmplsigs]
  template &lt;
    sender Sndr,
    class Env = no_env,
    <i>valid-completion-signatures&lt;Env></i> AddlSigs = completion_signatures<>,
    template &lt;class...> class SetValue = <i>/* see below */</i>,
    template &lt;class> class SetError = <i>/* see below */</i>,
    <i>valid-completion-signatures&lt;Env></i> SetStopped = completion_signatures&lt;set_stopped_t()>>
      requires sender&lt;Sndr, Env>
  using make_completion_signatures = completion_signatures<<i>/* see below */</i>>;

  // [exec.ctx], execution contexts
  class run_loop;
}

namespace std::this_thread {
  namespace <i>this-thread</i> { // exposition only
    struct <i>sync-wait-env</i>; <i>// exposition only</i>
    template&lt;class S>
        requires sender&lt;S, <i>sync-wait-env</i>>
      using <i>sync-wait-type</i> = <i>see-below</i>; // exposition-only
    template&lt;class S>
      using <i>sync-wait-with-variant-type</i> = <i>see-below</i>; // exposition-only

    struct sync_wait_t;
    struct sync_wait_with_variant_t;
  }
  using <i>this-thread</i>::sync_wait_t;
  using <i>this-thread</i>::sync_wait_with_variant_t;
  inline constexpr sync_wait_t sync_wait{};
  inline constexpr sync_wait_with_variant_t sync_wait_with_variant{};
}

namespace std::execution {
  // [exec.execute], one-way execution
  namespace <i>execute</i> { // exposition only
    struct execute_t;
  }
  using <i>execute</i>::execute_t;
  inline constexpr execute_t execute{};

  // [exec.as_awaitable]
  namespace <i>coro-utils</i> { // exposition only
    struct as_awaitable_t;
  }
  using <i>coro-utils</i>::as_awaitable_t;
  inline constexpr as_awaitable_t as_awaitable;

  // [exec.with_awaitable_senders]
  template &lt;<i>class-type</i> Promise>
    struct with_awaitable_senders;
}
</pre>

## Helper concepts <b>[exec.helpers]</b> ## {#spec-execution.helpers}

    <pre highlight=c++>
    template&lt;class T>
    concept <i>movable-value</i> = // exposition only
      move_constructible&lt;decay_t&lt;T>> &&
      constructible_from&lt;decay_t&lt;T>, T>;
    </pre>

## General queries <b>[exec.queries]</b> ## {#spec-execution.queries}

### `execution::get_scheduler` <b>[exec.queries.get_scheduler]</b> ### {#spec-execution.receivers.queries.get_scheduler}

1. `execution::get_scheduler` is used to ask an object for its associated scheduler.

2. The name `execution::get_scheduler` denotes a customization point object. For some subexpression `r`, if the type of `r` is (possibly cv-qualified) `no_env`, then `execution::get_scheduler(r)` is ill-formed. Otherwise, it is expression equivalent to:

    1. `tag_invoke(execution::get_scheduler, as_const(r))`, if this expression is well formed.

        * <i>Mandates:</i> The `tag_invoke` expression above is not
            potentially-throwing and its type satisfies `execution::scheduler`.

    2. Otherwise, `execution::get_scheduler(r)` is ill-formed.

3. `execution::get_scheduler()` (with no arguments) is expression-equivalent to `execution::read(execution::get_scheduler)`.

### `execution::get_delegatee_scheduler` <b>[exec.queries.get_delegatee_scheduler]</b> ### {#spec-execution.receivers.queries.get_delegatee_scheduler}

1. `execution::get_delegatee_scheduler` is used to ask an object for a scheduler that may be used to delegate work to for the purpose of forward progress delegation.

2. The name `execution::get_delegatee_scheduler` denotes a customization point object. For some subexpression `r`, if the type of `r` is (possibly cv-qualified) `no_env`, then `execution::get_delegatee_scheduler(r)` is ill-formed. Otherwise, it is expression equivalent to:

    1. `tag_invoke(execution::get_delegatee_scheduler, as_const(r))`, if this expression is well formed.

        * <i>Mandates:</i> The `tag_invoke` expression above is not
            potentially-throwing and its type satisfies `execution::scheduler`.

    2. Otherwise, `execution::get_delegatee_scheduler(r)` is ill-formed.

3. `execution::get_delegatee_scheduler()` (with no arguments) is expression-equivalent to `execution::read(execution::get_delegatee_scheduler)`.

### `execution::get_allocator` <b>[exec.queries.get_allocator]</b> ### {#spec-execution.receivers.queries.get_allocator}

1. `execution::get_allocator` is used to ask an object for its associated allocator.

2. The name `execution::get_allocator` denotes a customization point object. For some subexpression `r`, if the type of `r` is (possibly cv-qualified) `no_env`, then `execution::get_allocator(r)` is ill-formed. Otherwise, it is expression equivalent to:

    1. `tag_invoke(execution::get_allocator, as_const(r))`, if this expression is well formed.

        * <i>Mandates:</i> The `tag_invoke` expression above is not
            potentially-throwing and its type satisfies <i>Allocator</i>.

    2. Otherwise, `execution::get_allocator(r)` is ill-formed.

3. `execution::get_allocator()` (with no arguments) is expression-equivalent to `execution::read(execution::get_allocator)`.

### `execution::get_stop_token` <b>[exec.queries.get_stop_token]</b> ### {#spec-execution.receivers.queries.get_stop_token}

1. `execution::get_stop_token` is used to ask an object for an associated stop token.

2. The name `execution::get_stop_token` denotes a customization point object. For some subexpression `r`, if the type of `r` is (possibly cv-qualified) `no_env`, then `execution::get_stop_token(r)` is ill-formed. Otherwise, it is expression equivalent to:

    1. `tag_invoke(execution::get_stop_token, as_const(r))`, if this expression is well formed.

        * <i>Mandates:</i> The `tag_invoke` expression above is not
            potentially-throwing and its type satisfies `stoppable_token`.

    2. Otherwise, `never_stop_token{}`.

3. `execution::get_stop_token()` (with no arguments) is expression-equivalent to `execution::read(execution::get_stop_token)`.

## Execution environments <b>[exec.env]</b> ## {#spec-execution.environment}

1. An <i>execution environment</i> contains state associated with the completion of an asynchronous operation. Every receiver has an associated execution environment, accessible with the `get_env` receiver query. The state of an execution environment is accessed with customization point objects. An execution environment may respond to any number of these environment queries.

2. An <i>environment query</i> is a customization point object that accepts as its first argument an execution environment. For an environment query `EQ` and an object `e` of type `no_env`, the expression `EQ(e)` shall be ill-formed.

### `execution::no_env` <b>[exec.no_env]</b> ### {#spec-execution.environment.no_env}

   <pre highlight="c++">
    namespace <i>exec-envs</i> { // exposition only
      struct no_env {
        friend void tag_invoke(auto, same_as&lt;no_env> auto, auto&&...) = delete;
      };
    }
    </pre>

  1. `no_env` is a special environment used by the `sender` concept and by the `get_completion_signatures` customization point when the user has specified no environment argument. [<i>Note:</i> A user may choose to not specify an environment in order to see if a sender knows its completion signatures independent of any particular execution environment. -- <i>end note</i>]

### `execution::get_env` <b>[exec.get_env]</b> ### {#spec-execution.environment.get_env}

    <pre highlight="c++">
    namespace <i>exec-envs</i> { // exposition only
      struct get_env_t;
    }
    inline constexpr <i>exec-envs</i>::get_env_t get_env {};
    </pre>

1. `get_env` is a customization point object. For some subexpression `r`, `get_env(r)` is expression-equivalent to

    1. `tag_invoke(execution::get_env, r)` if that expression is well-formed.

        * <i>Mandates:</i> The decayed type of the above expression is not `no_env`.

    2. Otherwise, `get_env(r)` is ill-formed.

2. If `get_env(r)` is an lvalue, the object it refers to shall be valid while `r` is valid.

### `execution::forwarding_env_query` <b>[exec.fwd_env]</b> ### {#spec-execution.environment.forwarding_env_query}

1. `execution::forwarding_env_query` is used to ask a customization point object whether it is a environment query that should be forwarded through environment adaptors.

2. The name `execution::forwarding_env_query` denotes a customization point object. For some subexpression `t`, `execution::forwarding_env_query(t)` is expression equivalent to:

    1. `tag_invoke(execution::forwarding_env_query, t)`, contextually converted to `bool`, if the `tag_invoke` expression is well formed.

        * <i>Mandates:</i> The `tag_invoke` expression is indeed contextually
            convertible to `bool`, that expression and the contextual conversion
            are not potentially-throwing and are core constant expressions if
            `t` is a core constant expression.

    2. Otherwise, `true`.

## Schedulers <b>[exec.sched] </b> ## {#spec-execution.schedulers}

1. The `scheduler` concept defines the requirements of a type that allows for scheduling of work on its <i>associated execution context</i>.

    <pre highlight=c++>
    template&lt;class S>
      concept scheduler =
        requires(S&& s, const get_completion_scheduler_t&lt;set_value_t> tag) {
          { execution::schedule(std::forward&lt;S>(s)) } -> sender;
          { tag_invoke(tag, execution::schedule(std::forward&lt;S>(s))) } -> same_as&lt;remove_cvref_t&lt;S>>;
        } &&
        equality_comparable&lt;remove_cvref_t&lt;S>> &&
        copy_constructible&lt;remove_cvref_t&lt;S>>;
    </pre>

2. Let `S` be the type of a scheduler and let `E` be the type of an execution environment for which `sender<schedule_result_t<S>, E>` is `true`. Then `sender_of<schedule_result_t<S>, E>` shall be `true`.

3. None of a scheduler's copy constructor, destructor, equality comparison, or `swap` member functions shall exit via an exception.

4. None of these member functions, nor a scheduler type's `schedule` function, shall introduce data races as a result of concurrent invocations of those functions from different threads.

5. For any two (possibly const) values `s1` and `s2` of some scheduler type `S`, `s1 == s2` shall return `true` only if both `s1` and `s2` are handles to the same associated execution context.

6. For a given scheduler expression `s`, the expression `execution::get_completion_scheduler<set_value_t>(execution::schedule(s))` shall compare equal to `s`.

7. A scheduler type's destructor shall not block pending completion of any receivers connected to the sender objects returned from `schedule`. [<i>Note:</i> The ability to wait for completion of submitted function objects may be provided by the associated execution
    context of the scheduler. <i>—end note</i>]

### Scheduler queries <b>[exec.sched_queries]</b> ### {#spec-execution.schedulers.queries}

#### `execution::forwarding_scheduler_query` <b>[exec.sched_queries.forwarding_scheduler_query]</b> #### {#spec-execution.schedulers.queries.forwarding_scheduler_query}

1. `execution::forwarding_scheduler_query` is used to ask a customization point object whether it is a scheduler query that should be forwarded through scheduler adaptors.

2. The name `execution::forwarding_scheduler_query` denotes a customization point object. For some subexpression `t`, `execution::forwarding_scheduler_query(t)` is expression equivalent to:

    1. `tag_invoke(execution::forwarding_scheduler_query, t)`, contextually converted to `bool`, if the `tag_invoke` expression is well formed.

        * <i>Mandates:</i> The `tag_invoke` expression is indeed contextually
            convertible to `bool`, that expression and the contextual conversion
            are not potentially-throwing and are core constant expressions if
            `t` is a core constant expression.

    2. Otherwise, `false`.

#### `execution::get_forward_progress_guarantee` <b>[exec.sched_queries.get_forward_progress_guarantee]</b> #### {#spec-execution.schedulers.queries.get_forward_progress_guarantee}

<pre highlight=c++>
enum class forward_progress_guarantee {
  concurrent,
  parallel,
  weakly_parallel
};
</pre>

1. `execution::get_forward_progress_guarantee` is used to ask a scheduler about the forward progress guarantees of execution agents created by that scheduler.

2. The name `execution::get_forward_progress_guarantee` denotes a customization point object. For some subexpression `s`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::scheduler`, `execution::get_forward_progress_guarantee` is ill-formed.
    Otherwise, `execution::get_forward_progress_guarantee(s)` is expression equivalent to:

    1. `tag_invoke(execution::get_forward_progress_guarantee, as_const(s))`, if this expression is well formed.

        * <i>Mandates:</i> The `tag_invoke` expression above is not potentially
            throwing and its type is `execution::forward_progress_guarantee`.

    2. Otherwise, `execution::forward_progress_guarantee::weakly_parallel`.

3. If `execution::get_forward_progress_guarantee(s)` for some scheduler `s` returns `execution::forward_progress_guarantee::concurrent`, all execution agents created by that scheduler shall provide the concurrent forward progress guarantee. If it returns
    `execution::forward_progress_guarantee::parallel`, all execution agents created by that scheduler shall provide at least the parallel forward progress guarantee.

#### `this_thread::execute_may_block_caller` <b>[exec.sched_queries.execute_may_block_caller]</b> #### {#spec-execution.schedulers.queries.execute_may_block_caller}

1. `this_thread::execute_may_block_caller` is used to ask a scheduler `s` whether a call `execution::execute(s, f)` with any invocable `f` may block the thread where such a call occurs.

2. The name `this_thread::execute_may_block_caller` denotes a customization point object. For some subexpression `s`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::scheduler`, `this_thread::execute_may_block_caller` is ill-formed. Otherwise,
    `this_thread::execute_may_block_caller(s)` is expression equivalent to:

    1. `tag_invoke(this_thread::execute_may_block_caller, as_const(s))`, if this expression is well formed.

        * <i>Mandates:</i> The `tag_invoke` expression above is not potentially
            throwing and its type is `bool`.

    2. Otherwise, `true`.

3. If `this_thread::execute_may_block_caller(s)` for some scheduler `s` returns `false`, no `execution::execute(s, f)` call with some invocable `f` shall block the calling thread.

## Receivers <b>[exec.recv]</b> ## {#spec-execution.receivers}

1. A <i>receiver</i> represents the continuation of an asynchronous operation.
    An asynchronous operation may complete with a (possibly empty) set of
    values, an error, or it may be cancelled. A receiver has three principal
    operations corresponding to the three ways an asynchronous operation may
    complete: `set_value`, `set_error`, and `set_stopped`. These are
    collectively known as a receiver’s <i>completion-signal operations</i>.

2. The `receiver` concept defines the requirements for a receiver type with an
    unknown set of completion signatures. The `receiver_of` concept defines the
    requirements for a receiver type with a known set of completion signatures.

    <pre highlight=c++>
    template&lt;class T>
      concept receiver =
        move_constructible&lt;remove_cvref_t&lt;T>> &&
        constructible_from&lt;remove_cvref_t&lt;T>, T> &&
        requires(const remove_cvref_t&lt;T>& t) {
          execution::get_env(t);
        };

    template &lt;class Signature, class T>
      concept <i>valid-completion-for</i> = <i>// exposition only</i>
        requires (Signature* sig) {
            []&lt;class Ret, class... Args>(Ret(*)(Args...))
                requires nothrow_tag_invocable&lt;Ret, remove_cvref_t&lt;T>, Args...>
            {}(sig);
        };

    template &lt;class T, class Completions>
      concept receiver_of =
        receiver&lt;T> &amp;&amp;
        requires (Completions* completions) {
            []&lt;<i>valid-completion-for</i>&lt;T>...Sigs>(completion_signatures&lt;Sigs...>*)
            {}(completions);
        };
    </pre>

3. The receiver’s completion-signal operations have semantic requirements that are collectively known as the <i>receiver contract</i>, described below:

    1. None of a receiver’s completion-signal operations shall be invoked before `execution::start` has been called on the operation state object that was returned by `execution::connect` to connect that receiver to a sender.

    2. Once `execution::start` has been called on the operation state object, exactly one of the receiver’s completion-signal operations shall complete non-exceptionally before the receiver is destroyed.

    3. If `execution::set_value` exits with an exception, it is still valid to call `execution::set_error` or `execution::set_stopped` on the receiver, but it is no longer valid to call `execution::set_value` on the receiver.

4. Once one of a receiver’s completion-signal operations has completed non-exceptionally, the receiver contract has been satisfied.

5. Receivers have an associated <i>execution environment</i> that is accessible by passing the receiver to `execution::get_env`. A sender can obtain information about the current execution environment by querying the environment of the receiver to which it is connected. The set of environment queries is extensible and includes:

    * `execution::get_scheduler`: used to obtain a <i>suggested scheduler</i> to
        be used when a sender needs to launch additional work. [<i>Note:</i> the
        presence of this query on a receiver's environment does not bind a
        sender to use its result. --<i>end note</i>]

    * `execution::get_delegatee_scheduler`: used to obtain a <i>delegatee
        scheduler</i> on which an algorithm or scheduler may delegate work for the
        purpose of ensuring forward progress.

    * `execution::get_allocator`: used to obtain a <i>suggested allocator</i>
        to be used when a sender needs to allocate memory. [<i>Note:</i> the
        presence of this query on a receiver does not bind a sender to use its
        result. --<i>end note</i>]

    * `execution::get_stop_token`: used to obtain the <i>associated stop
        token</i> to be used by a sender to check whether a stop request has
        been made. [<i>Note</i>: such a stop token being signalled does not bind
        the sender to actually cancel any work. --<i>end note</i>]

6. Let `r` be a receiver, `s` be a sender, and `op_state` be an operation state
    resulting from an `execution::connect(s, r)` call. Let `token` be a stop
    token resulting from an `execution::get_stop_token(execution::get_env(r))`
    call. `token` must remain valid at least until a call to a receiver
    completion-signal function of `r` returns successfully. [<i>Note</i>: this
    means that, unless it knows about further guarantees provided by the
    receiver `r`, the implementation of `op_state` should not use `token` after
    it makes a call to a receiver completion-signal function of `r`. This also
    implies that any stop callbacks registered on `token` by the implementation
    of `op_state` or `s` must be destroyed before such a call to a receiver
    completion-signal function of `r`. --<i>end note</i>]

### `execution::set_value` <b>[exec.set_value]</b> ### {#spec-execution.receivers.set_value}

1. `execution::set_value` is used to send a <i>value completion signal</i> to a receiver.

2. The name `execution::set_value` denotes a customization point object. The
    expression `execution::set_value(R, Vs...)` for some subexpressions `R` and
    `Vs...` is expression-equivalent to:

    1. `tag_invoke(execution::set_value, R, Vs...)`, if that expression is
        valid. If the function selected by `tag_invoke` does not send the
        value(s) `Vs...` to the receiver `R`’s value channel, the behavior of
        calling `execution::set_value(R, Vs...)` is undefined.

        * <i>Mandates:</i> The `tag_invoke` expression above is not potentially
            throwing.

    2. Otherwise, `execution::set_value(R, Vs...)` is ill-formed.

### `execution::set_error` <b>[exec.set_error]</b> ### {#spec-execution.receivers.set_error}

1. `execution::set_error` is used to send a <i>error signal</i> to a receiver.

2. The name `execution::set_error` denotes a customization point object. The expression `execution::set_error(R, E)` for some subexpressions `R` and `E` is expression-equivalent to:

    1. `tag_invoke(execution::set_error, R, E)`, if that expression is valid. If
        the function selected by `tag_invoke` does not send the error `E` to the
        receiver `R`’s error channel, the behavior of calling
        `execution::set_error(R, E)` is undefined.

        * <i>Mandates:</i> The `tag_invoke` expression above is not potentially
            throwing.

    2. Otherwise, `execution::set_error(R, E)` is ill-formed.

### `execution::set_stopped` <b>[exec.set_stopped]</b> ### {#spec-execution.receivers.set_stopped}

1. `execution::set_stopped` is used to send a <i>stopped signal</i> to a receiver.

2. The name `execution::set_stopped` denotes a customization point object. The expression `execution::set_stopped(R)` for some subexpression `R` is expression-equivalent to:

    1. `tag_invoke(execution::set_stopped, R)`, if that expression is valid. If the function selected by `tag_invoke` does not signal the receiver `R`’s stopped channel, the behavior of calling `execution::set_stopped(R)` is undefined.

        * <i>Mandates:</i> The `tag_invoke` expression above is not potentially
            throwing.

    2. Otherwise, `execution::set_stopped(R)` is ill-formed.

### Receiver queries <b>[exec.recv_queries]</b> ### {#spec-execution.receivers.queries}

#### `execution::forwarding_receiver_query` <b>[exec.recv_queries.forwarding_receiver_query]</b> #### {#spec-execution.receivers.queries.forwarding_receiver_query}

1. `execution::forwarding_receiver_query` is used to ask a customization point object whether it is a receiver query that should be forwarded through receiver adaptors.

2. The name `execution::forwarding_receiver_query` denotes a customization point object. For some subexpression `t`, `execution::forwarding_receiver_query(t)` is expression equivalent to:

    1. `tag_invoke(execution::forwarding_receiver_query, t)`, contextually converted to `bool`, if the `tag_invoke` expression is well formed.

        * <i>Mandates:</i> The `tag_invoke` expression is indeed contextually
            convertible to `bool`, that expression and the contextual conversion
            are not potentially-throwing and are core constant expressions if
            `t` is a core constant expression.

    2. Otherwise, `false` if the type of `t` is one of `set_value_t`, `set_error_t`, or `set_stopped_t`.

    3. Otherwise, `true`.

3. [*Note:* Currently the only standard receiver query is `execution::get_env` -- *end note*]

## Operation states <b>[exec.op_state]</b> ## {#spec-execution.op_state}

1. The `operation_state` concept defines the requirements for an operation state type, which allows for starting the execution of work.

    <pre highlight=c++>
    template&lt;class O>
      concept operation_state =
        destructible&lt;O> &&
        is_object_v&lt;O> &&
        requires (O& o) {
          { execution::start(o) } noexcept;
        };
    </pre>

2. Any operation state types defined by the implementation are non-movable types.

### `execution::start` <b>[exec.op_state.start]</b> ### {#spec-execution.op_state.start}

1. `execution::start` is used to start work represented by an operation state object.

2. The name `execution::start` denotes a customization point object. The expression `execution::start(O)` for some lvalue subexpression `O` is expression-equivalent to:

    1. `tag_invoke(execution::start, O)`, if that expression is valid. If the function selected by `tag_invoke` does not start the work represented by the operation state `O`, the behavior of calling `execution::start(O)` is undefined.

        * <i>Mandates:</i> The `tag_invoke` expression above is not potentially
            throwing.

    2. Otherwise, `execution::start(O)` is ill-formed.

3. The caller of `execution::start(O)` must guarantee that the lifetime of the operation state object `O` extends at least until one of the receiver completion-signal functions of a receiver `R` passed into the `execution::connect` call that produced `O` is ready
    to successfully return. [<i>Note:</i> this allows for the receiver to manage the lifetime of the operation state object, if destroying it is the last operation it performs in its completion-signal functions. --<i>end note</i>]

## Senders <b>[exec.snd]</b> ## {#spec-execution.senders}

1. A sender describes a potentially asynchronous operation. A sender's responsibility is to fulfill the receiver contract of a connected receiver by delivering one of the receiver completion-signals.

2. The `sender` concept defines the requirements for a sender type. The `sender_to` concept defines the requirements for a sender type capable of being connected with a specific receiver type.

    <pre highlight=c++>
    template &lt;class T, template &lt;class...> class C>
      inline constexpr bool <i>is-instance-of</i> = false; // exposition only

    template &lt;class... Ts, template &lt;class...> class C>
      inline constexpr bool <i>is-instance-of</i>&lt;C&lt;Ts...>, C> = true;

    template &lt;class Sigs, class E>
      concept <i>valid-completion-signatures</i> = // exposition only
        <i>is-instance-of</i>&lt;Sigs, completion_signatures> ||
        (
          same_as&lt;Sigs, dependent_completion_signatures&lt;no_env>> &&
          same_as&lt;E, no_env>
        );

    template &lt;class S, class E>
      concept <i>sender-base</i> = // exposition only
        requires (S&& s, E&& e) {
          { get_completion_signatures(std::forward&lt;S>(s), std::forward&lt;E>(e)) } ->
            <i>valid-completion-signatures</i>&lt;E>;
        };

    template&lt;class S, class E = no_env>
      concept sender =
        <i>sender-base</i>&lt;S, E> &amp;&amp;
        <i>sender-base</i>&lt;S, no_env> &amp;&amp;
        move_constructible&lt;remove_cvref_t&lt;S>>;

    template&lt;class S, class R>
      concept sender_to =
        sender&lt;S, env_of_t&lt;R>> &amp;&amp;
        receiver_of&lt;R, completion_signatures_of_t&lt;S, env_of_t&lt;R>>> &amp;&amp;
        requires (S&amp;&amp; s, R&amp;&amp; r) {
          execution::connect(std::forward&lt;S>(s), std::forward&lt;R>(r));
        };
    </pre>

3. The `sender_of` concept defines the requirements for a sender type that on successful completion sends the specified set of value types.

    <pre highlight=c++>
    template&ltclass S, class E = no_env, class... Ts>
      concept sender_of =
        sender&ltS, E> &&
        same_as&lt
          <i>type-list</i>&ltTs...>,
          value_types_of_t&ltS, E, <i>type-list</i>, type_identity_t>
        >;
    </pre>

### Completion signatures <b>[exec.sndtraits]</b> ### {#spec-exec.sndtraits}

1. This clause makes use of the following implementation-defined entities:

    <pre highlight="c++">
    struct <i>no-completion-signatures</i> {};
    </pre>

#### `execution::completion_signatures_of_t` <b>[exec.sndtraitst]</b> #### {#spec-exec.sndtraitst}

1. The alias template `completion_signatures_of_t` is used to query a sender type for facts associated with the signals it sends.

2. `completion_signatures_of_t` also recognizes awaitables as senders. For this clause ([exec]):

    1. An <i>awaitable</i> is an expression that would be well-formed as the operand of a `co_await` expression within a given context.

    2. For any type `T`, <code><i>is-awaitable</i>&lt;T></code> is `true` if and only if an expression of that type is an awaitable as described above within the context of a coroutine whose promise type does not define a member `await_transform`. For a coroutine promise type `P`, <code><i>is-awaitable</i>&lt;T, P></code> is `true` if and only if an expression of that type is an awaitable as described above within the context of a coroutine whose promise type is `P`.

    3. For an awaitable `a` such that `decltype((a))` is type `A`, <code><i>await-result-type</i>&lt;A></code> is an alias for <code>decltype(<i>e</i>)</code>, where <code><i>e</i></code> is `a`'s <i>await-resume</i> expression ([expr.await]) within the context of a coroutine whose promise type does not define a member `await_transform`. For a coroutine promise type `P`, <code><i>await-result-type</i>&lt;A, P></code> is an alias for <code>decltype(<i>e</i>)</code>, where <code><i>e</i></code> is `a`'s <i>await-resume</i> expression ([expr.await]) within the context of a coroutine whose promise type is `P`.

3. For types `S` and `E`, the type `completion_signatures_of_t<S, E>` is an
    alias for `decltype(get_completion_signatures(declval<S>(), declval<E>()))`
    if that expression is well-formed and names a type other than
    <code><i>no-completion-signatures</i></code>. Otherwise, it is ill-formed.

4. `execution::get_completion_signatures` is a customization point object. Let
    `s` be an expression such that `decltype((s))` is `S`, and let `e` be an
    expression such that `decltype((e))` is `E`. Then
    `get_completion_signatures(s)` is expression-equivalent to
    `get_completion_signatures(s, no_env{})` and `get_completion_signatures(s,
    e)` is expression-equivalent to:

    1. `tag_invoke_result_t<get_completion_signatures_t, S, E>{}` if that expression is well-formed,

        * <i>Mandates:</i> <code><i>is-instance-of</i>&lt;Sigs,
            completion_signatures></code> or <code><i>is-instance-of</i>&lt;Sigs,
            dependent_completion_signatures></code>, where `Sigs` names the type
            `tag_invoke_result_t<get_completion_signatures_t, S, E>`.

    2. Otherwise, if `remove_cvref_t<S>::completion_signatures` is well-formed
        and names a type, then a value-initialized prvalue of type
        `remove_cvref_t<S>::completion_signatures`,

        * <i>Mandates:</i> <code><i>is-instance-of</i>&lt;Sigs,
            completion_signatures></code> or <code><i>is-instance-of</i>&lt;Sigs,
            dependent_completion_signatures></code>, where `Sigs` names the type `remove_cvref_t<S>::completion_signatures`.

    3. Otherwise, if <code><i>is-awaitable</i>&lt;S></code> is `true`, then

        1. If <code><i>await-result-type</i>&lt;S></code> is <code><i>cv</i> void</code> then a prvalue of a type equivalent to:

            <pre highlight="c++">
            completion_signatures<
              set_value_t(),
              set_error_t(exception_ptr),
              set_stopped_t()>
            </pre>

        2. Otherwise, a prvalue of a type equivalent to:

            <pre highlight="c++">
            completion_signatures<
              set_value_t(<i>await-result-type</i>&lt;S>),
              set_error_t(exception_ptr),
              set_stopped_t()>
            </pre>

    4. Otherwise, <code><i>no-completion-signatures</i>{}</code>.

5. The exposition-only type <code><i>variant-or-empty&lt;Ts...></i></code> is
     defined as follows:

    1. If `sizeof...(Ts)` is greater than zero, <code><i>variant-or-empty&lt;Ts...></i></code> names the type `variant<Us...>` where `Us...` is the pack `decay_t<Ts>...` with duplicate types removed.

    2. Otherwise, <code><i>variant-or-empty&lt;Ts...></i></code> names an implementation defined class type equivalent to the following:

        <pre highlight="c++">
        struct <i>empty-variant</i> {
          <i>empty-variant</i>() = delete;
        };
        </pre>

6. Let `r` be an rvalue receiver of type `R`, and let `S` be the type of a
    sender. If `value_types_of_t<S, env_of_t<R>, Tuple, Variant>` is well
    formed, it shall name the type
    <code>Variant&lt;Tuple&lt;Args<i><sub>0</sub></i>...>,
    Tuple&lt;Args<i><sub>1</sub></i>...>, ...,
    Tuple&lt;Args<i><sub>N</sub></i>...>>></code>, where the type packs
    <code>Args<i><sub>0</sub></i></code> through
    <code>Args<i><sub>N</sub></i></code> are the packs of types the sender `S`
    passes as arguments to `execution::set_value` (besides the receiver object).
    Such a sender `S` shall not odr-use ([basic.def.odr]) `execution::set_value(r,
    args...)`, where `decltype(args)...` is not one of the type packs
    <code>Args<i><sub>0</sub></i>...</code> through
    <code>Args<i><sub>N</sub></i>...</code> (ignoring differences in
    rvalue-reference qualification).

7. Let `r` be an rvalue receiver of type `R`, and let `S` be the type of a
    sender. If `error_types_of_t<S, env_of_t<R>, Variant>` is well formed, it
    shall name the type <code>Variant&lt;E<i><sub>0</sub></i>,
    E<i><sub>1</sub></i>, ..., E<i><sub>N</sub></i>></code>, where the types
    <code>E<i><sub>0</sub></i></code> through <code>E<i><sub>N</sub></i></code>
    are the types the sender `S` passes as arguments to `execution::set_error`
    (besides the receiver object). Such a sender `S` shall not odr-use
    `execution::set_error(r, e)`, where `decltype(e)` is not one of the types
    <code>E<i><sub>0</sub></i></code> through <code>E<i><sub>N</sub></i></code>
    (ignoring differences in rvalue-reference qualification).

8. Let `r` be an rvalue receiver of type `R`, and let `S` be the type of a
    sender. If `sends_stopped<S, env_of_t<R>>` is well formed and
    `false`, such a sender `S` shall not odr-use `execution::set_stopped(r)`.

9. Let `S` be the type of a sender, let `E` be the type of an execution
    environment other than `execution::no_env` such that `sender<S, E>` is
    `true`. Let `Tuple`, `Variant1`, and `Variant2` be variadic alias templates
    or class templates such that following types are well-formed:

      * `value_types_of_t<S, no_env, Tuple, Variant1>`
      * `error_types_of_t<S, no_env, Variant2>`

      then the following shall also be `true`:

      * `value_types_of_t<S, E, Tuple, Variant1>` shall also be well-formed and shall
          name the same type as `value_types_of_t<S, no_env, Tuple, Variant1>`,
      * `error_types_of_t<S, E, Variant2>` shall also be well-formed and shall
          name the same type as `error_types_of_t<S, no_env, Variant2>`, and
      * `sends_stopped<S, E>` shall have the same
          value as `sends_stopped<S, no_env>`.
10. [<i>Note</i>: The types <code>Args<i><sub>i</sub></i>...</code> and <code>E<i><sub>i</sub></i>...</code> captured in `value_types` and `error_types` can appear in any order.
     For example, a sender that can yield, in case of an error, either `exception_ptr` or `error_code` can have `error_types` be either `Variant<exception_ptr, error_code>` or `Variant<error_code, exception_ptr>`. --<i>end note</i>]

#### `dependent_completion_signatures` <b>[exec.depsndtraits]</b> #### {#spec-exec.depsndtraitst}

<pre highlight="c++">
template &lt;class E>  // arguments are not associated entities ([lib.tmpl-heads])
  struct dependent_completion_signatures {};
</pre>

1. `dependent_completion_signatures` is a placeholder completion signatures
    descriptor that can be returned from `get_completion_signatures` to report
    that a type might be a sender within a particular execution environment, but
    it isn't a sender in an arbitrary execution environment.

2. When used as the return type of a customization of
    `get_completion_signatures`, the template argument `E` shall be the
    unqualified type of the second argument.

### `execution::connect` <b>[exec.connect]</b> ### {#spec-execution.senders.connect}

1. `execution::connect` is used to <i>connect</i> a sender with a receiver, producing an operation state object that represents the work that needs to be performed to satisfy the receiver contract of the receiver with values that are the result of the operations described by the sender.

2. The name `execution::connect` denotes a customization point object. For some subexpressions `s` and `r`, let `S` be `decltype((s))` and `R` be `decltype((r))`, and let `S'` and `R'` be the decayed types of `S` and `R`, respectively. If `R` does not satisfy `execution::receiver`, `execution::connect(s, r)` is ill-formed. Otherwise, the expression `execution::connect(s, r)` is expression-equivalent to:

    1. `tag_invoke(execution::connect, s, r)`, if the constraints below are satisfied. If the function selected by `tag_invoke` does not return an operation state for which `execution::start` starts work described by `s`, the behavior of calling `execution::connect(s, r)` is undefined.

        * <i>Constraints:</i>

            <pre highlight="c++">
            sender&lt;S, env_of_t&lt;R>> &amp;&amp;
            receiver_of&lt;R, completion_signatures_of_t&lt;S, env_of_t&lt;R>>> &amp;&amp;
            tag_invocable&lt;connect_t, S, R>
            </pre>

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `operation_state`.

    2. Otherwise, <code><i>connect-awaitable</i>(s, r)</code> if <code><i>is-awaitable</i>&lt;S, <i>connect-awaitable-promise</i>></code> is `true` and that expression is valid, where <code><i>connect-awaitable</i></code> is a coroutine equivalent to the following:

        <pre highlight="c++">
        <i>operation-state-task</i> <i>connect-awaitable</i>(S' s, R' r) requires <i>see-below</i> {
          exception_ptr ep;
          try {
            <i>set-value-expr</i>
          } catch(...) {
            ep = current_exception();
          }
          <i>set-error-expr</i>
        }
        </pre>

        where <code><i>connect-awaitable-promise</i></code> is the promise type of <code><i>connect-awaitable</i></code>, and where <code><i>connect-awaitable</i></code> suspends at the <i>initial suspends point</i> ([dcl.fct.def.coroutine]), and:

          1. <i>set-value-expr</i> first evaluates `co_await std::move(s)`, then suspends the coroutine and evaluates `execution::set_value(std::move(r))` if <code><i>await-result-type</i>&lt;S, <i>connect-awaitable-promise</i>></code> is <code><i>cv</i> void</code>; otherwise, it evaluates `auto&& res = co_await std::move(s)`, then suspends the coroutine and evaluates `execution::set_value(std::move(r), std::forward<decltype(res)>(res))`.

            If the call to `execution::set_value` exits with an exception, the coroutine is resumed and the exception is immediately propagated in the context of the coroutine.

            [<i>Note</i>: If the call to `execution::set_value` exits normally, then the <code><i>connect-awaitable</i></code> coroutine is never resumed. --<i>end note</i>]

          2. <i>set-error-expr</i> first suspends the coroutine and then executes `execution::set_error(std::move(r), std::move(ep))`.

            [<i>Note</i>: The <code><i>connect-awaitable</i></code> coroutine is never resumed after the call to `execution::set_error`. --<i>end note</i>]

          3. <code><i>operation-state-task</i></code> is a type that models `operation_state`. Its `execution::start` resumes the <code><i>connect-awaitable</i></code> coroutine, advancing it past the initial suspend point.

          4. Let `p` be an lvalue reference to the promise of the <code><i>connect-awaitable</i></code> coroutine, let `b` be a `const` lvalue reference to the receiver `r`. Then `tag_invoke(tag, p, as...)` is expression-equivalent to `tag(b, as...)` for any set of arguments `as...` and for any `tag` whose type satisfies <code><i>forwarding-receiver-query</i></code>.

          5. The expression `p.unhandled_stopped()` is expression-equivalent to `(execution::set_stopped(std::move(r)), noop_coroutine())`.

          6. For some expression `e`, the expression `p.await_transform(e)` is expression-equivalent to `tag_invoke(as_awaitable, e, p)` if that expression is well-formed; otherwise, it is expression-equivalent to `e`.

        Let `Res` be <code><i>await-result-type</i>&lt;S, <i>connect-awaitable-promise</i>></code>, and let `Vs...` be an empty parameter pack if `Res` is <code><i>cv</i> void</code>, or a pack containing the single type `Res` otherwise. The operand of the <i>requires-clause</i> of <code><i>connect-awaitable</i></code> is equivalent to `receiver_of<R, Sigs>` where `Sigs` names the type:

            <pre highlight="c++">
            completion_signatures&lt;
              set_value_t(Vs...),
              set_error_t(exception_ptr),
              set_stopped_t()>
            </pre>

    3. Otherwise, `execution::connect(s, r)` is ill-formed.

3. Standard sender types shall always expose an rvalue-qualified overload of a customization of `execution::connect`. Standard sender types shall only expose an lvalue-qualified overload of a customization of `execution::connect` if they are copyable.

### Sender queries <b>[exec.snd_queries]</b> ### {#spec-execution.senders.queries}

#### `execution::forwarding_sender_query` <b>[exec.snd_queries.forwarding_sender_query]</b> #### {#spec-execution.senders.queries.forwarding_sender_query}

1. `execution::forwarding_sender_query` is used to ask a customization point object whether it is a sender query that should be forwarded through sender adaptors.

2. The name `execution::forwarding_sender_query` denotes a customization point object. For some subexpression `t`, `execution::forwarding_sender_query(t)` is expression equivalent to:

    1. `tag_invoke(execution::forwarding_sender_query, t)` contextually converted to `bool`, if the `tag_invoke` expression is well formed.

        * <i>Mandates:</i> The `tag_invoke` expression is indeed contextually
            convertible to `bool`, that expression and the contextual conversion
            are not potentially-throwing and are core constant expressions if
            `t` is a core constant expression.

    2. Otherwise, `false`.

#### `execution::get_completion_scheduler` <b>[exec.snd_queries.get_completion_scheduler]</b> #### {#spec-execution.senders.queries.get_completion_scheduler}

1. `execution::get_completion_scheduler` is used to ask a sender object for the <i>completion scheduler</i> for one of its signals.

2. The name `execution::get_completion_scheduler` denotes a customization point object template. For some subexpression `s`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::get_completion_scheduler<CPO>(s)` is ill-formed for all template arguments `CPO`. If the template
    argument `CPO` in `execution::get_completion_scheduler<CPO>` is not one of `execution::set_value_t`, `execution::set_error_t`, or `execution::set_stopped_t`, `execution::get_completion_scheduler<CPO>` is ill-formed. Otherwise,
    `execution::get_completion_scheduler<CPO>(s)` is expression-equivalent to:

    1. `tag_invoke(execution::get_completion_scheduler<CPO>, as_const(s))` if this expression is well formed.

        * <i>Mandates:</i> The `tag_invoke` expression above is not potentially throwing and its type satisfies `execution::scheduler`.

    2. Otherwise, `execution::get_completion_scheduler<CPO>(s)` is ill-formed.

3. If, for some sender `s` and customization point object `CPO`, `execution::get_completion_scheduler<decltype(CPO)>(s)` is well-formed and results in a scheduler `sch`, and the sender `s` invokes `CPO(r, args...)`, for some receiver `r` which has been connected to
    `s`, with additional arguments `args...`, on an execution agent which does not belong to the associated execution context of `sch`, the behavior is undefined.

4. The expression `execution::forwarding_sender_query(get_completion_scheduler<CPO>)` shall be a prvalue core constant expression of type `bool` with value `true`. It shall not be potentially-throwing. `CPO` shall be one of `set_value_t`, `set_error_t` or `set_stopped_t`.

### Sender factories <b>[exec.factories]</b> ### {#spec-execution.senders.factories}

#### General <b>[exec.factories.general]</b> #### {#spec-execution.senders.factories.general}

1. Subclause [exec.factories] defines <i>sender factories</i>, which are utilities that return senders without accepting senders as arguments.

#### `execution::schedule` <b>[exec.schedule]</b> #### {#spec-execution.senders.schedule}

1. `execution::schedule` is used to obtain a sender associated with a scheduler, which can be used to describe work to be started on that scheduler's associated execution context.

2. The name `execution::schedule` denotes a customization point object. For some subexpression `s`, the expression `execution::schedule(s)` is expression-equivalent to:

    1. `tag_invoke(execution::schedule, s)`, if that expression is valid. If the function selected by `tag_invoke` does not return a sender whose `set_value` completion scheduler is equivalent to `s`, the behavior of calling `execution::schedule(s)` is undefined.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    2. Otherwise, `execution::schedule(s)` is ill-formed.

#### `execution::just`, `execution::just_error`, `execution::just_stopped` <b>[exec.just]</b> #### {#spec-execution.senders.just}

1. `execution::just` is used to create a sender that propagates a set of values to a connected receiver.
    `execution::just_error` is used to create a sender that propagates an error to a connected receiver.
    `execution::just_stopped` is used to create a sender that propagates a stopped signal to a connected receiver.

2. Let `just-sender` be the class template:

    <pre highlight=c++>
    template&lt;class CPO, class... Ts>
    struct <i>just-sender</i> { // exposition only
      using completion_signatures =
        execution::completion_signatures&lt;CPO(Ts...)>;

      [[no_unique_address]] tuple&lt;Ts...> vs_; // exposition only

      template&lt;class R>
      struct operation_state { // exposition only
        [[no_unique_address]] tuple&lt;Ts...> vs_; // exposition only
        R r_; // exposition only

        friend void tag_invoke(start_t, operation_state&amp; s) noexcept {
          apply([&amp;s](Ts&amp;... values_) {
            CPO{}(std::move(s.r_), std::move(values_)...);
          }, s.vs_);
        }
      };

      template&lt;receiver_of&lt;completion_signatures> R>
        requires (copy_constructible&ltTs> &amp;&amp;...)
      friend operation_state&lt;decay_t<R>> tag_invoke(connect_t, const <i>just-sender</i>&amp; s, R &amp;&amp; r) {
        return { s.vs_, std::forward&lt;R>(r) };
      }

      template&lt;receiver_of&lt;completion_signatures> R>
      friend operation_state&lt;decay_t<R>> tag_invoke(connect_t, <i>just-sender</i>&amp;&amp; s, R &amp;&amp; r) {
        return { std::move(s.vs_), std::forward&lt;R>(r) };
      }
    };
    </pre>

3. The name `execution::just` denotes a customization point object. For some subexpressions `vs...`, let `Vs...` be `decltype((vs))`. If any type `V` in `Vs` does not satisfy <code><i>movable-value</i></code>, `execution::just(vs...)` is ill-formed.
    Otherwise, `execution::just(vs...)` is expression-equivalent to <code><i>just-sender</i>&lt;set_value_t, decay_t&lt;Ts>...>(vs...)</i></code>.

4. The name `execution::just_error` denotes a customization point object. For some subexpression `err`, let `Err` be `decltype((err))`. If `Err` does not satisfy <code><i>movable-value</i></code>, `execution::just_error(err)` is ill-formed.
    Otherwise, `execution::just_error(err)` is expression-equivalent to <code><i>just-sender</i>&lt;set_error_t, decay_t&lt;Err>>(err)</i></code>.

5. Then name `execution::just_stopped` denotes a customization point object. `execution::just_stopped` is expression-equivalent to <code><i>just-sender</i>&lt;set_stopped_t>()</i></code>.

#### `execution::transfer_just` <b>[exec.transfer_just]</b> #### {#spec-execution.senders.transfer_just}

1. `execution::transfer_just` is used to create a sender that propagates a set of values to a connected receiver on an execution agent belonging to the associated execution context of a specified scheduler.

2. The name `execution::transfer_just` denotes a customization point object. For some subexpressions `s` and `vs...`, let `S` be `decltype((s))` and `Vs...` be `decltype((vs))`. If `S` does not satisfy `execution::scheduler`, or any type `V` in `Vs` does not
    satisfy <code><i>movable-value</i></code>, `execution::transfer_just(s, vs...)` is ill-formed. Otherwise, `execution::transfer_just(s, vs...)` is expression-equivalent to:

    1. `tag_invoke(execution::transfer_just, s, vs...)`, if that expression is
        valid. If the function selected by `tag_invoke` does not return a sender
        whose `set_value` completion scheduler is equivalent to `s` and sends
        values equivalent to `auto(vs)...` to a receiver connected to it, the
        behavior of calling `execution::transfer_just(s, vs...)` is undefined.

        * <i>Mandates:</i>  `execution::sender_of<R, no_env, decltype(auto(vs))...>`, where `R` is the type of the `tag_invoke` expression above.

    2. Otherwise, `execution::transfer(execution::just(vs...), s)`.

#### `execution::read` <b>[exec.read]</b> #### {#spec-execution.senders.read}

1. `execution::read` is used to create a sender that retrieves a value from the receiver's associated environment and sends it back to the receiver through the value channel.

2. `execution::read` is a customization point object of an unspecified class type equivalent to:

    <pre highlight=c++>
    template &lt;class Tag>
      struct <i>read-sender</i>; // exposition only

    struct <i>read-t</i> { // exposition only
      template &lt;class Tag>
        <i>read-sender</i>&lt;Tag> operator()(Tag) const noexcept { return {}; }
    };
    </pre>

3. <code><i>read-sender</i></code> is an exposition only class template equivalent to:

    <pre highlight=c++>
    template &lt;class Tag>
      struct <i>read-sender</i> { // exposition only
        template&lt;class R>
          struct <i>operation-state</i> { // exposition only
            R r_; // exposition only

            friend void tag_invoke(start_t, <i>operation-state</i>& s) noexcept {
              <i>TRY-SET-VALUE</i>(std::move(s.r_), auto(Tag{}(get_env(s.r_))));
            }
          };

        template&lt;receiver R>
        friend <i>operation-state</i>&lt;decay_t&lt;R>> tag_invoke(connect_t, <i>read-sender</i>, R && r) {
          return { std::forward&lt;R>(r) };
        }

        template&lt;class Env>
          friend auto tag_invoke(get_completion_signatures_t, <i>read-sender</i>, Env)
            -> dependent_completion_signatures&lt;Env>; <i>// not defined</i>

        template&lt;class Env>
            requires <i>callable</i>&lt;Tag, Env>
          friend auto tag_invoke(get_completion_signatures_t, <i>read-sender</i>, Env)
            -> completion_signatures&lt;
              set_value_t(<i>call-result-t</i>&lt;Tag, Env>), set_error_t(exception_ptr)>; <i>// not defined</i>

        template&lt;class Env>
            requires <i>nothrow-callable</i>&lt;Tag, Env>
          friend auto tag_invoke(get_completion_signatures_t, <i>read-sender</i>, Env)
            -> completion_signatures&lt;set_value_t(<i>call-result-t</i>&lt;Tag, Env>)>; <i>// not defined</i>
      };
    </pre>

    where <code><i>TRY-SET-VALUE</i>(r, e)</code>, for two subexpressions `r` and `e`,
    is equivalent to:

        <pre highlight="c++">
        try {
          execution::set_value(r, e);
        } catch(...) {
          execution::set_error(r, current_exception());
        }
        </pre>

        if `e` is potentially throwing; or `execution::set_value(r, e)` otherwise.

### Sender adaptors <b>[exec.adapt]</b> ### {#spec-execution.senders.adapt}

#### General <b>[exec.adapt.general]</b> #### {#spec-execution.senders.adapt.general}

1. Subclause [exec.adapt] defines <i>sender adaptors</i>, which are utilities that transform one or more senders into a sender with custom behaviors. When they accept a single sender argument, they can be chained to create sender chains.

2. The bitwise OR operator is overloaded for the purpose of creating sender chains. The adaptors also support function call syntax with equivalent semantics.

3. Unless otherwise specified, a sender adaptor is required to not begin executing any functions which would observe or modify any of the arguments of the adaptor before the returned sender is connected with a receiver using `execution::connect`, and
    `execution::start` is called on the resulting operation state. This requirement applies to any function that is selected by the implementation of the sender adaptor.

4. A type `T` is a <i>forwarding sender query</i> if it is the type of a customization point object that models <code>forwarding-sender-query</code>. Unless otherwise specified, all sender adaptors that accept a single `sender` argument return sender objects that propagate forwarding sender queries to that single sender argument. This requirement applies to any function that is selected by the implementation of the
    sender adaptor.

5. A type `T` is a <i>forwarding receiver query</i> if it is the type of a customization point object that models <code>forwarding-receiver-query</code>. Unless otherwise specified, whenever a sender adaptor constructs a receiver that it passes to another sender's connect, that receiver shall propagate forwarding receiver queries to a receiver accepted as an argument of `execution::connect`. This requirements
    applies to any sender returned from a function that is selected by the implementation of such sender adaptor.

6. For any sender type, receiver type, operation state type, execution environment type, or coroutine promise type that is part of the implementation of any sender adaptor in this subclause and that is a class template, the template arguments do not contribute to the associated entities ([basic.lookup.argdep]) of a function call where a specialization of the class template is an associated entity.

    [*Example:*

    <pre highlight="c++">
    namespace <i>sender-adaptors</i> { // exposition only
      template &lt;class Sch, class S> // arguments are not associated entities ([lib.tmpl-heads])
      class <i>on-sender</i> {
        // ...
      };

      struct on_t {
        template &lt;scheduler Sch, sender S>
        <i>on-sender</i>&lt;Sch, S> operator()(Sch&& sch, S&& s) const {
          // ...
        }
      };
    }
    inline constexpr <i>sender-adaptors</i>::on_t on{};
    </pre>

    -- <i>end example</i>]

7. If the specification of a sender adaptor requires that the implementation of the `get_completion_signatures` customization point adds the signature `set_error_t(exception_ptr)` as an additional signature, but a customization of that sender adaptor never
    calls the `exception_ptr` overload of `set_error`, that customization is allowed to omit the `set_error_t(exception_ptr)` additional signature from its implementation of the `get_completion_signatures` sender query.

#### Sender adaptor closure objects <b>[exec.adapt.objects]</b> #### {#spec-execution.senders.adaptor.objects}

1. A <i>pipeable sender adaptor closure object</i> is a function object that accepts one or more `sender` arguments and returns a `sender`. For a sender adaptor closure object `C` and an expression `S` such that `decltype((S))` models `sender`, the following
    expressions are equivalent and yield a `sender`:

    <pre highlight=c++>
    C(S)
    S | C
    </pre>

    Given an additional pipeable sender adaptor closure object `D`, the expression `C | D` produces another pipeable sender adaptor closure object `E`:

    `E` is a perfect forwarding call wrapper ([func.require]) with the following properties:

    - Its target object is an object `d` of type `decay_t<decltype((D))>` direct-non-list-initialized with `D`.

    - It has one bound argument entity, an object `c` of type `decay_t<decltype((C))>` direct-non-list-initialized with `C`.

    - Its call pattern is `d(c(arg))`, where `arg` is the argument used in a function call expression of `E`.

    The expression `C | D` is well-formed if and only if the initializations of the state entities of `E` are all well-formed.

2. An object `t` of type `T` is a pipeable sender adaptor closure object if `T` models `derived_from<sender_adaptor_closure<T>>`, `T` has no other base
    classes of type `sender_adaptor_closure<U>` for any other type `U`, and `T` does not model `sender`.

3. The template parameter `D` for `sender_adaptor_closure` may be an incomplete type. Before any expression of type <code><i>cv</i> D</code> appears as
    an operand to the `|` operator, `D` shall be complete and model `derived_from<sender_adaptor_closure<D>>`. The behavior of an expression involving an
    object of type <code><i>cv</i> D</code> as an operand to the `|` operator is undefined if overload resolution selects a program-defined `operator|`
    function.

4. A <i>pipeable sender adaptor object</i> is a customization point object that accepts a `sender` as its first argument and returns a `sender`.

5. If a pipeable sender adaptor object accepts only one argument, then it is a pipeable sender adaptor closure object.

6. If a pipeable sender adaptor object `adaptor` accepts more than one argument, then let `s` be an expression such that `decltype((s))` models `sender`,
    let `args...` be arguments such that `adaptor(s, args...)` is a well-formed expression as specified in the rest of this subclause
    ([exec.adapt.objects]), and let `BoundArgs` be a pack that denotes `decay_t<decltype((args))>...`. The expression `adaptor(args...)`
    produces a pipeable sender adaptor closure object `f` that is a perfect forwarding call wrapper with the following properties:

    - Its target object is a copy of `adaptor`.

    - Its bound argument entities `bound_args` consist of objects of types `BoundArgs...` direct-non-list-initialized with `std::forward<decltype((args))>(args)...`, respectively.

    - Its call pattern is `adaptor(r, bound_args...)`, where `r` is the argument used in a function call expression of `f`.

    The expression `adaptor(args...)` is well-formed if and only if the initializations of the bound argument entities of the result, as specified above,
     are all well-formed.

#### `execution::on` <b>[exec.on]</b> #### {#spec-execution.senders.adapt.on}

1. `execution::on` is used to adapt a sender into a sender that will start the input sender on an execution agent belonging to a specific execution context.

2. Let <code><i>replace-scheduler</i>(e, sch)</code> be an expression denoting an object `e'` such that `execution::get_scheduler(e)` returns a copy of `sch`, and `tag_invoke(tag, e', args...)` is expression-equivalent to `tag(e, args...)`
    for all arguments `args...` and for all `tag` whose type satisfies <code><i>forwarding-env-query</i></code> and is not `execution::get_scheduler_t`.

3. The name `execution::on` denotes a customization point object. For some subexpressions `sch` and `s`, let `Sch` be `decltype((sch))` and `S` be `decltype((s))`. If `Sch` does not satisfy `execution::scheduler`, or `S` does not satisfy `execution::sender`,
    `execution::on` is ill-formed. Otherwise, the expression `execution::on(sch, s)` is expression-equivalent to:

    1. `tag_invoke(execution::on, sch, s)`, if that expression is valid. If the function selected above does not return a sender which starts `s` on an execution agent of the associated execution context of `sch` when
        started, the behavior of calling `execution::on(sch, s)` is undefined.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    2. Otherwise, constructs a sender `s1`. When `s1` is connected with some receiver `out_r`, it:

        1. Constructs a receiver `r` such that:

            1. When `execution::set_value(r)` is called, it calls `execution::connect(s, r2)`, where `r2` is as specified below, which results in `op_state3`. It calls `execution::start(op_state3)`. If any of these throws an exception, it calls `execution::set_error` on `out_r`, passing `current_exception()` as the second argument.

            2. `execution::set_error(r, e)` is expression-equivalent to `execution::set_error(out_r, e)`.

            3. `execution::set_stopped(r)` is expression-equivalent to `execution::set_stopped(out_r)`.

            4. `execution::get_env(r)` is expression-equivalent to `execution::get_env(out_r)`.

        2. Calls `execution::schedule(sch)`, which results in `s2`. It then calls `execution::connect(s2, r)`, resulting in `op_state2`.

        3. `op_state2` is wrapped by a new operation state, `op_state1`, that is returned to the caller.

        4. `r2` is a receiver that wraps a reference to `out_r` and forwards all
            receiver completion-signals to it. In addition,
            `execution::get_env(r2)` returns <code><i>replace-scheduler</i>(e, sch)</code>.

        5. When `execution::start` is called on `op_state1`, it calls `execution::start` on `op_state2`.

        6. The lifetime of `op_state2`, once constructed, lasts until either `op_state3` is constructed or `op_state1` is destroyed, whichever comes first. The lifetime of `op_state3`, once constructed, lasts until `op_state1` is destroyed.

    3. Given subexpressions `s1` and `e`, where `s1` is a sender returned from `on` or a copy of such, let `S1` be `decltype((s1))`.
        Let `E'` be <code>decltype((<i>replace-scheduler</i>(e, sch)))</code>.
        Then the type of `tag_invoke(get_completion_signatures, s1, e)` shall be:

        <pre highlight="c++">
        make_completion_signatures&lt;
          copy_cvref_t&lt;S1, S>,
          E',
          make_completion_signatures&lt;
            schedule_result_t&lt;Sch>,
            E,
            completion_signatures&lt;set_error_t(exception_ptr)>,
            <i>no-value-completions</i>>>;
        </pre>

        where <code><i>no-value-completions</i>&lt;As...></code> names the type `completion_signatures<>`
        for any set of types `As...`.

#### `execution::transfer` <b>[exec.transfer]</b> #### {#spec-execution.senders.adapt.transfer}

1. `execution::transfer` is used to adapt a sender into a sender with a different associated `set_value` completion scheduler. [<i>Note</i>: it results in a transition between different execution contexts when executed. --<i>end note</i>]

2. The name `execution::transfer` denotes a customization point object. For some subexpressions `sch` and `s`, let `Sch` be `decltype((sch))` and `S` be `decltype((s))`. If `Sch` does not satisfy `execution::scheduler`, or `S` does not satisfy
    `execution::sender`, `execution::transfer` is ill-formed. Otherwise, the expression `execution::transfer(s, sch)` is expression-equivalent to:

    1. `tag_invoke(execution::transfer, get_completion_scheduler<set_value_t>(s), s, sch)`, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::transfer, s, sch)`, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    3. Otherwise, `schedule_from(sch, s)`.

    If the function selected above does not return a sender which is a result of
    a call to `execution::schedule_from(sch, s2)`, where `s2` is a sender which
    sends values equivalent to those sent by `s`, the behavior of calling
    `execution::transfer(s, sch)` is undefined.

3. Senders returned from `execution::transfer` shall not propagate the sender queries `get_completion_scheduler<CPO>` to an input sender. They will implement `get_completion_scheduler<CPO>`, where `CPO` is one of `set_value_t` and `set_stopped_t`; this query returns a scheduler equivalent to the `sch` argument from those queries. The `get_completion_scheduler<set_error_t>` is not implemented, as the scheduler cannot be guaranteed in case an error is thrown while trying to schedule work on the given scheduler object.

#### `execution::schedule_from` <b>[exec.schedule_from]</b> #### {#spec-execution.senders.adaptors.schedule_from}

1. `execution::schedule_from` is used to schedule work dependent on the completion of a sender onto a scheduler's associated execution context. [<i>Note</i>: `schedule_from` is not meant to be used in user code; it is used in the implementation of
    `transfer`. -<i>end note</i>]

3. The name `execution::schedule_from` denotes a customization point object. For some subexpressions `sch` and `s`, let `Sch` be `decltype((sch))` and `S` be `decltype((s))`. If `Sch` does not satisfy `execution::scheduler`, or `S` does not satisfy
    `execution::sender`, `execution::schedule_from` is ill-formed. Otherwise, the expression `execution::schedule_from(sch, s)` is expression-equivalent to:

    1. `tag_invoke(execution::schedule_from, sch, s)`, if that expression is valid. If the function selected by `tag_invoke` does not return a sender which completes on an execution agent belonging to the associated
        execution context of `sch` and sends signals equivalent to those sent by `s`, the behavior of calling `execution::schedule_from(sch, s)` is undefined.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    2. Otherwise, constructs a sender `s2`. When `s2` is connected with some receiver `out_r`, it:

        1. Constructs a receiver `r` such that when a receiver completion-signal <code><i>Signal</i>(r, args...)</code> is called, it decay-copies `args...` into `op_state` (see below) as `args'...` and constructs a receiver `r2` such that:

            1. When `execution::set_value(r2)` is called, it calls <code><i>Signal</i>(out_r, std::move(args')...)</code>.

            2. `execution::set_error(r2, e)` is expression-equivalent to `execution::set_error(out_r, e)`.

            3. `execution::set_stopped(r2)` is expression-equivalent to `execution::set_stopped(out_r)`.

            It then calls `execution::schedule(sch)`, resulting in a sender `s3`. It then calls `execution::connect(s3, r2)`, resulting in an operation state `op_state3`. It then calls `execution::start(op_state3)`. If any of these throws an exception,
            it catches it and calls `execution::set_error(out_r, current_exception())`. If any of these expressions would be ill-formed, then <code><i>Signal</i>(r, args...)</code> is ill-formed.

        2. Calls `execution::connect(s, r)` resulting in an operation state `op_state2`. If this expression would be ill-formed, `execution::connect(s2, out_r)` is ill-formed.

        3. Returns an operation state `op_state` that contains `op_state2`. When `execution::start(op_state)` is called, calls `execution::start(op_state2)`. The lifetime of `op_state3` ends when `op_state` is destroyed.

    3. Given subexpressions `s2` and `e`, where `s2` is a sender returned from `schedule_from` or a copy of such, let `S2` be `decltype((s2))` and let `E` be `decltype((e))`. Then the type of `tag_invoke(get_completion_signatures, s2, e)` shall be:

        <pre highlight="c++">
        make_completion_signatures&lt;
          copy_cvref_t&lt;S2, S>,
          E,
          make_completion_signatures&lt;
            schedule_result_t&lt;Sch>,
            E,
            completion_signatures&lt;set_error_t(exception_ptr)>,
            <i>no-value-completions</i>>>;
        </pre>

        where <code><i>no-value-completions</i>&lt;As...></code> names the type `completion_signatures<>`
        for any set of types `As...`.

4. Senders returned from `execution::schedule_from` shall not propagate the sender queries `get_completion_scheduler<CPO>` to an input sender. They will implement `get_completion_scheduler<CPO>`, where `CPO` is one of `set_value_t` and `set_stopped_t`; this query returns a scheduler equivalent to the `sch` argument from those queries. The `get_completion_scheduler<set_error_t>` is not implemented, as the scheduler cannot be guaranteed in case an error is thrown while trying to schedule work on the given scheduler object.

#### `execution::then` <b>[exec.then]</b> #### {#spec-execution.senders.adaptor.then}

1. `execution::then` is used to attach an invocable as a continuation for the successful completion of the input sender.

2. The name `execution::then` denotes a customization point object. For some
    subexpressions `s` and `f`, let `S` be `decltype((s))`, let `F` be the
    decayed type of `f`, and let `f'` be an xvalue refering to an object
    decay-copied from `f`. If `S` does not satisfy `execution::sender`, or `F`
    does not model <code><i>movable-value</i></code>, `execution::then` is
    ill-formed. Otherwise, the expression `execution::then(s, f)` is
    expression-equivalent to:

    1. `tag_invoke(execution::then, get_completion_scheduler<set_value_t>(s), s, f)`, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::then, s, f)`, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    3. Otherwise, constructs a sender `s2`. When `s2` is connected with some receiver `out_r`, it:

        1. Constructs a receiver `r` such that:

            1. When `execution::set_value(r, args...)` is called, let `v` be the
                expression `invoke(f', args...)`. If `decltype(v)` is `void`,
                calls `execution::set_value(out_r)`; otherwise, it calls
                `execution::set_value(out_r, v)`. If any of these throw an
                exception, it catches it and calls `execution::set_error(out_r,
                current_exception())`. If any of these expressions would be
                ill-formed, the expression `execution::set_value(r, args...)` is
                ill-formed.

            2. `execution::set_error(r, e)` is expression-equivalent to `execution::set_error(out_r, e)`.

            3. `execution::set_stopped(r)` is expression-equivalent to `execution::set_stopped(out_r)`.

        2. Returns an expression equivalent to `execution::connect(s, r)`.

        3. Let <code><i>compl-sig-t</i>&lt;Tag, Args...></code> name the type
            `Tag()` if `Args...` is a template paramter pack containing the
            single type `void`; otherwise, `Tag(Args...)`. Given
            subexpressions `s2` and `e` where `s2` is a sender returned from
            `then` or a copy of such, let `S2` be `decltype((s2))` and let
            `E` be `decltype((e))`. The type of
            `tag_invoke(get_completion_signatures, s2, e)` shall be equivalent
            to:

            <pre highlight="c++">
            make_completion_signatures&lt;
              copy_cvref_t&lt;S2, S>, E, <i>set-error-signature</i>,
                <i>set-value-completions</i>>;
            </pre>

            where <code><i>set-value-completions</i></code> is an alias for:

            <pre highlight="c++">
            template &lt;class... As>
              <i>set-value-completions</i> =
                completion_signatures&lt;<i>compl-sig-t</i>&lt;set_value_t, invoke_result_t&lt;F, As...>>>
            </pre>

            and <code><i>set-error-signature</i></code> is an alias for
            `completion_signatures<set_error_t(exception_ptr)>` if any of the types
            in the <code><i>type-list</i></code> named by
            <code>value_types_of_t&lt;copy_cvref_t&lt;S2, S>, E, <i>potentially-throwing</i>, <i>type-list</i>></code>
            are `true_type`; otherwise, `completion_signatures<>`, where
            <code><i>potentially-throwing</i></code> is the template alias:

            <pre highlight="c++">
            template &lt;class... As>
              using <i>potentially-throwing</i> =
                bool_constant&lt;!is_nothrow_invocable_v&lt;F, As...>>;
            </pre>

    If the function selected above does not return a sender that invokes `f` with the result of the `set_value` signal of `s`, passing the return value as the value to any connected receivers, and propagates the other completion-signals sent by `s`, the behavior of calling `execution::then(s, f)` is undefined.

#### `execution::upon_error` <b>[exec.upon_error]</b> #### {#spec-execution.senders.adaptor.upon_error}

1. `execution::upon_error` is used to attach an invocable as a continuation for the unsuccessful completion of the input sender.

2. The name `execution::upon_error` denotes a customization point object. For
    some subexpressions `s` and `f`, let `S` be `decltype((s))`, let `F` be the
    decayed type of `f`, and let `f'` be an xvalue refering to an object
    decay-copied from `f`. If `S` does not satisfy `execution::sender`, or `F`
    does not model <code><i>movable-value</i></code>, `execution::upon_error` is
    ill-formed. Otherwise, the expression `execution::upon_error(s, f)` is
    expression-equivalent to:

    1. `tag_invoke(execution::upon_error, get_completion_scheduler<set_error_t>(s), s, f)`, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::upon_error, s, f)`, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    3. Otherwise, constructs a sender `s2`. When `s2` is connected with some receiver `out_r`, it:

        1. Constructs a receiver `r` such that:

            1. `execution::set_value(r, args...)` is expression-equivalent to
                `execution::set_value(out_r, args...)`.

            2. When `execution::set_error(r, e)` is called, let `v` be the
                expression `invoke(f', e)`. If `decltype(v)` is `void`, calls
                `execution::set_value(out_r)`; otherwise, it calls
                `execution::set_value(out_r, v)`. If any of these throw an
                exception, it catches it and calls `execution::set_error(out_r,
                current_exception())`. If any of these expressions would be
                ill-formed, the expression `execution::set_error(r, e)` is
                ill-formed.

            3. `execution::set_stopped(r)` is expression-equivalent to
                `execution::set_stopped(out_r)`.

        2. Returns an expression equivalent to `execution::connect(s, r)`.

        3. Let <code><i>compl-sig-t</i>&lt;Tag, Args...></code> name the type
            `Tag()` if `Args...` is a template paramter pack containing the
            single type `void`; otherwise, `Tag(Args...)`. Given
            subexpressions `s2` and `e` where `s2` is a sender returned from
            `upon_error` or a copy of such, let `S2` be `decltype((s2))` and let
            `E` be `decltype((e))`. The type of
            `tag_invoke(get_completion_signatures, s2, e)` shall be equivalent
            to:

            <pre highlight="c++">
            make_completion_signatures&lt;
              copy_cvref_t&lt;S2, S>, E, <i>set-error-signature</i>,
                <i>default-set-value</i>, <i>set-error-completion</i>>;
            </pre>

            where <code><i>set-error-completion</i></code> is the template alias:

            <pre highlight="c++">
            template &lt;class E>
              <i>set-error-completion</i> =
                completion_signatures&lt;<i>compl-sig-t</i>&lt;set_value_t, invoke_result_t&lt;F, E>>>
            </pre>

            and <code><i>set-error-signature</i></code> is an alias for
            `completion_signatures<set_error_t(exception_ptr)>` if any of the types
            in the <code><i>type-list</i></code> named by
            <code>error_types_of_t&lt;copy_cvref_t&lt;S2, S>, E, <i>potentially-throwing</i>></code>
            are `true_type`; otherwise, `completion_signatures<>`, where
            <code><i>potentially-throwing</i></code> is the template alias:

            <pre highlight="c++">
            template &lt;class... Es>
              using <i>potentially-throwing</i> =
                <i>type-list</i>&lt;!bool_constant&lt;is_nothrow_invocable_v&lt;F, Es>>...>;
            </pre>

    If the function selected above does not return a sender which invokes `f` with the result of the `set_error` signal of `s`, passing the return value as the value to any connected receivers, and propagates the other completion-signals sent by `s`, the behavior of calling `execution::upon_error(s, f)` is undefined.

#### `execution::upon_stopped` <b>[exec.upon_stopped]</b> #### {#spec-execution.senders.adaptor.upon_stopped}

1. `execution::upon_stopped` is used to attach an invocable as a continuation for the completion of the input sender using the "stopped" channel.

2. The name `execution::upon_stopped` denotes a customization point object. For
    some subexpressions `s` and `f`, let `S` be `decltype((s))`, let `F` be the
    decayed type of `f`, and let `f'` be an xvalue refering to an object
    decay-copied from `f`. If `S` does not satisfy `execution::sender`, or `F`
    does not model both <code><i>movable-value</i></code> and `invocable`,
    `execution::upon_stopped` is ill-formed. Otherwise, the expression
    `execution::upon_stopped(s, f)` is expression-equivalent to:

    1. `tag_invoke(execution::upon_stopped, get_completion_scheduler<set_stopped_t>(s), s, f)`, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::upon_stopped, s, f)`, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    3. Otherwise, constructs a sender `s2`. When `s2` is connected with some receiver `out_r`, it:

        1. Constructs a receiver `r` such that:

            2. `execution::set_value(r, args...)` is expression-equivalent to `execution::set_value(out_r, args...)`.

            2. `execution::set_error(r, e)` is expression-equivalent to `execution::set_error(out_r, e)`.

            1. When `execution::set_stopped(r)` is called, let `v` be the
                expression `invoke(f')`. If `v` has type `void`, calls
                `execution::set_value(out_r)`; otherwise, calls
                `execution::set_value(out_r, v)`. If any of these throw an
                exception, it catches it and calls `execution::set_error(out_r,
                current_exception())`. If any of these expressions would be
                ill-formed, the expression `execution::set_stopped(r)` is
                ill-formed.

        2. Returns an expression equivalent to `execution::connect(s, r)`.

        3. Let <code><i>compl-sig-t</i>&lt;Tag, Args...></code> name the type
            `Tag()` if `Args...` is a template paramter pack containing the
            single type `void`; otherwise, `Tag(Args...)`. Given
            subexpressions `s2` and `e` where `s2` is a sender returned from
            `upon_stopped` or a copy of such, let `S2` be `decltype((s2))` and let
            `E` be `decltype((e))`. The type of
            `tag_invoke(get_completion_signatures, s2, e)` shall be equivalent
            to:

            <pre highlight="c++">
            make_completion_signatures&lt;
              copy_cvref_t&lt;S2, S>, E, <i>set-error-signature</i>,
                <i>default-set-value</i>, <i>default-set-error</i>, <i>set-stopped-completions</i>>;
            </pre>

            where <code><i>set-stopped-completions</i></code> names the type
            <code>completion_signatures&lt;<i>compl-sig-t</i>&lt;set_value_t,
            invoke_result_t&lt;F>></code>, and
            <code><i>set-error-signature</i></code> names the type
            `completion_signatures<set_error_t(exception_ptr)>` if
            `is_nothrow_invocable_v<F>` is `true`, or `completion_signatures<>`
            otherwise.
            </pre>

    If the function selected above does not return a sender which invokes `f` when `s` completes by calling `set_stopped`, passing the return value as the value to any connected receivers, and propagates the other completion-signals sent by `s`, the behavior of calling `execution::upon_stopped(s, f)` is undefined.

#### `execution::let_value`, `execution::let_error`, `execution::let_stopped`,  <b>[exec.let]</b> #### {#spec-execution.senders.adapt.let}

1. `execution::let_value` is used to insert continuations creating more work dependent on the results of their input senders into a sender chain.
    `execution::let_error` is used to insert continuations creating more work dependent on the error of its input senders into a sender chain.
    `execution::let_stopped` is used to insert continuations creating more work dependent on the stopped signal of its input senders into a sender chain.

2. The names `execution::let_value`, `execution::let_error`, and `execution::let_stopped` denote a customization point object.
    Let the expression <code><i>let-cpo</i></code> be one of `execution::let_value`, `execution::let_error`, or `execution::let_stopped`.
    For some subexpressions `s` and `f`, let `S` be `decltype((s))`, let `F` be the decayed type of `f`, and let `f'` be an xvalue that refers to an object decay-copied from `f`.
    If `S` does not satisfy `execution::sender`, the expression <code><i>let-cpo</i>(s, f)</code> is ill-formed.
    If `F` does not satisfy `invocable`, the expression `execution::let_stopped(s, f)` is ill-formed.
    Otherwise, the expression
    <code><i>let-cpo</i>(s, f)</code> is expression-equivalent to:

    1. <code>tag_invoke(<i>let-cpo</i>, get_completion_scheduler&lt;set_value_t>(s), s, f)</code>, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    2. Otherwise, <code>tag_invoke(<i>let-cpo</i>, s, f)</code>, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    3. Otherwise, given a receiver `out_r` and an lvalue `out_r'` refering to an object decay-copied from `out_r`.

        1. For `execution::let_value`, let `set-cpo` be `execution::set_value`.
            For `execution::let_error`, let `set-cpo` be `execution::set_error`.
            For `execution::let_stopped`, let `set-cpo` be `execution::set_stopped`.
            Let <code><i>signal</i></code> be one of `execution::set_value`, `execution::set_error`, or `execution::set_stopped`.

        2. Let `r` be an rvalue of a receiver type `R` such that:

            1. When <code><i>set-cpo</i>(r, args...)</code> is called, the receiver `r` decay-copies `args...` into `op_state2` as `args'...`, then calls `invoke(f', args'...)`, resulting in a sender `s3`.
                It then calls `execution::connect(s3, std::move(out_r'))`, resulting in an operation state `op_state3`.
                `op_state3` is saved as a part of `op_state2`.
                It then calls `execution::start(op_state3)`.
                If any of these throws an exception, it catches it and calls `execution::set_error(std::move(out_r'), current_exception())`.
                If any of these expressions would be ill-formed, <code><i>set-cpo</i>(r, args...)</code> is ill-formed.

            2. <code><i>signal</i>(r, args...)</code> is expression-equivalent to <code><i>signal</i>(std::move(out_r'), args...)</code>, when <code><i>signal</i></code> is different from <code><i>set-cpo</i></code>.

        3. <code><i>let-cpo</i>(s, f)</code>  returns a sender `s2` such that:

            1. If the expression `execution::connect(s, r)` is ill-formed, `execution::connect(s2, out_r)` is ill-formed.

            2. Otherwise, let `op_state2` be the result of `execution::connect(s, r)`. `execution::connect(s2, out_r)` returns an operation state `op_state` that stores `op_state2`. `execution::start(op_state)` is expression-equivalent to `execution::start(op_state2)`.

        4. Given subexpressions `s2` and `e`, where `s2` is a sender returned
            from <code><i>let-cpo</i>(s, f)</code> or a copy of such, let `S2` be
            `decltype((s2))`, let `E` be `decltype((e))`, and let `S'` be
            `copy_cvref_t<S2, S>`. Then the type of
            `tag_invoke(get_completion_signatures, s2, e)` is specified as
            follows:

            1. If `sender<S', E>` is `false`, the type of
                `tag_invoke(get_completion_signatures, s2, e)` shall be equivalent
                to `dependent_completion_signatures<E>`.

            2. Otherwise, let `Sigs...` be the set of template arguments of the
                `completion_signatures` specialization named by `completion_signatures_of_t<S', E>`,
                let `Sigs2...` be the set of function types in `Sigs...` whose return type
                is <code><i>set-cpo</i></code>, and let `Rest...` be the set of function types
                in `Sigs...` but not `Sigs2...`.

            3. For each <code>Sig2<i><sub>i</sub></i></code> in `Sigs2...`, let
                <code>Vs<i><sub>i</sub></i>...</code> be the set of function
                arguments in <code>Sig2<i><sub>i</sub></i></code> and let
                <code>S3<i><sub>i</sub></i></code> be <code>invoke_result_t&lt;F,
                decay_t&lt;Vs<i><sub>i</sub></i>>&amp;...></code>. If
                <code>S3<i><sub>i</sub></i></code> is ill-formed, or if
                <code>sender&lt;S3<i><sub>i</sub></i>, E></code> is not satisfied,
                then the type of `tag_invoke(get_completion_signatures, s2, e)`
                shall be equivalent to `dependent_completion_signatures<E>`.

            4. Otherwise, let <code>Sigs3<i><sub>i</sub></i>...</code> be the
                set of template arguments of the `completion_signatures`
                specialization named by
                <code>completion_signatures_of_t&lt;S3<i><sub>i</sub></i>,
                E></code>. Then the type of `tag_invoke(get_completion_signatures,
                s2, e)` shall be equivalent to
                <code>completion_signatures&lt;Sigs3<i><sub>0</sub></i>...,
                Sigs3<i><sub>1</sub></i>..., ... Sigs3<i><sub>n-1</sub></i>...,
                Rest..., set_error_t(exception_ptr)></code>, where
                <code><i>n</i></code> is `sizeof...(Sigs2)`.

    If <code><i>let-cpo</i>(s, f)</code> does not return a sender that invokes `f` when <code><i>set-cpo</i></code> is called, and makes its completion dependent on the completion of a sender returned by `f`, and propagates the other completion-signals sent by `s`, the behavior of calling <code><i>let-cpo</i>(s, f)</code> is undefined.

#### `execution::bulk` <b>[exec.bulk]</b> #### {#spec-execution.senders.adapt.bulk}

1. `execution::bulk` is used to run a task repeatedly for every index in an index space.

2. The name `execution::bulk` denotes a customization point object. For some
    subexpressions `s`, `shape`, and `f`, let `S` be `decltype((s))`, `Shape` be
    `decltype((shape))`, and `F` be `decltype((f))`. If `S` does not satisfy
    `execution::sender` or `Shape` does not satisfy `integral`,
    `execution::bulk` is ill-formed. Otherwise, the expression
    `execution::bulk(s, shape, f)` is expression-equivalent to:

    1. `tag_invoke(execution::bulk, get_completion_scheduler<set_value_t>(s), s, shape, f)`, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::bulk, s, shape, f)`, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    3. Otherwise, constructs a sender `s2`. When `s2` is connected with some receiver `out_r`, it:

        1. Constructs a receiver `r`:

            1. When `execution::set_value(r, args...)` is called, calls `f(i, args...)` for each `i` of type `Shape` from `0` to `shape`, then calls `execution::set_value(out_r, args...)`. If any of these throws an exception, it catches it and calls
                `execution::set_error(out_r, current_exception())`.

            2. When `execution::set_error(r, e)` is called, calls `execution::set_error(out_r, e)`.

            3. When `execution::set_stopped(r)` is called, calls `execution::set_stopped(out_r, e)`.

        2. Calls `execution::connect(s, r)`, which results in an operation state `op_state2`.

        3. Returns an operation state `op_state` that contains `op_state2`. When `execution::start(op_state)` is called, calls `execution::start(op_state2)`.

        4. Given subexpressions `s2` and `e` where `s2` is a sender returned
            from `bulk` or a copy of such, let `S2` be `decltype((s2))`, let
            `E` be `decltype((e))`, let `S'` be `copy_cvref_t<S2, S>` and let
            <code><i>nothrow-callable</i></code> be the alias template:

              <pre highlight="c++">
              template &lt;class... As>
                using <i>nothrow-callable</i> =
                  bool_constant&lt;is_nothrow_invocable_v&lt;decay_t&lt;F>&, As...>>;
              </pre>

            1. If any of the types in the <code><i>type-list</i></code> named by
                <code>value_types_of_t&lt;S', E, <i>nothrow-callable</i>,
                <i>type-list</i>></code> are `false_type`, then the type of
                `tag_invoke(get_completion_signatures, s2, e)` shall be
                equivalent to:

                <pre highlight="c++">
                make_completion_signatures&lt;
                  S', E, completion_signatures&lt;set_error_t(exception_ptr)>>
                </pre>

            2. Otherwise, the type of `tag_invoke(get_completion_signatures, s2,
                e)` shall be equivalent to `completion_signatures_of_t<S', E>`.

    4. If the function selected above does not return a sender which invokes
        `f(i, args...)` for each `i` of type `Shape` from `0` to `shape` when
        the input sender sends values `args...`, or does not propagate the
        values of the signals sent by the input sender to a connected receiver,
        the behavior of calling `execution::bulk(s, shape, f)` is undefined.

#### `execution::split` <b>[exec.split]</b> #### {#spec-execution.senders.adapt.split}

1. `execution::split` is used to adapt an arbitrary sender into a sender that can be connected multiple times.

2. Let <code><i>split-env</i></code> be the type of an execution environment such that, given an instance `e`, the expression `get_stop_token(e)` is well formed and has type `stop_token`.

3. The name `execution::split` denotes a customization point object. For some
    subexpression `s`, let `S` be `decltype((s))`. If
    <code>execution::sender&lt;S, <i>split-env</i>></code> is `false`,
    `execution::split` is ill-formed. Otherwise, the expression
    `execution::split(s)` is expression-equivalent to:

    1. `tag_invoke(execution::split, get_completion_scheduler<set_value_t>(s), s)`,
        if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::split, s)`, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    3. Otherwise, constructs a sender `s2`, which:

        1. Creates an object `sh_state` that contains a `stop_source`, a list of
            pointers to operation states awaiting the completion of `s`, and that
            also reserves space for storing:

            * the operation state that results from connecting `s` with `r` described below, and
            * the sets of values and errors with which `s` may complete, with
                the addition of `exception_ptr`.

        2. Constructs a receiver `r` such that:

            1. When `execution::set_value(r, args...)` is called, decay-copies
                the expressions `args...` into `sh_state`. It then notifies all
                the operation states in `sh_state`'s list of operation states
                that the results are ready. If any exceptions are thrown, the
                exception is caught and `execution::set_error(r,
                current_exception())` is called instead.

            2. When `execution::set_error(r, e)` is called, decay-copies `e`
                into `sh_state`. It then notifies the operation states in
                `sh_state`'s list of operation states that the results are ready.

            3. When `execution::set_stopped(r)` is called, it then notifies the
                operation states in `sh_state`'s list of operation states that
                the results are ready.

            4. `get_env(r)` is an expression <code><i>e</i></code> of type
                <code><i>split-env</i></code> such that
                <code>execution::get_stop_token(<i>e</i>)</code> is well-formed
                and returns the results of calling `get_token()` on `sh_state`'s
                stop source.

        3. Calls `execution::connect(s, r)`, resulting in an operation state
            `op_state2`. `op_state2` is saved in `sh_state`.

        4. When `s2` is connected with a receiver `out_r` of type `OutR`, it
            returns an operation state object `op_state` that contains:

              * An object `out_r'` of type `OutR` decay-copied from `out_r`,
              * A reference to `sh_state`,
              * A stop callback of type
                <code>optional&lt;stop_token_of_t&lt;env_of_t&lt;OutR>>::callback_type&lt;<i>stop-callback-fn</i>>></code>,
                where <code><i>stop-callback-fn</i></code> is an implementation
                defined class type equivalent to the following:

                <pre highlight="c++">
                struct <i>stop-callback-fn</i> {
                  stop_source& stop_src_;
                  void operator()() noexcept {
                    stop_src_.request_stop();
                  }
                };
                </pre>

        5. When `execution::start(op_state)` is called:

            * If `r`'s receiver contract has already been satisfied, then let
                <code><i>Signal</i></code> be whichever receiver completion-signal
                was used to complete r's receiver contract ([exec.recv]). Calls
                <code><i>Signal</i>(out_r', args2...)</code>, where `args2...` is a
                pack of const lvalues referencing the subobjects of `sh_state` that
                have been saved by the original call to <code><i>Signal</i>(r,
                args...)</code> and returns.

            * Otherwise, it emplace constructs the stop callback optional with
                the arguments `execution::get_stop_token(get_env(out_r'))` and
                <code><i>stop-callback-fn</i>{<i>stop-src</i>}</code>, where
                <code><i>stop-src</i></code> refers to the stop source of
                `sh_state`.

            * Otherwise, it adds a pointer to `op_state` to the list of
                operation states in `sh_state`. If `op_state` is the first such
                state added to the list:

                  * If <code><i>stop-src</i>.stop_requested()</code> is `true`,
                      all of the operation states in `sh_state`'s list of operation
                      states are notified as if `execution::set_stopped(r)` had
                      been called.

                  * Otherwise, `execution::start(op_state2)` is called.

        6. When `r` completes it will notify `op_state` that the result are
            ready. Let <code><i>Signal</i></code> be whichever receiver
            completion-signal was used to complete `r`'s receiver contract
            ([exec.recv]). `op_state`'s stop callback optional is reset. Then
            <code><i>Signal</i>(std::move(out_r'), args2...)</code> is called,
            where `args2...` is a pack of const lvalues referencing the subobjects of
            `sh_state` that have been saved by the original call to
            <code><i>Signal</i>(r, args...)</code>.

        7. Ownership of `sh_state` is shared by `s2` and by every `op_state`
            that results from connecting `s2` to a receiver.

        8. Given subexpressions `s2` and `e` where `s2` is a sender returned
            from `split` or a copy of such, let `S2` be `decltype((s2))`
            and let `E` be `decltype((e))`. The type of
            `tag_invoke(get_completion_signatures, s2, e)` shall be equivalent
            to:

            <pre highlight="c++">
            make_completion_signatures&lt;
              copy_cvref_t&lt;S2, S>, E, completion_signatures&lt;set_error_t(exception_ptr)>,
                <i>value-signatures</i>, <i>error-signatures</i>>;
            </pre>

            where <code><i>value-signatures</i></code>
            is the alias template:

            <pre highlight="c++">
            template &lt;class... Ts>
              using <i>value-signatures</i> =
                completion_signatures&lt;set_value_t(const decay_t&lt;Ts>&amp;...)>;
            </pre>

            and <code><i>error-signatures</i></code> is the alias template:

            <pre highlight="c++">
            template &lt;class E>
              using <i>error-signatures</i> =
                completion_signatures&lt;set_error_t(const decay_t&lt;E>&amp;)>;
            </pre>

        9. Does not expose the sender queries get_completion_scheduler<CPO>.

    4. If the function selected above does not return a sender which sends
        references to values sent by `s`, propagating the other channels, the
        behavior of calling `execution::split(s)` is undefined.

#### `execution::when_all` <b>[exec.when_all]</b> #### {#spec-execution.senders.adaptor.when_all}

1. `execution::when_all` is used to join multiple sender chains and create a sender whose execution is dependent on all of the input senders that only send a single set of values. `execution::when_all_with_variant`
    is used to join multiple sender chains and create a sender whose execution is dependent on all of the input senders, each of which may have one or more sets of sent values.

2. The name `execution::when_all` denotes a customization point object. For some subexpressions <code>s<i><sub>i</sub></i>...</code>, let <code>S<i><sub>i</sub></i>...</code> be <code>decltype((s<i><sub>i</sub></i>))...</code>. The expression <code>execution::when_all(s<i><sub>i</sub></i>...)</code> is ill-formed if any of the following is true:

    * If the number of subexpressions <code>s<i><sub>i</sub></i>...</code> is 0, or
    * If any type <code>S<i><sub>i</sub></i></code> does not satisfy `execution::sender`.

    Otherwise, the expression <code>execution::when_all(s<i><sub>i</sub></i>...)</code> is expression-equivalent to:

    1. <code>tag_invoke(execution::when_all, s<i><sub>i</sub></i>...)</code>, if
        that expression is valid. If the function selected by `tag_invoke` does
        not return a sender that sends a concatenation of values sent by
        <code>s<i><sub>i</sub></i>...</code> when they all complete with
        `set_value`, the behavior of calling
        <code>execution::when_all(s<i><sub>i</sub></i>...)</code> is undefined.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    2. Otherwise, constructs a sender `w` of type `W`. When `w` is connected
        with some receiver `out_r` of type `OutR`, it returns an operation state
        `op_state` specified as below:

        1. For each sender <code>s<i><sub>i</sub></i></code>, constructs a receiver <code>r<i><sub>i</sub></i></code> such that:

            1. If <code>execution::set_value(r<i><sub>i</sub></i>, t<i><sub>i</sub></i>...)</code> is called for every <code>r<i><sub>i</sub></i></code>, `op_state`'s associated stop callback optional is reset and <code>execution::set_value(out_r, t<i><sub>0</sub></i>..., t<i><sub>1</sub></i>..., ..., t<i><sub>n-1</sub></i>...)</code> is called, where `n` the number of subexpressions in <code>s<i><sub>i</sub></i>...</code>.

            2. Otherwise, `execution::set_error` or `execution::set_stopped` was called for at least one receiver <code>r<i><sub>i</sub></i></code>. If the first such to complete did so with the call <code>execution::set_error(r<i><sub>i</sub></i>, e)</code>, `request_stop` is called on `op_state`'s associated stop source. When all child operations have completed, `op_state`'s associated stop callback optional is reset and `execution::set_error(out_r, e)` is called.

            3. Otherwise, `request_stop` is called on `op_state`'s associated stop source. When all child operations have completed, `op_state`'s associated stop callback optional is reset and `execution::set_stopped(out_r)` is called.

            4. For each receiver <code>r<i><sub>i</sub></i></code>, <code>get_env(r<i><sub>i</sub></i>)</code> is an expression <code><i>e</i></code> such that <code>execution::get_stop_token(<i>e</i>)</code> is well-formed and returns the results of calling `get_token()` on `op_state`'s associated stop source, and for which <code>tag_invoke(tag, <i>e</i>, args...)</code> is expression-equivalent to `tag(get_env(out_r), args...)` for all arguments `args...` and all `tag` whose type satisfies <code><i>forwarding-env-query</i></code> and is not `get_stop_token_t`.

        2. For each sender <code>s<i><sub>i</sub></i></code>, calls <code>execution::connect(s<i><sub>i</sub></i>, r<i><sub>i</sub></i>)</code>, resulting in operation states <code>child_op<i><sub>i</sub></i></code>.

        3. Returns an operation state `op_state` that contains:

            * Each operation state <code>child_op<i><sub>i</sub></i></code>,
            * A stop source of type `in_place_stop_source`,
            * A stop callback of type <code>optional&lt;stop_token_of_t&lt;env_of_t&lt;OutR>>::callback_type&lt;<i>stop-callback-fn</i>>></code>, where <code><i>stop-callback-fn</i></code> is an implementation defined class type equivalent to the following:

                <pre highlight="c++">
                struct <i>stop-callback-fn</i> {
                  in_place_stop_source& stop_src_;
                  void operator()() noexcept {
                    stop_src_.request_stop();
                  }
                };
                </pre>

        4. When `execution::start(op_state)` is called it:

            * Emplace constructs the stop callback optional with the arguments `execution::get_stop_token(get_env(out_r))` and <code><i>stop-callback-fn</i>{<i>stop-src</i>}</code>, where <code><i>stop-src</i></code> refers to the stop source of `op_state`.

            * Then, it checks to see if <code><i>stop-src</i>.stop_requested()</code> is true. If so, it calls `execution::set_stopped(out_r)`.

            * Otherwise, calls <code>execution::start(child_op<i><sub>i</sub></i>)</code> for each <code>child_op<i><sub>i</sub></i></code>.

        5. Given subexpressions `s2` and `e` where `s2` is a sender returned
            from `when_all` or a copy of such, let `S2` be `decltype((s2))`, let
            `E` be `decltype((e))`, and let `Ss...` be the decayed types of the
            arguments to the `when_all` expression that created `s2`. If the
            decayed type of `e` is `no_env`, let `WE` be `no_env`; otherwise,
            let `WE` be a type such that `stop_token_of_t<WE>` is
            `in_place_stop_token` and `tag_invoke_result_t<Tag, WE, As...>`
            names the type, if any, of <code><i>call-result-t</i>&lt;Tag, E,
            As...></code> for all types `As...` and all types `Tag` besides
            `get_stop_token_t`. The type of
            `tag_invoke(get_completion_signatures, s2, e)` shall be as follows:

            1. For each type <code>S<i><sub>i</sub></i></code> in `Ss...`, let
                <code>S'<i><sub>i</sub></i></code> name the type
                <code>copy_cvref_t&lt;S2, S<i><sub>i</sub></i>></code>. If for
                any type <code>S'<i><sub>i</sub></i></code>, the type
                <code>completion_signatures_of_t&lt;S'<i><sub>i</sub></i>,
                WE></code> names a type other than an instantiation of
                `completion_signatures`, the type of
                `tag_invoke(get_completion_signatures, s2, e)` shall be
                `dependent_completion_signatures<E>`.

            2. Otherwise, for each type <code>S'<i><sub>i</sub></i></code>, let
                <code>Sigs<i><sub>i</sub></i>...</code> be the set of template
                arguments in the instantiation of `completion_signatures` named
                by <code>completion_signatures_of_t&lt;S'<i><sub>i</sub></i>,
                WE></code>, and let <code>C<i><sub>i</sub></i></code> be the
                count of function types in
                <code>Sigs<i><sub>i</sub></i>...</code> for which the return
                type is `set_value_t`. If any
                <code>C<i><sub>i</sub></i></code> is two or greater, then the
                type of `tag_invoke(get_completion_signatures, s2, e)` shall be
                `dependent_completion_signatures<E>`.

            3. Otherwise, let <code>Sigs2<i><sub>i</sub></i>...</code> be the set of
                function types in <code>Sigs<i><sub>i</sub></i>...</code> whose
                return types are <i>not</i> `set_value_t`, and let `Ws...` be
                the unique set of types in <code>[Sigs2<i><sub>0</sub></i>...,
                Sigs2<i><sub>1</sub></i>..., ... Sigs2<i><sub>n-1</sub></i>...,
                set_stopped_t()]</code>, where
                <code><i>n</i></code> is `sizeof...(Ss)`. If any
                <code>C<i><sub>i</sub></i></code> is `0`, then the type of
                `tag_invoke(get_completion_signatures, s2, e)` shall be
                `completion_signatures<Ws...>`.

            4. Otherwise, let <code>V<i><sub>i</sub></i>...</code> be the
                function argument types of the single type in
                <code>Sigs<i><sub>i</sub></i>...</code> for which the return
                type is `set_value_t`. Then the type of
                `tag_invoke(get_completion_signatures, s2, e)` shall be
                <code>completion_signatures&lt;Ws...,
                set_value_t(decay_t&lt;V<i><sub>0</sub></i>>&amp;&amp;...,
                decay_t&lt;V<i><sub>1</sub></i>>&amp;&amp;..., ...
                decay_t&lt;V<i><sub>n-1</sub></i>>&amp;&amp;...)></code>.

3. The name `execution::when_all_with_variant` denotes a customization point object. For some subexpressions `s...`, let `S` be `decltype((s))`. If any type <code>S<i><sub>i</sub></i></code> in `S...` does not satisfy `execution::sender`,
    `execution::when_all_with_variant` is ill-formed. Otherwise, the expression `execution::when_all_with_variant(s...)` is expression-equivalent to:

    1. `tag_invoke(execution::when_all_with_variant, s...)`, if that expression
        is valid. If the function selected by `tag_invoke` does not return a
        sender that, when connected with a receiver of type `R`, sends the types
        <code><i>into-variant-type</i>&lt;S, env_of_t&lt;R>>...</code> when they
        all complete with `set_value`, the behavior of calling
        <code>execution::when_all(s<i><sub>i</sub></i>...)</code> is undefined.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    2. Otherwise, `execution::when_all(execution::into_variant(s)...)`.

4. Senders returned from adaptors defined in this subclause shall not expose the sender queries `get_completion_scheduler<CPO>`.

#### `execution::transfer_when_all` <b>[exec.transfer_when_all]</b> #### {#spec-execution.senders.adaptor.transfer_when_all}

1. `execution::transfer_when_all` is used to join multiple sender chains and
    create a sender whose execution is dependent on all of the input senders
    that only send a single set of values each, while also making sure that they
    complete on the specified scheduler.
    `execution::transfer_when_all_with_variant` is used to join multiple sender
    chains and create a sender whose execution is dependent on all of the input
    senders, which may have one or more sets of sent values. [<i>Note:</i> this
    can allow for better customization of the adaptors. --<i>end note</i>]

2. The name `execution::transfer_when_all` denotes a customization point object. For some subexpressions `sch` and `s...`, let `Sch` be `decltype(sch)` and `S` be `decltype((s))`. If `Sch` does not satisfy `scheduler`, or any type
    <code>S<i><sub>i</sub></i></code> in `S...` does not satisfy `execution::sender`,
    `execution::transfer_when_all` is ill-formed. Otherwise, the expression `execution::transfer_when_all(sch, s...)` is expression-equivalent to:

    1. `tag_invoke(execution::transfer_when_all, sch, s...)`, if that expression
        is valid. If the function selected by `tag_invoke` does not return a
        sender that sends a concatenation of values sent by `s...` when they all
        complete with `set_value`, or does not send its completion signals,
        other than ones resulting from a scheduling error, on an execution agent
        belonging to the associated execution context of `sch`, the behavior of
        calling `execution::transfer_when_all(sch, s...)` is undefined.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    2. Otherwise, `execution::transfer(execution::when_all(s...), sch)`.

3. The name `execution::transfer_when_all_with_variant` denotes a customization
    point object. For some subexpressions `sch` and `s...`, let `Sch` be
    `decltype((sch))` and let `S` be `decltype((s))`. If any type
    <code>S<i><sub>i</sub></i></code> in `S...` does not satisfy
    `execution::sender`, `execution::transfer_when_all_with_variant` is
    ill-formed. Otherwise, the expression
    `execution::transfer_when_all_with_variant(sch, s...)` is expression-equivalent
    to:

    1. `tag_invoke(execution::transfer_when_all_with_variant, s...)`, if that
        expression is valid. If the function selected by `tag_invoke` does not
        return a sender that, when connected with a receiver of type `R`, sends
        the types <code><i>into-variant-type</i>&lt;S, env_of_t&lt;R>>...</code>
        when they all complete with `set_value`, the behavior
        of calling `execution::transfer_when_all_with_variant(sch, s...)`
        is undefined.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    2. Otherwise, `execution::transfer_when_all(sch, execution::into_variant(s)...)`.

4. Senders returned from `execution::transfer_when_all` shall not propagate the sender queries `get_completion_scheduler<CPO>` to input senders. They will implement `get_completion_scheduler<CPO>`, where `CPO` is one of `set_value_t` and `set_stopped_t`; this query returns a scheduler equivalent to the `sch` argument from those queries. The `get_completion_scheduler<set_error_t>` is not implemented, as the scheduler cannot be guaranteed in case an error is thrown while trying to schedule work on the given scheduler object.

#### `execution::into_variant` <b>[exec.into_variant]</b> #### {#spec-execution.senders.adapt.into_variant}

1. `execution::into_variant` can be used to turn a sender which sends multiple sets of values into a sender which sends a variant of all of those sets of values.

2. The template <code><i>into-variant-type</i></code> is used to compute the type sent by a sender returned from `execution::into_variant`.

    <pre highlight=c++>
        template&lt;class S, class E>
            requires sender&lt;S, E>
          using <i>into-variant-type</i> =
            value_types_of_t&lt;S, E>;
    </pre>

3. `execution::into_variant` is a customization point object. For some subexpression `s`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::into_variant(s)` is ill-formed. Otherwise, `execution::into_variant(s)` returns
    a sender `s2`. When `s2` is connected with some receiver `out_r`, it:

    1. Constructs a receiver `r`:

        1. If `execution::set_value(r, ts...)` is called, calls <code>execution::set_value(out_r, <i>into-variant-type</i>&lt;S, env_of_t&lt;decltype((r))>>(<i>decayed-tuple</i>&lt;decltype(ts)...>(ts...)))</code>. If this expression throws an exception, calls `execution::set_error(out_r, current_exception())`.

        2. `execution::set_error(r, e)` is expression-equivalent to `execution::set_error(out_r, e)`.

        3. `execution::set_stopped(r)` is expression-equivalent to `execution::set_stopped(out_r)`.

    2. Calls `execution::connect(s, r)`, resulting in an operation state `op_state2`.

    3. Returns an operation state `op_state` that contains `op_state2`. When `execution::start(op_state)` is called, calls `execution::start(op_state2)`.

    4. Given subexpressions `s2` and `e`, where `s2` is a sender returned from `into_variant` or a copy of such, let `S2` be `decltype((s2))` and `E` be `decltype((e))`.
        Let <code><i>into-variant-set-value</i></code> be the class template:

        <pre highlight=c++>
            template &lt;class S, class E>
            struct <i>into-variant-set-value</i> {
              template &lt;class ...Args>
              using <i>apply</i> = set_value_t(<i>into-variant-type</i>&lt;S, E>);
            };
        </pre>

        Let <code><i>into-variant-is-nothrow</i></code> be the class template:

        <pre highlight=c++>
            template &lt;class S, class E>
            struct <i>into-variant-is-nothrow</i> {
              template &lt;class... Args>
                  requires constructible_from&lt;<i>decayed-tuple</i>&lt;Args...>, Args...>
                using <i>apply</i> = bool_constant&lt;noexcept(
                  <i>into-variant-type</i>&lt;S, E>(<i>decayed-tuple</i>&lt;Args...>(declval&lt;Args>()...)))>;
            };
        </pre>

        Let <code><i>INTO-VARIANT-ERROR-SIGNATURES</i>(S, E)</code> be `completion_signatures<set_error_t(exception_ptr)>` if any of the types in the <code><i>type-list</i></code> named by
            <code>value_types_of_t&lt;S, E, <i>into-variant-is-nothrow</i>&lt;S, E>::template <i>apply</i>, <i>type-list</i>></code> are `false_type`; otherwise, `completion_signatures<>`.

        The type of `tag_invoke(get_completion_signatures_t{}, s2, e))` shall be equivalent to:

        <pre highlight=c++>
            make_completion_signatures<
                S2,
                E,
                <i>INTO-VARIANT-ERROR-SIGNATURES</i>(S, E),
                <i>into-variant-set-value</i>&lt;S2, E>::template <i>apply</i>
            >
        </pre>

#### `execution::stopped_as_optional` <b>[exec.stopped_as_optional]</b> #### {#spec-execution.senders.adapt.stopped_as_optional}

1. `execution::stopped_as_optional` is used to handle a stopped signal by mapping it into the value channel as an empty optional. The value channel is also converted into an optional. The result is a sender that never completes with stopped, reporting cancellation by completing with an empty optional.

2. The name `execution::stopped_as_optional` denotes a customization point object. For some subexpression `s`, let `S` be `decltype((s))`. Let <code><i>get-env-sender</i></code> be an expression such that, when it is `connect`ed with a receiver `r`, `start` on the resulting operation state completes immediately by calling `execution::set_value(r, get_env(r))`. The expression `execution::stopped_as_optional(s)` is expression-equivalent to:

    <pre highlight=c++>
    execution::let_value(
      <i>get-env-sender</i>,
      []&lt;class E>(const E&) requires <i>single-sender</i>&lt;S, E> {
        return execution::let_stopped(
          execution::then(s,
            []&lt;class T>(T&& t) {
              return optional&lt;decay_t&lt;<i>single-sender-value-type</i>&lt;S, E>>>{
                static_cast&lt;T&&>(t)
              };
            }
          ),
          [] () noexcept {
            return execution::just(optional&lt;decay_t&lt;<i>single-sender-value-type</i>&lt;S, E>>>{});
          }
        );
      }
    )
    </pre>

#### `execution::stopped_as_error` <b>[exec.stopped_as_error]</b> #### {#spec-execution.senders.adapt.stopped_as_error}

1. `execution::stopped_as_error` is used to handle a stopped signal by mapping it into the error channel as a custom exception type. The result is a sender that never completes with stopped, reporting cancellation by completing with an error.

2. The name `execution::stopped_as_error` denotes a customization point object. For some subexpressions `s` and `e`, let `S` be `decltype((s))` and let `E` be `decltype((e))`. If the type `S` does not satisfy `sender` or if the type `E` doesn't satisfy <code><i>movable-value</i></code>, `execution::stopped_as_error(s, e)` is ill-formed. Otherwise, the expression `execution::stopped_as_error(s, e)` is expression-equivalent to:

    <pre highlight=c++>
    execution::let_stopped(s, [] { return execution::just_error(e); })
    </pre>

#### `execution::ensure_started` <b>[exec.ensure_started]</b> #### {#spec-execution.senders.adapt.ensure_started}

1. `execution::ensure_started` is used to eagerly start the execution of a sender, while also providing a way to attach further work to execute once it has completed.

2. Let <code><i>ensure-started-env</i></code> be the type of an execution
    environment such that, given an instance `e`, the expression
    `get_stop_token(e)` is well formed and has type `stop_token`.

2. The name `execution::ensure_started` denotes a customization point object.
    For some subexpression `s`, let `S` be `decltype((s))`. If
    <code>execution::sender&lt;S, <i>ensure-started-env</i>></code> is
    `false`, `execution::ensure_started(s)` is ill-formed. Otherwise, the
    expression `execution::ensure_started(s)` is expression-equivalent to:

    1. `tag_invoke(execution::ensure_started, get_completion_scheduler<set_value_t>(s), s)`, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    2. Otherwise, `tag_invoke(execution::ensure_started, s)`, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above satisfies `execution::sender`.

    3. Otherwise, constructs a sender `s2`, which:

        1. Creates an object `sh_state` that contains a `stop_source`, an
            initially null pointer to an operation state awaitaing completion,
            and that also reserves space for storing:

            * the operation state that results from connecting `s` with `r` described below, and
            * the sets of values and errors with which `s` may complete, with
                the addition of `exception_ptr`.

            `s2` shares ownership of `sh_state` with `r` described below.

        2. Constructs a receiver `r` such that:

            1. When `execution::set_value(r, args...)` is called, decay-copies
                the expressions `args...` into `sh_state`. It then checks
                `sh_state` to see if there is an operation state awaiting
                completion; if so, it notifies the operation state that the
                results are ready. If any exceptions are thrown, the exception
                is caught and `execution::set_error(r, current_exception())` is
                called instead.

            2. When `execution::set_error(r, e)` is called, decay-copies `e`
                into `sh_state`. If there is an operation state awaiting completion,
                it then notifies the operation state that the results are ready.

            3. When `execution::set_stopped(r)` is called, it then notifies any
                awaiting operation state that the results are ready.

            4. `get_env(r)` is an expression <code><i>e</i></code> of type
                <code><i>ensure-started-env</i></code> such that
                <code>execution::get_stop_token(<i>e</i>)</code> is well-formed
                and returns the results of calling `get_token()` on `sh_state`'s
                stop source.

            5. `r` shares ownership of `sh_state` with `s2`. After `r`'s
                receiver contract has been completed, it releases its ownership
                of `sh_state`.

        3. Calls `execution::connect(s, r)`, resulting in an operation state
            `op_state2`. `op_state2` is saved in `sh_state`. It then calls
            `execution::start(op_state2)`.

        4. When `s2` is connected with a receiver `out_r` of type `OutR`, it
            returns an operation state object `op_state` that contains:

              * An object `out_r'` of type `OutR` decay-copied from `out_r`,
              * A reference to `sh_state`,
              * A stop callback of type
                <code>optional&lt;stop_token_of_t&lt;env_of_t&lt;OutR>>::callback_type&lt;<i>stop-callback-fn</i>>></code>,
                where <code><i>stop-callback-fn</i></code> is an implementation
                defined class type equivalent to the following:

                <pre highlight="c++">
                struct <i>stop-callback-fn</i> {
                  stop_source& stop_src_;
                  void operator()() noexcept {
                    stop_src_.request_stop();
                  }
                };
                </pre>

              `s2` transfers its ownership of `sh_state` to `op_state`.

        5. When `execution::start(op_state)` is called:

            * If `r`'s receiver contract has already been satisfied, then let
                <code><i>Signal</i></code> be whichever receiver completion-signal
                was used to complete `r`'s receiver contract ([exec.recv]). Calls
                <code><i>Signal</i>(out_r', args2...)</code>, where `args2...` is a
                pack of xvalues referencing the subobjects of `sh_state` that have
                been saved by the original call to <code><i>Signal</i>(r,
                args...)</code> and returns.

            * Otherwise, it emplace constructs the stop callback optional with
                the arguments `execution::get_stop_token(get_env(out_r'))` and
                <code><i>stop-callback-fn</i>{<i>stop-src</i>}</code>, where
                <code><i>stop-src</i></code> refers to the stop source of
                `sh_state`.

            * Then, it checks to see if
                <code><i>stop-src</i>.stop_requested()</code> is `true`. If so, it
                calls `execution::set_stopped(out_r')`.

            * Otherwise, it sets `sh_state` operation state pointer to the
                address of `op_state`, registering itself as awaiting the result
                of the completion of `r`.

        6. When `r` completes it will notify `op_state` that the result are
            ready. Let <code><i>Signal</i></code> be whichever receiver
            completion-signal was used to complete `r`'s receiver contract
            ([exec.recv]). `op_state`'s stop callback optional is reset. Then
            <code><i>Signal</i>(std::move(out_r'), args2...)</code> is called,
            where `args2...` is a pack of xvalues referencing the subobjects of
            `sh_state` that have been saved by the original call to
            <code><i>Signal</i>(r, args...)</code>.

        7. [*Note:* If sender `s2` is destroyed without being connected to a
            receiver, or if it is connected but the operation state is destroyed
            without having been started, then when `r`'s receiver contract
            completes and it releases its shared ownership of `sh_state`,
            `sh_state` will be destroyed and the results of the operation are
            discarded. -- *end note*]

    4. Given subexpressions `s2` and `e` where `s2` is a sender returned
        from `ensure_started` or a copy of such, let `S2` be `decltype((s2))` and let
        `E` be `decltype((e))`. The type of
        `tag_invoke(get_completion_signatures, s2, e)` shall be equivalent
        to:

            <pre highlight="c++">
            make_completion_signatures&lt;
              copy_cvref_t&lt;S2, S>,
              <i>ensure-started-env</i>,
              completion_signatures&lt;set_error_t(exception_ptr&amp;&amp;)>,
              <i>set-value-signature</i>,
              <i>error-types</i>>
            </pre>

            where <code><i>set-value-signature</i></code> is the alias template:

            <pre highlight="c++">
            template &lt;class... Ts>
              using <i>set-value-signature</i> =
                completion_signatures&lt;set_value_t(decay_t&lt;Ts>&amp;&amp;...)>;
            </pre>

            and <code><i>error-types</i></code> is the alias template:

            <pre highlight="c++">
            template &lt;class E>
              using <i>error-types</i> =
                completion_signatures&lt;set_error_t(decay_t&lt;E>&amp;&amp;)>;
            </pre>

    If the function selected above does not return a sender that sends xvalue
    references to values sent by `s`, propagating the other channels, the
    behavior of calling `execution::ensure_started(s)` is undefined.

### Sender consumers <b>[exec.consumers]</b> ### {#spec-execution.senders.consumers}

#### `execution::start_detached` <b>[exec.start_detached]</b> #### {#spec-execution.senders.consumers.start_detached}

1. `execution::start_detached` is used to eagerly start a sender without the caller needing to manage the lifetimes of any objects.

2. The name `execution::start_detached` denotes a customization point object. For some subexpression `s`, let `S` be `decltype((s))`. If `S` does not satisfy `execution::sender`, `execution::start_detached` is ill-formed. Otherwise, the expression
    `execution::start_detached(s)` is expression-equivalent to:

    1. `tag_invoke(execution::start_detached, execution::get_completion_scheduler<execution::set_value_t>(s), s)`, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above is `void`.

    2. Otherwise, `tag_invoke(execution::start_detached, s)`, if that expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above is `void`.

    3. Otherwise:

        1. Let `R` be the type of a receiver, let `r` be an rvalue of type `R`, and let `cr` be a
            lvalue reference to `const R` such that:

            1. The expression `set_value(r)` is not potentially throwing and has no effect,

            2. For any subexpression `e`, the expression `set_error(r, e)` is expression-equivalent
                to `terminate()`,

            3. The expression `set_stopped(r)` is not potentially throwing and has no effect, and

            4. The expression `get_env(cr)` is expression-equivalent to <code><i>empty-env</i>{}</code>.

        2. Calls `execution::connect(s, r)`, resulting in an operation state
            `op_state`, then calls `execution::start(op_state)`. The lifetime of
            `op_state` lasts until one of the receiver completion-signals of `r`
            is called.

    If the function selected above does not eagerly start the sender `s` after
    connecting it with a receiver which ignores the `set_value` and
    `set_stopped` signals and calls `terminate()` on the `set_error` signal,
    the behavior of calling `execution::start_detached(s)` is undefined.

#### `this_thread::sync_wait` <b>[exec.sync_wait]</b> #### {#spec-execution.senders.consumers.sync_wait}

1. `this_thread::sync_wait` and `this_thread::sync_wait_with_variant` are used to block a current thread until a sender passed into it as an argument has completed, and to obtain the values (if any) it completed with.

2. For any receiver `r` created by an implementation of `sync_wait` and
    `sync_wait_with_variant`, the expressions `get_scheduler(get_env(r))` and
    `get_delegatee_scheduler(get_env(r))` shall be well-formed. For a receiver
    created by the default implementation of `this_thread::sync_wait`, these
    expressions shall return a scheduler to the same thread-safe,
    first-in-first-out queue of work such that tasks scheduled to the queue
    execute on the thread of the caller of `sync_wait`. [<i>Note:</i> The
    scheduler for an instance of `execution::run_loop` that is a local variable
    within `sync_wait` is one valid implementation. -- <i>end note</i>]

3. The templates <code><i>sync-wait-type</i></code> and
    <code><i>sync-wait-with-variant-type</i></code> are used to determine the
    return types of `this_thread::sync_wait` and
    `this_thread::sync_wait_with_variant`. Let <code><i>sync-wait-env</i></code>
    be the type of the expression `get_env(r)` where `r` is an instance of the
    receiver created by the default implementation of `sync_wait`.

    <pre highlight=c++>
    template&lt;sender&lt;<i>sync-wait-env</i>> S>
      using <i>sync-wait-type</i> =
        optional&lt;execution::value_types_of_t&lt;S, <i>sync-wait-env</i>, <i>decayed-tuple</i>, type_identity_t>>;

    template&lt;sender&lt;<i>sync-wait-env</i>> S>
      using <i>sync-wait-with-variant-type</i> = optional&lt;execution::<i>into-variant-type</i>&lt;S, <i>sync-wait-env</i>>>;
    </pre>

4. The name `this_thread::sync_wait` denotes a customization point object. For
    some subexpression `s`, let `S` be `decltype((s))`. If
    <code>execution::sender&lt;S, <i>sync-wait-env</i>></code> is `false`,
    or the number of the arguments <code>completion_signatures_of_t&lt;S,
    <i>sync-wait-env</i>>::value_types</code> passed into the `Variant` template
    parameter is not 1, `this_thread::sync_wait(s)` is ill-formed. Otherwise,
    `this_thread::sync_wait(s)` is expression-equivalent to:

    1. `tag_invoke(this_thread::sync_wait, execution::get_completion_scheduler<execution::set_value_t>(s), s)`, if this expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above is <code><i>sync-wait-type</i>&lt;S, <i>sync-wait-env</i>></code>.

    2. Otherwise, `tag_invoke(this_thread::sync_wait, s)`, if this expression is valid and its type is.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above is <code><i>sync-wait-type</i>&lt;S, <i>sync-wait-env</i>></code>.

    3. Otherwise:

        1. Constructs a receiver `r`.

        2. Calls `execution::connect(s, r)`, resulting in an operation state `op_state`, then calls `execution::start(op_state)`.

        3. Blocks the current thread until a receiver completion-signal of `r` is called. When it is:

            1. If `execution::set_value(r, ts...)` has been called, returns <code><i>sync-wait-type</i>&lt;S, <i>sync-wait-env</i>>{<i>decayed-tuple</i>&lt;decltype(ts)...>{ts...}}</code>. If that expression exits exceptionally, the exception is propagated to the caller of `sync_wait`.

            2. If `execution::set_error(r, e)` has been called, let `E` be the decayed type of `e`. If `E` is `exception_ptr`, calls `std::rethrow_exception(e)`. Otherwise, if the `E` is `error_code`, throws `system_error(e)`. Otherwise, throws `e`.

            3. If `execution::set_stopped(r)` has been called, returns <code><i>sync-wait-type</i>&lt;S, <i>sync-wait-env</i>>{}</code>.

5. The name `this_thread::sync_wait_with_variant` denotes a customization point
    object. For some subexpression `s`, let `S` be the type of
    `execution::into_variant(s)`. If <code>execution::sender&lt;S,
    <i>sync-wait-env</i>></code> is `false`,
    `this_thread::sync_wait_with_variant(s)` is ill-formed. Otherwise,
    `this_thread::sync_wait_with_variant(s)` is expression-equivalent to:

    1. `tag_invoke(this_thread::sync_wait_with_variant, execution::get_completion_scheduler<execution::set_value_t>(s), s)`, if this expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above is <code><i>sync-wait-with-variant-type</i>&lt;S, <i>sync-wait-env</i>></code>.

    2. Otherwise, `tag_invoke(this_thread::sync_wait_with_variant, s)`, if this expression is valid.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above is <code><i>sync-wait-with-variant-type</i>&lt;S, <i>sync-wait-env</i>></code>.

    3. Otherwise, `this_thread::sync_wait(execution::into_variant(s))`.

## `execution::execute` <b>[exec.execute]</b> ## {#spec-execution.execute}

1. `execution::execute` is used to create fire-and-forget tasks on a specified scheduler.

2. The name `execution::execute` denotes a customization point object. For some subexpressions `sch` and `f`, let `Sch` be `decltype((sch))` and `F` be `decltype((f))`. If `Sch` does not satisfy `execution::scheduler` or `F` does not satisfy `invocable`,
    `execution::execute` is ill-formed. Otherwise, `execution::execute` is expression-equivalent to:

    1. `tag_invoke(execution::execute, sch, f)`, if that expression is valid. If
        the function selected by `tag_invoke` does not invoke the function `f`
        (or an object decay-copied from `f`) on an execution agent belonging to
        the associated execution context of `sch`, or if it does not call
        `std::terminate` if an error occurs after control is returned to the
        caller, the behavior of calling `execution::execute`
        is undefined.

        * <i>Mandates:</i> The type of the `tag_invoke` expression above is `void`.

    2. Otherwise, `execution::start_detached(execution::then(execution::schedule(sch), f))`.

## Sender/receiver utilities <b>[exec.utils]</b> ## {#spec-execution.snd_rec_utils}

1. This section makes use of the following exposition-only entities:

    <pre highlight="c++">
    // [<i>Editorial note:</i> copy_cvref_t as in [[P1450R3]] -- <i>end note</i>]
    // Mandates: is_base_of_v&lt;T, remove_reference_t&lt;U>> is true
    template &lt;class T, class U>
      copy_cvref_t&lt;U&amp;&amp;, T> <i>c-style-cast</i>(U&amp;&amp; u) noexcept requires <i>decays-to</i>&lt;T, T> {
        return (copy_cvref_t&lt;U&amp;&amp;, T>) std::forward&lt;U>(u);
      }
    </pre>

2. [<i>Note:</i> The C-style cast in <tt><i>c-style-cast</i></tt> is to disable accessibility checks. -- <i>end note</i>]

### `execution::receiver_adaptor` <b>[exec.utils.rcvr_adptr]</b> ### {#spec-execution.snd_rec_utils.rcvr_adptr}

    <pre highlight="c++">
    template&lt;
        <i>class-type</i> Derived,
        receiver Base = <i>unspecified</i>> // arguments are not associated entities ([lib.tmpl-heads])
      class receiver_adaptor;
    </pre>

1. `receiver_adaptor` is used to simplify the implementation of one receiver type in terms of another. It defines `tag_invoke` overloads that forward to named members if they exist, and to the adapted receiver otherwise.

2. If `Base` is an alias for the unspecified default template argument, then:

    - Let <code><i>HAS-BASE</i></code> be `false`, and
    - Let <code><i>GET-BASE</i>(d)</code> be `d.base()`.

    otherwise, let:

    - Let <code><i>HAS-BASE</i></code> be `true`, and
    - Let <code><i>GET-BASE</i>(d)</code> be <code><i>c-style-cast</i>&lt;receiver_adaptor&lt;Derived, Base>>(d).base()</code>.

    Let <code><i>BASE-TYPE</i>(D)</code> be the type of <code><i>GET-BASE</i>(declval&lt;D>())</code>.

3. `receiver_adaptor<Derived, Base>` is equivalent to the following:

    <pre highlight="c++">
    template &lt;
      <i>class-type</i> Derived,
      receiver Base = <i>unspecified</i>> // arguments are not associated entities ([lib.tmpl-heads])
    class receiver_adaptor {
      friend Derived;
     public:
      // Constructors
      receiver_adaptor() = default;
      template &lt;class B>
          requires <i>HAS-BASE</i> && constructible_from&lt;Base, B>
        explicit receiver_adaptor(B&& base) : base_(std::forward&lt;B>(base)) {}

     private:
      using set_value = <i>unspecified</i>;
      using set_error = <i>unspecified</i>;
      using set_stopped = <i>unspecified</i>;
      using get_env = <i>unspecified</i>;

      // Member functions
      template &lt;class Self>
        requires <i>HAS-BASE</i>
      decltype(auto) base(this Self&amp;&amp; self) noexcept {
        return (std::forward&lt;Self>(self).base_);
      }

      // [exec.utils.rcvr_adptr.nonmembers] Non-member functions
      template &lt;class... As>
        friend void tag_invoke(set_value_t, Derived&amp;&amp; self, As&amp;&amp;... as) noexcept;

      template &lt;class E>
        friend void tag_invoke(set_error_t, Derived&amp;&amp; self, E&amp;&amp; e) noexcept;

      friend void tag_invoke(set_stopped_t, Derived&amp;&amp; self) noexcept;

      friend decltype(auto) tag_invoke(get_env_t, const Derived&amp; self)
          noexcept(<i>see below</i>);

      template &lt;<i>forwarding-receiver-query</i> Tag, class... As>
          requires <i>callable</i>&lt;Tag, <i>BASE-TYPE</i>(const Derived&amp;), As...>
        friend auto tag_invoke(Tag tag, const Derived&amp; self, As&amp;&amp;... as)
          noexcept(<i>nothrow-callable</i>&lt;Tag, <i>BASE-TYPE</i>(const Derived&amp;), As...>)
          -> <i>call-result-t</i>&lt;Tag, <i>BASE-TYPE</i>(const Derived&), As...> {
          return std::move(tag)(<i>GET-BASE</i>(self), std::forward&lt;As>(as)...);
        }

      [[no_unique_address]] Base base_; // present if and only if <i>HAS-BASE</i> is true
    };
    </pre>

4. [<i>Note:</i> `receiver_adaptor` provides `tag_invoke` overloads on behalf of
    the derived class `Derived`, which is incomplete when `receiver_adaptor` is
    instantiated.]

5. [<i>Example:</i>
     <pre highlight="c++">
     using _int_completion =
       execution::completion_signatures&lt;execution::set_value_t(int)>;

     template &lt;execution::receiver_of&lt;_int_completion> R>
       class my_receiver : execution::receiver_adaptor&lt;my_receiver&lt;R>, R> {
         friend execution::receiver_adaptor&lt;my_receiver, R>;
         void set_value() && {
           execution::set_value(std::move(*this).base(), 42);
         }
        public:
         using execution::receiver_adaptor&lt;my_receiver, R>::receiver_adaptor;
       };
     </pre>
     -- <i>end example</i>]

#### Non-member functions <b>[exec.utils.rcvr_adptr.nonmembers]</b> #### {#spec-execution.snd_rec_utils.receiver_adaptor.nonmembers}

    <pre>
    template &lt;class... As>
      friend void tag_invoke(set_value_t, Derived&amp;&amp; self, As&amp;&amp;... as) noexcept;
    </pre>

    1. Let `SET-VALUE` be the expression `std::move(self).set_value(std::forward<As>(as)...)`.

    2. <i>Constraints:</i> Either `SET-VALUE` is a valid expression or `typename Derived::set_value` denotes a type and <code><i>callable</i>&lt;set_value_t, <i>BASE-TYPE</i>(Derived), As...></code> is `true`.

    3. <i>Mandates:</i> `SET-VALUE`, if that expression is valid, is not potentially throwing.

    4. <i>Effects:</i> Equivalent to:

        * If `SET-VALUE` is a valid expression, `SET-VALUE`;

        * Otherwise, <code>execution::set_value(<i>GET-BASE</i>(std::move(self)), std::forward&lt;As>(as)...)</code>.

    <pre>
    template &lt;class E>
      friend void tag_invoke(set_error_t, Derived&amp;&amp; self, E&amp;&amp; e) noexcept;
    </pre>

    1. Let `SET-ERROR` be the expression `std::move(self).set_error(std::forward<E>(e))`.

    2. <i>Constraints:</i> Either `SET-ERROR` is a valid expression or `typename Derived::set_error` denotes a type and <code><i>callable</i>&lt;set_error_t, <i>BASE-TYPE</i>(Derived), E></code> is `true`.

    3. <i>Mandates:</i> `SET-ERROR`, if that expression is valid, is not potentially throwing.

    4. <i>Effects:</i> Equivalent to:

        * If `SET-ERROR` is a valid expression, `SET-ERROR`;

        * Otherwise, <code>execution::set_error(<i>GET-BASE</i>(std::move(self)), std::forward&lt;E>(e))</code>.

    <pre>
    friend void tag_invoke(set_stopped_t, Derived&amp;&amp; self) noexcept;
    </pre>

    1. Let `SET-STOPPED` be the expression `std::move(self).set_stopped()`.

    2. <i>Constraints:</i> Either `SET-STOPPED` is a valid expression or `typename Derived::set_stopped` denotes a type and <code><i>callable</i>&lt;set_stopped_t, <i>BASE-TYPE</i>(Derived)></code> is `true`.

    3. <i>Mandates:</i> `SET-STOPPED`, if that expression is valid, is not potentially throwing.

    4. <i>Effects:</i> Equivalent to:

        * If `SET-STOPPED` is a valid expression, `SET-STOPPED`;

        * Otherwise, <code>execution::set_stopped(<i>GET-BASE</i>(std::move(self)))</code>.

    <pre>
    friend decltype(auto) tag_invoke(get_env_t, const Derived&amp; self)
      noexcept(<i>see below</i>);
    </pre>

    1. <i>Constraints:</i> Either `self.get_env()` is a valid expression or `typename Derived::get_env` denotes a type and <code><i>callable</i>&lt;get_env_t, <i>BASE-TYPE</i>(const Derived&amp;)></code> is `true`.

    2. <i>Effects:</i> Equivalent to:

        * If `self.get_env()` is a valid expression, `self.get_env()`;

        * Otherwise, <code>execution::get_env(<i>GET-BASE</i>(self))</code>.

    3. <i>Remarks:</i> The expression in the `noexcept` clause is:

        * If `self.get_env()` is a valid expression, `noexcept(self.get_env())`;

        * Otherwise, <code>noexcept(execution::get_env(<i>GET-BASE</i>(self)))</code>.

### `execution::completion_signatures` <b>[exec.utils.cmplsigs]</b> ### {#spec-execution.snd_rec_utils.completion_sigs}

1. `completion_signatures` is used to describe the completion signals of a receiver that
    a sender may invoke. Its template argument list is a list of function types corresponding
    to the signatures of the receiver's completion signals.

2. [<i>Example:</i>
     <pre highlight="c++">
      class my_sender {
        using completion_signatures =
          execution::completion_signatures&lt;
            execution::set_value_t(),
            execution::set_value_t(int, float),
            execution::set_error_t(exception_ptr),
            execution::set_error_t(error_code),
            execution::set_stopped_t()>;
      };

      // Declares my_sender to be a sender that can complete by calling
      // one of the following for a receiver expression R:
      //    execution::set_value(R)
      //    execution::set_value(R, int{...}, float{...})
      //    execution::set_error(R, exception_ptr{...})
      //    execution::set_error(R, error_code{...})
      //    execution::set_stopped(R)
     </pre>
     -- <i>end example</i>]

3. This section makes use of the following exposition-only concept:

    <pre highlight="c++">
    template &lt;class Fn>
      concept <i>completion-signature</i> = <i>see below</i>;
    </pre>

    1. A type `Fn` satisfies <code><i>completion-signature</i></code> if it is a function type with one of the following forms:

        * <code>set_value_t(<i>Vs</i>...)</code>, where <code><i>Vs</i></code> is an arbitrary parameter pack.
        * <code>set_error_t(<i>E</i>)</code>, where <code><i>E</i></code> is an arbitrary type.
        * `set_stopped_t()`

    2. Otherwise, `Fn` does not satisfy <code><i>completion-signature</i></code>.

4.  <pre highlight="c++">
    template &lt;<i>completion-signature</i>... Fns>
      struct completion_signatures {};
    </pre>

5.  <pre highlight="c++">
    template&lt;class S,
            class E = no_env,
            template &lt;class...> class Tuple = <i>decayed-tuple</i>,
            template &lt;class...> class Variant = <i>variant-or-empty</i>>
        requires sender&lt;S, E>
      using value_types_of_t = <i>see below</i>;
    </pre>

    * Let `Fns...` be a template parameter pack of the arguments of the
        `completion_signatures` instantiation named by
        `completion_signatures_of_t<S, E>`, let <code><i>ValueFns</i></code> be a
        template parameter pack of the function types in `Fns` whose return types
        are `execution::set_value_t`, and let
        <code><i>Values<i><sub>n</sub></i></i></code> be a template parameter
        pack of the function argument types in the <code><i>n</i></code>-th type
        in <code><i>ValueFns</i></code>. Then, given two variadic templates
        <code><i>Tuple</i></code> and <code><i>Variant</i></code>, the type
        <code>value_types_of_t&lt;S, E, <i>Tuple</i>, <i>Variant</i>></code>
        names the type
        <code><i>Variant</i>&lt;<i>Tuple</i>&lt;<i>Values<i><sub>0</sub></i></i>...>,
        <i>Tuple</i>&lt;<i>Values<i><sub>1</sub></i></i>...>, ...
        <i>Tuple</i>&lt;<i>Values<i><sub>m-1</sub></i></i>...>></code>, where
        <code><i>m</i></code> is the size of the parameter pack
        <code><i>ValueFns</i></code>.

6.  <pre highlight="c++">
    template&lt;class S,
            class E = no_env,
            template &lt;class...> class Variant = <i>variant-or-empty</i>>
        requires sender&lt;S, E>
      using error_types_of_t = <i>see below</i>;
    </pre>

    * Let `Fns...` be a template parameter pack of the arguments of the
        `completion_signatures` instantiation named by
        `completion_signatures_of_t<S, E>`, let <code><i>ErrorFns</i></code> be a
        template parameter pack of the function types in `Fns` whose return types
        are `execution::set_error_t`, and let
        <code><i>Error<i><sub>n</sub></i></i></code> be the function argument
        type in the <code><i>n</i></code>-th type in
        <code><i>ErrorFns</i></code>. Then, given a variadic template
        <code><i>Variant</i></code>, the type <code>error_types_of_t&lt;S, E,
        <i>Variant</i>></code> names the type
        <code><i>Variant</i>&lt;<i>Error<i><sub>0</sub></i></i>,
        <i>Error<i><sub>1</sub></i></i>, ...
        <i>Error<i><sub>m-1</sub></i></i>></code>, where <code><i>m</i></code> is
        the size of the parameter pack <code><i>ErrorFns</i></code>.

7.  <pre highlight="c++">
    template&lt;class S, class E = no_env>
        requires sender&lt;S, E>
      inline constexpr bool sends_stopped = <i>see below</i>;
    </pre>

    * Let `Fns...` be a template parameter pack of the arguments of the
        `completion_signatures` instantiation named by
        `completion_signatures_of_t<S, E>`. `sends_stopped<S, E>` is `true` if at
        least one of the types in `Fns` is `execution::set_stopped_t()`;
        otherwise, `false`.

### `execution::make_completion_signatures` <b>[exec.utils.mkcmplsigs]</b> ### {#spec-execution.snd_rec_utils.make_completion_sigs}

1. `make_completion_signatures` is an alias template used to adapt the
    completion signatures of a sender. It takes a sender, and environment, and
    several other template arguments that apply modifications to the sender's
    completion signatures to generate a new instantiation of
    `execution::completion_signatures`.

2. [<i>Example:</i>
    <pre highlight="c++">
    // Given a sender S and an environment Env, adapt a S's completion
    // signatures by lvalue-ref qualifying the values, adding an additional
    // exception_ptr error completion if its not already there, and leaving the
    // other signals alone.
    template &lt;class... Args>
      using my_set_value_t =
        execution::completion_signatures&lt;
          execution::set_value_t(add_lvalue_reference_t&lt;Args>...)>;

    using my_completion_signals =
      execution::make_completion_signatures&lt;
        S, Env,
        execution::completion_signatures&lt;execution::set_error_t(exception_ptr)>,
        my_set_value_t>;
    </pre>
    -- <i>end example</i>]

3. This section makes use of the following exposition-only entities:

    <pre highlight="c++">
    template &lt;class... As>
      using <i>default-set-value</i> =
        execution::completion_signatures&lt;execution::set_value_t(As...)>;

    template &lt;class Err>
      using <i>default-set-error</i> =
        execution::completion_signatures&lt;execution::set_error_t(Err)>;
    </pre>

4.  <pre highlight="c++">
    template &lt;
      execution::sender Sndr,
      class Env = execution::no_env,
      <i>valid-completion-signatures&lt;Env></i> AddlSigs = execution::completion_signatures&lt;>,
      template &lt;class...> class SetValue = <i>default-set-value</i>,
      template &lt;class> class SetError = <i>default-set-error</i>,
      <i>valid-completion-signatures&lt;Env></i> SetStopped =
          execution::completion_signatures&lt;set_stopped_t()>>
        requires sender&lt;Sndr, Env>
    using make_completion_signatures =
      execution::completion_signatures&lt;<i>/* see below */</i>>;
    </pre>

    *  `SetValue` shall name an alias template such that for any template
        parameter pack `As...`, the type `SetValue<As...>` is either ill-formed
        or else <code><i>valid-completion-signatures</i>&lt;SetValue&lt;As...>, E></code>
        is satisfied.
    *  `SetError` shall name an alias template such that for any type `Err`,
        `SetError<Err>` is either ill-formed or else
        <code><i>valid-completion-signatures</i>&lt;SetError&lt;Err>, E></code>
        is satisfied.

    Then:

        * Let `Vs...` be a pack of the types in the <code><i>type-list</i></code> named
            by <code>value_types_of_t&lt;Sndr, Env, SetValue, <i>type-list</i>></code>.

        *  Let `Es...` be a pack of the types in the
            <code><i>type-list</i></code> named by <code>error_types_of_t&lt;Sndr, Env,
            <i>error-list</i>></code>, where <code><i>error-list</i></code> is an
            alias template such that <code><i>error-list</i>&lt;Ts...></code> names
            <code><i>type-list</i>&lt;SetError&lt;Ts>...></code>.

        * Let `Ss` name the type `completion_signatures<>` if `sends_stopped<Sndr,
            Env>` is `false`; otherwise, `SetStopped`.

        Then:

        1. If any of the above types are ill-formed, then
            `make_completion_signatures<Sndr, Env, AddlSigs, SetValue, SetError,
            SetStopped>` is ill-formed,

        2. Otherwise, if any type in `[AddlSigs, Vs..., Es..., Ss]` is not an
            instantiation of `completion_signatures`, then
            `make_completion_signatures<Sndr, Env, AddlSigs, SetValue, SetError,
            SetStopped>` is an alias for `dependent_completion_signatures<no_env>`,

        3. Otherwise, `make_completion_signatures<Sndr, Env, AddlSigs, SetValue,
            SetError, SetStopped>` names the type `completion_signatures<Sigs...>`
            where `Sigs...` is the unique set of types in all the template arguments
            of all the `completion_signatures` instantiations in `[AddlSigs, Vs..., Es..., Ss]`.

## Execution contexts <b>[exec.ctx]</b> ## {#spec-execution.contexts}

1. This section specifies some execution contexts on which work can be scheduled.

### `run_loop` <b>[exec.run_loop]</b> ### {#spec-execution.contexts.run_loop}

1. A `run_loop` is an execution context on which work can be scheduled. It maintains a simple, thread-safe first-in-first-out queue of work. Its `run()` member function removes elements from the queue and executes them in a loop on whatever thread of execution calls `run()`.

2. A `run_loop` instance has an associated <i>count</i> that corresponds to the number of work items that are in its queue. Additionally, a `run_loop` has an associated <i>state</i> that can be one of <i>starting</i>, <i>running</i>, or <i>finishing</i>.

3. Concurrent invocations of the member functions of `run_loop`, other than `run` and its destructor, do not introduce data races. The member functions `pop_front`, `push_back`, and `finish` execute atomically.

4. [<i>Note:</i> Implementations are encouraged to use an intrusive queue of operation states to hold the work units to make scheduling allocation-free. — <i>end note</i>]

    <pre highlight="c++">
    class run_loop {
      // [exec.run_loop.types] Associated types
      class <i>run-loop-scheduler</i>; // exposition only
      class <i>run-loop-sender</i>; // exposition only
      struct <i>run-loop-opstate-base</i> { // exposition only
        virtual void execute() = 0;
        run_loop* loop_;
        <i>run-loop-opstate-base</i>* next_;
      };
      template&lt;receiver_of R>
        using <i>run-loop-opstate</i> = <i>unspecified</i>; // exposition only

      // [exec.run_loop.members] Member functions:
      <i>run-loop-opstate-base</i>* pop_front(); // exposition only
      void push_back(<i>run-loop-opstate-base</i>*); // exposition only

     public:
      // [exec.run_loop.ctor] construct/copy/destroy
      run_loop() noexcept;
      run_loop(run_loop&&) = delete;
      ~run_loop();

      // [exec.run_loop.members] Member functions:
      <i>run-loop-scheduler</i> get_scheduler();
      void run();
      void finish();
    };
    </pre>

#### Associated types <b>[exec.run_loop.types]</b> #### {#spec-execution.contexts.run_loop.types}

    <pre highlight="c++">
    class <i>run-loop-scheduler</i>;
    </pre>

  1. <code><i>run-loop-scheduler</i></code> is an implementation defined type that models the `scheduler` concept.

  2. Instances of <code><i>run-loop-scheduler</i></code> remain valid until the end of the lifetime of the `run_loop` instance from which they were obtained.

  3. Two instances of <code><i>run-loop-scheduler</i></code> compare equal if and only if they were obtained from the same `run_loop` instance.

  4. Let <code><i>sch</i></code> be an expression of type <code><i>run-loop-scheduler</i></code>. The expression  <code>execution::schedule(<i>sch</i>)</code> is not potentially throwing and has type <code><i>run-loop-sender</i></code>.

  <pre highlight="c++">
  class <i>run-loop-sender</i>;
  </pre>

  1. <code><i>run-loop-sender</i></code> is an implementation defined type that models the `sender_of` concept; <i>i.e.,</i> <code>sender_of&lt;<i>run-loop-sender</i>></code> is `true`. Additionally, the types reported by its `error_types` associated type is `exception_ptr`, and the value of its `sends_stopped` trait is `true`.

  2. An instance of <code><i>run-loop-sender</i></code> remains valid until the end of the lifetime of its associated `execution::run_loop` instance.

  3. Let <code><i>s</i></code> be an expression of type <code><i>run-loop-sender</i></code>, let <code><i>r</i></code> be an expression such that <code>decltype(<i>r</i>)</code> models the `receiver_of` concept, and let `C` be either `set_value_t` or `set_stopped_t`. Then:

    * The expression <code>execution::connect(<i>s</i>, <i>r</i>)</code> has type <code><i>run-loop-opstate</i>&lt;decay_t&lt;decltype(<i>r</i>)>></code> and is potentially throwing if and only if the initialiation of <code>decay_t&lt;decltype(<i>r</i>)></code> from <code><i>r</i></code> is potentially throwing.

    * The expression <code>get_completion_scheduler&lt;C>(<i>s</i>)</code> is not potentially throwing, has type <code><i>run-loop-scheduler</i></code>, and compares equal to the <code><i>run-loop-scheduler</i></code> instance from which <code><i>s</i></code> was obtained.

  <pre highlight="c++">
  template&lt;receiver_of R> // arguments are not associated entities ([lib.tmpl-heads])
    struct <i>run-loop-opstate</i>;
  </pre>

  1. <code><i>run-loop-opstate</i>&lt;<i>R</i>></code> inherits unambiguously from <code><i>run-loop-opstate-base</i></code>.

  2. Let <code><i>o</i></code> be a non-`const` lvalue of type <code><i>run-loop-opstate</i>&lt;R></code>, and let <code><i>REC</i>(<i>o</i>)</code> be a non-`const` lvalue reference to an instance of type <code><i>R</i></code> that was initialized with the expression <code><i>r</i></code> passed to the invocation of `execution::connect` that returned <code><i>o</i></code>. Then:

    * The object to which <code><i>REC</i>(<i>o</i>)</code> refers remains valid for the lifetime of the object to which <code><i>o</i></code> refers.

    * The type <code><i>run-loop-opstate</i>&lt;R></code> overrides <code><i>run-loop-opstate-base</i>::execute()</code> such that <code><i>o</i>.execute()</code> is equivalent to the following:

        <pre highlight="c++">
        if (execution::get_stop_token(<i>REC</i>(<i>o</i>)).stop_requested()) {
          execution::set_stopped(std::move(<i>REC</i>(<i>o</i>)));
        } else {
          execution::set_value(std::move(<i>REC</i>(<i>o</i>)));
        }
        </pre>

    * The expression <code>execution::start(<i>o</i>)</code> is equivalent to the following:

        <pre highlight="c++">
        try {
          <i>o</i>.loop_->push_back(&<i>o</i>);
        } catch(...) {
          execution::set_error(std::move(<i>REC</i>(<i>o</i>)), current_exception());
        }
        </pre>

#### Constructor and destructor <b>[exec.run_loop.ctor]</b> #### {#spec-execution.contexts.run_loop.ctor}

    <pre highlight="c++">
    run_loop::run_loop() noexcept;
    </pre>

    1. <i>Postconditions:</i> <i>count</i> is `0` and <i>state</i> is <i>starting</i>.

    <pre highlight="c++">
    run_loop::~run_loop();
    </pre>

    1. <i>Effects:</i> If <i>count</i> is not `0` or if <i>state</i> is <i>running</i>, invokes `terminate()`. Otherwise, has no effects.

#### Member functions <b>[exec.run_loop.members]</b> #### {#spec-execution.contexts.run_loop.members}

    <pre highlight="c++">
    <i>run-loop-opstate-base</i>* run_loop::pop_front();
    </pre>

    1. <i>Effects:</i> Blocks ([defns.block]) until one of the following conditions is `true`:

        * <i>count</i> is `0` and <i>state</i> is <i>finishing</i>, in which case `pop_front` returns `nullptr`; or

        * <i>count</i> is greater than `0`, in which case an item is removed from the front of the queue, <i>count</i> is decremented by `1`, and the removed item is returned.

    <pre highlight="c++">
    void run_loop::push_back(<i>run-loop-opstate-base</i>* item);
    </pre>

    1. <i>Effects:</i> Adds `item` to the back of the queue and increments <i>count</i> by `1`.

    2. <i>Synchronization:</i> This operation synchronizes with the `pop_front` operation that obtains `item`.

    <pre highlight="c++">
    <i>run-loop-scheduler</i> run_loop::get_scheduler();
    </pre>

    1. <i>Returns:</i> an instance of <code><i>run-loop-scheduler</i></code> that can be used to schedule work onto this `run_loop` instance.

    <pre highlight="c++">
    void run_loop::run();
    </pre>

    1. <i>Effects:</i> Equivalent to:

        <pre highlight="c++">
        while (auto* op = pop_front()) {
          op->execute();
        }
        </pre>

    2. <i>Precondition:</i> <i>state</i> is <i>starting</i>.

    3. <i>Postcondition:</i> <i>state</i> is <i>finishing</i>.

    4. <i>Remarks:</i> While the loop is executing, <i>state</i> is <i>running</i>. When <i>state</i> changes, it does so without introducing data races.

    <pre highlight="c++">
    void run_loop::finish();
    </pre>

    1. <i>Effects:</i> Changes <i>state</i> to <i>finishing</i>.

    2. <i>Synchronization:</i> This operation synchronizes with all `pop_front` operations on this object.

## Coroutine utilities <b>[exec.coro_utils]</b> ## {#spec-execution.coro_utils}

### `execution::as_awaitable` <b>[exec.as_awaitable]</b> ### {#spec-execution.coro_utils.as_awaitable}

1. `as_awaitable` is used to transform an object into one that is awaitable within a particular coroutine. This section makes use of the following exposition-only entities:

    <pre highlight="c++">
    template&lt;class S, class E>
      using <i>single-sender-value-type</i> = <i>see below</i>;

    template&lt;class S, class E>
      concept <i>single-sender</i> =
        sender&lt;S, E> &amp;&amp;
        requires { typename <i>single-sender-value-type</i>&lt;S, E>; };

    template &lt;class S, class P>
      concept <i>awaitable-sender</i> =
        <i>single-sender</i>&lt;S, env_of_t&lt;P>> &amp;&amp;
        sender_to&lt;S, <i>awaitable-receiver</i>> &amp;&amp; // see below
        requires (P&amp; p) {
          { p.unhandled_stopped() } -> convertible_to&lt;coroutine_handle&lt;>>;
        };

    template &lt;class S, class P>
      class <i>sender-awaitable</i>;
    </pre>

    1. Alias template <i>single-sender-value-type</i> is defined as follows:

        1. If `value_types_of_t<S, E, Tuple, Variant>` would have the form `Variant<Tuple<T>>`, then <code><i>single-sender-value-type</i>&lt;S, E></code> is an alias for type `T`.

        2. Otherwise, if `value_types_of_t<S, E, Tuple, Variant>` would have the form `Variant<Tuple<>>` or `Variant<>`, then <code><i>single-sender-value-type</i>&lt;S, E></code> is an alias for type `void`.

        3. Otherwise, <code><i>single-sender-value-type</i>&lt;S, E></code> is ill-formed.

    2. The type <code><i>sender-awaitable</i>&lt;S, P></code> is equivalent to the following:

        <pre highlight="c++">
        template &lt;class S, class P> // arguments are not associated entities ([lib.tmpl-heads])
        class <i>sender-awaitable</i> {
          struct unit {};
          using value_t = <i>single-sender-value-type</i>&lt;S, env_of_t&lt;P>>;
          using result_t = conditional_t&lt;is_void_v&lt;value_t>, unit, value_t>;
          struct <i>awaitable-receiver</i>;

          variant&lt;monostate, result_t, exception_ptr> result_{};
          connect_result_t&lt;S, <i>awaitable-receiver</i>> state_;

         public:
          <i>sender-awaitable</i>(S&& s, P& p);
          bool await_ready() const noexcept { return false; }
          void await_suspend(coroutine_handle&lt;P>) noexcept { start(state_); }
          value_t await_resume();
        };
        </pre>

        1. <code><i>awaitable-receiver</i></code> is equivalent to the following:

            <pre highlight=c++>
            struct <i>awaitable-receiver</i> {
              variant&lt;monostate, result_t, exception_ptr>* result_ptr_;
              coroutine_handle&lt;P> continuation_;
              // ... <i>see below</i>
            };
            </pre>

            Let `r` be an rvalue expression of type <code><i>awaitable-receiver</i></code>, let `cr` be a `const` lvalue that refers to `r`, let `vs...` be an arbitrary function parameter pack of types `Vs...`, and let `err` be an arbitrary expression of type `Err`. Then:

              1. If `constructible_from<result_t, Vs...>` is satisfied, the expression `execution::set_value(r, vs...)` is not potentially throwing and is equivalent to:

                  <pre highlight="c++">
                  try {
                    r.result_ptr_->emplace&lt;1>(vs...);
                  } catch(...) {
                    r.result_ptr_->emplace&lt;2>(current_exception());
                  }
                  r.continuation_.resume();
                  </pre>

                  Otherwise, `execution::set_value(r, vs...)` is ill-formed.

              2. The expression `execution::set_error(r, err)` is not potentially throwing and is equivalent to:

                  <pre highlight="c++">
                  r.result_ptr_->emplace&lt;2>(<i>AS_EXCEPT_PTR</i>(err));
                  r.continuation_.resume();
                  </pre>

                  where <code><i>AS_EXCEPT_PTR</i>(err)</code> is:

                  1. `err` if `decay_t<Err>` names the same type as `exception_ptr`,

                  2. Otherwise, `make_exception_ptr(system_error(err))` if `decay_t<Err>` names the same type as `error_code`,

                  3. Otherwise, `make_exception_ptr(err)`.

              3. The expression `execution::set_stopped(r)` is not potentially throwing and is equivalent to
                `static_cast<coroutine_handle<>>(r.continuation_.promise().unhandled_stopped()).resume()`.

              4. `tag_invoke(tag, cr, as...)` is expression-equivalent to `tag(as_const(cr.continuation_.promise()), as...)` for any expression `tag` whose type satisfies <code><i>forwarding-receiver-query</i></code> and for any set of arguments `as...`.

        2. <b><code><i>sender-awaitable</i>::<i>sender-awaitable</i>(S&& s, P& p)</code></b>

            - <i>Effects:</i> initializes `state_` with <code>connect(std::forward&lt;S>(s), <i>awaitable-receiver</i>{&result_, coroutine_handle&lt;P>::from_promise(p)})</code>.

        3. <b><code>value_t <i>sender-awaitable</i>::await_resume()</code></b>

            - <i>Effects:</i> equivalent to:

                <pre highlight="c++">
                if (result_.index()) == 2)
                  rethrow_exception(get&lt;2>(result_));
                if constexpr (!is_void_v&lt;value_t>)
                  return static_cast&lt;value_t&&>(get&lt;1>(result_));
                </pre>

2. `as_awaitable` is a customization point object. For some subexpressions `e` and `p` where `p` is an lvalue, `E` names the type `decltype((e))` and `P` names the type `decltype((p))`, `as_awaitable(e, p)` is expression-equivalent to the following:

    1. `tag_invoke(as_awaitable, e, p)` if that expression is well-formed.

        * <i>Mandates:</i> <code><i>is-awaitable</i>&lt;A></code> is `true`, where `A` is the type of the `tag_invoke` expression above.

    2. Otherwise, `e` if <code><i>is-awaitable</i>&lt;E></code> is `true`.

    3. Otherwise, <code><i>sender-awaitable</i>{e, p}</code> if <code><i>awaitable-sender</i>&lt;E, P></code> is `true`.

    4. Otherwise, `e`.

### `execution::with_awaitable_senders` <b>[exec.with_awaitable_senders]</b> ### {#spec-execution.coro_utils.with_awaitable_senders}

  1. `with_awaitable_senders`, when used as the base class of a coroutine promise type, makes senders awaitable in that coroutine type.

    In addition, it provides a default implementation of `unhandled_stopped()` such that if a sender completes by calling `execution::set_stopped`, it is treated as if an uncatchable "stopped" exception were thrown from the <i>await-expression</i>. In practice, the coroutine is never resumed, and the `unhandled_stopped` of the coroutine caller's promise type is called.

    <pre highlight="c++">
    template &lt;<i>class-type</i> Promise>
      struct with_awaitable_senders {
        template&lt;OtherPromise>
          requires (!same_as&lt;OtherPromise, void>)
        void set_continuation(coroutine_handle&lt;OtherPromise> h) noexcept;

        coroutine_handle&lt;> continuation() const noexcept { return continuation_; }

        coroutine_handle&lt;> unhandled_stopped() noexcept {
          return stopped_handler_(continuation_.address());
        }

        template&lt;class Value>
        <i>see-below</i> await_transform(Value&& value);

       private:
        // exposition only
        [[noreturn]] static coroutine_handle&lt;> default_unhandled_stopped(void*) noexcept {
          terminate();
        }
        coroutine_handle&lt;> continuation_{}; // exposition only
        // exposition only
        coroutine_handle&lt;> (*stopped_handler_)(void*) noexcept = &default_unhandled_stopped;
      };
    </pre>

  2. <b>`void set_continuation(coroutine_handle<OtherPromise> h) noexcept`</b>

      - <i>Effects:</i> equivalent to:

        <pre highlight="c++">
        continuation_ = h;
        if constexpr ( requires(OtherPromise& other) { other.unhandled_stopped(); } ) {
          stopped_handler_ = [](void* p) noexcept -> coroutine_handle&lt;> {
            return coroutine_handle&lt;OtherPromise>::from_address(p)
              .promise().unhandled_stopped();
          };
        } else {
          stopped_handler_ = default_unhandled_stopped;
        }
        </pre>

  3. <b><code><i>call-result-t</i>&lt;as_awaitable_t, Value, Promise&amp;> await_transform(Value&amp;&amp; value)</code></b>

      - <i>Effects:</i> equivalent to:

        <pre highlight="c++">
        return as_awaitable(static_cast&lt;Value&&>(value), static_cast&lt;Promise&>(*this));
        </pre>

<pre class=biblio>
{
	"HPX": {
		"authors": [
      "Hartmut Kaiser",
      "Patrick Diehl",
      "Adrian S. Lemoine",
      "Bryce Adelstein Lelbach",
      "Parsa Amini",
      "Agustín Berge",
      "John Biddiscombe",
      "Steven R. Brandt",
      "Nikunj Gupta",
      "Thomas Heller",
      "Kevin Huck",
      "Zahra Khatami",
      "Alireza Kheirkhahan",
      "Auriane Reverdell",
      "Shahrzad Shirzad",
      "Mikael Simberg",
      "Bibek Wagle",
      "Weile Wei",
      "Tianyi Zhang"
		],
		"href": "https://doi.org/10.21105/joss.02352",
		"title": "HPX - The C++ Standard Library for Parallelism and Concurrency",
    "volume": 5,
    "number": 53,
    "pages": 2352,
		"publisher": "The Open Journal",
    "journal": "Journal of Open Source Software"
	}
}
</pre>
